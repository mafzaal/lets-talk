{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mafzaal/lets-talk/blob/main/py-src/notebooks/07_Fine_Tune_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b3f96d37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3f96d37",
        "outputId": "18601d50-2cf2-4e39-abf1-d500510cee4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/345.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "pylibcudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU sentence_transformers datasets pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_id = \"Snowflake/snowflake-arctic-embed-l\"\n",
        "model = SentenceTransformer(model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456,
          "referenced_widgets": [
            "1287e1f5ee4747f4b7be32a18c0371ea",
            "98ed0a843a5540e6b319ea7a5797466d",
            "8374bfaf4dfc4e5cba24cde4eddb6eb1",
            "20a6b33a3c4d4b59bb193823cdfa31c3",
            "4dcb732b601c4cb38962febec23463b9",
            "6c46c2b7a1e24426aa64c2e9924301c1",
            "3cbd589285ff4707a0f55b10db9b1c55",
            "2c860bf8fa844f3eaa568ea61321b558",
            "04b48cb1a021463694f193e7a792500a",
            "e92ab7080f404ea8b8923842cbb84e24",
            "ce46b786804a4f079ecd9fcf0cb8e244",
            "fbc711b851ff4e55bf75e8cb84d78718",
            "8ddc346b60914ba693e88c78956ea028",
            "eea62d5b0b3345559e7f43c41f601744",
            "7e1670bced804a23b51d8ee93dcd004c",
            "4f5a70eab3d24f5186a95b3301a322a1",
            "25eecd420c22440fa93a302c8d036edd",
            "13dcdd6d642b4544873fbea5f044a4a7",
            "3a9a6e8d67264f7e97449a0daa0c6187",
            "4910db42e120456ab304fba874dbcdb3",
            "0aff17ab318d460990e9f9306d6130e4",
            "255e75d694ce44828f2dc37fdb63f2a9",
            "482292b6d39c4408b5e6c19ff24ac118",
            "5961daf315be4ff5b5ef1863dc44baf2",
            "b58cfe205bb442198f87d56807e93fe7",
            "e35714c1849d4ae5938a6498b8ebe8cc",
            "e515005c754e4667be490a3585053e5c",
            "6c7e61b1ebd147f2812109c97cfa5779",
            "e3b261b8f6c947339eeb64e75b2c1077",
            "5368115a18364e33b77d8cb35e9d3107",
            "c4fdc95c3e4e43e781e8f4c7b5f23ce0",
            "774b95ed73bd41d790e85a57f0355737",
            "afe61b7053d74e56b8ee54ea6d246da5",
            "0e5dd853588f49438b0712b117e3955f",
            "eb87f81b7c0843a4baa9a240f7e5ac16",
            "60ef772cefec40bfbd7e9cfef0a64651",
            "f822e5d463b143a5836befebfe74e5ce",
            "919398796a1445bf9fe589ff551581c8",
            "3d69d12b8be74835b5579ea0b973c274",
            "036ec32a6c444be1ae95d2a727d1944c",
            "79e3da08256142288f200af9c98edc93",
            "8795588b15114316b3940456acbc473f",
            "46ed3926c672450da3bc78bc15feff9e",
            "b279d1d981fd4d4298631336fa4b26d2",
            "17fdafb7d0344661bb3cc459f18c34a4",
            "5edfb8869b9443fcb574d283cfa28b95",
            "1ed792cd88ef4e7998e7ff8f6a711ce8",
            "564d70470f6e4fc1a90c15c779ebf4a3",
            "7b2548da271a4bcba0fb29bdb55b7bc6",
            "cfa69ecb958a4ee29e735801d229b951",
            "85552ed6321c4c5b9c5e2137aeb8dae3",
            "7d77f7f3503a42809db27f11d80658e4",
            "01ad257c677e4366877751c2d2cf59d6",
            "64c8b4f86e43405490fa09a863e8cd9d",
            "40cf1ab7dd0c4ac8b2d2992e1e6362bd",
            "cd8ead189e0340ccb2a417316dcf9065",
            "821fd88bda4c42a1915120de94c7d6c5",
            "3539c4ebd6eb49f9ad1774bd7d498ea5",
            "70d004de272e42d58501a8db71ea43b8",
            "3378b32e58ff480aac403bcdeece053f",
            "b03fe5c7aa364ae086e732d4288c9807",
            "2e27aff92a9049188ced2886e98f32a1",
            "a7105c71570647a4aa71d5c0c705af48",
            "56aeb44c6385440987199ce4ea1dfc67",
            "be54e9f4837841f6a92e6022ebcc5511",
            "0c0be9be44874794bc39c53dfd0a239a",
            "41b9ecafb65c40c38e476f97b172b94d",
            "1fb7cfef28ff4dd8b983d0b6f45d3917",
            "215ef21bbadb48289966a799547c31f5",
            "87b4db1450d24c8c98b6abb1bfa892f5",
            "45b27c3bcc1f4399930de6467109b204",
            "1245ee931c9a416e8569b54f86e60dd8",
            "bdf705788cc949d09097ec7345dbf9ff",
            "bbe8a275285f4a75a27fbbf386d6bed5",
            "d7e96088df4a4856a7ed43dc3f3042ae",
            "02e9e28411fa4972845cf8255ed77560",
            "679d30f47b31400d900199daff0c38c0",
            "0fb2f3272a3f4e1290396befc23d95b9",
            "88eaf417ab44436fafc4bf4840054021",
            "e884e447f60d4c1bae624e8c8b99439d",
            "6a827996d2a1402dba21cfc7fbd54552",
            "123a290d8e7d4efdb6f1b6d07f0374f0",
            "69bd266916b54f2dad6c2b32c84dc952",
            "d0ea3c36e78b4aeb90197f554bec2f3c",
            "9b3088c37e754fdc95eec7fd1ee5ed0f",
            "cd8c92fa4948492290e454eabcb723f1",
            "ce25eefbab6542b8adf31bc8f0af0630",
            "233b020501e04edabc86ab20252ea578",
            "159985bc4ca04afcb64dea728f182d64",
            "44d0b243000f413bbdd64f4e1e27f835",
            "64f0667ce8384b5e8c6cc23c0cee4db5",
            "528734aaa187412ca211bccc2dff0d4e",
            "a22baad263de419babcfa1959c1068e6",
            "2bd07becd096406896752a399977e347",
            "a2afcfcb083748a599be1de1a1a76f89",
            "f73e86ee3a364f80b21e70d275bafbcb",
            "90b5f5c4e95a4a8a8b7d990db68b5f85",
            "584cdd8fcf3a4f679aede050843dac75",
            "00616310981f4d78886826ca673d4a46",
            "2db5518a228941efa0d5bd0fa38b099d",
            "7c52514ef45f438b8ef105cb92b0e55f",
            "b7bec93856ab468dbe58999b8fd4b9ef",
            "e7ced0f233194397a7c4c894ec052b01",
            "ae54928a39cf405abd824d3d32766eed",
            "6e8ca9438dc2404eb61efabd837e455d",
            "c49537bcf2dc47688d65c8e0eab07d26",
            "c498fffcc1604174bcd42a38148b89d9",
            "c392818942aa4461bd4b59c9cafd216b",
            "c3a2eba9926d48e7b0535cc6e09c849f",
            "ad250319a6374c75b4de7d7ae80f55d2",
            "981bcf8fec6d496b86692ea9e7b68f9c",
            "ea2860fcd4be47c3869e22d342d90453",
            "5d580c0e881d44529391bfe013837346",
            "65644575f25245119fea1fb9c0ce5d8c",
            "22b1cfbeb9d44a33bb9fb7b914980105",
            "4001363fd98e413993415b6210fe1a16",
            "1c00648957814d0899cac456cfddc1cf",
            "03867c26432045c78f8d6f366eae9652",
            "ca65f51dafc0480ab0e9956ec0b479de",
            "8c4d8165964f4faba73684e730a1d9c7",
            "a510b44cd0a145d298330c7fa0f019f6"
          ]
        },
        "id": "Qh-l5gQCi2iz",
        "outputId": "06ba9bf0-c7fa-4af7-847b-554303e3cda6"
      },
      "id": "Qh-l5gQCi2iz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:86: UserWarning: \n",
            "Access to the secret `HF_TOKEN` has not been granted on this notebook.\n",
            "You will not be requested again.\n",
            "Please restart the session if you want to be prompted again.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1287e1f5ee4747f4b7be32a18c0371ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbc711b851ff4e55bf75e8cb84d78718"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/85.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "482292b6d39c4408b5e6c19ff24ac118"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/107 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e5dd853588f49438b0712b117e3955f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17fdafb7d0344661bb3cc459f18c34a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd8ead189e0340ccb2a417316dcf9065"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41b9ecafb65c40c38e476f97b172b94d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fb2f3272a3f4e1290396befc23d95b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "159985bc4ca04afcb64dea728f182d64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2db5518a228941efa0d5bd0fa38b099d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "981bcf8fec6d496b86692ea9e7b68f9c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from sentence_transformers import InputExample"
      ],
      "metadata": {
        "id": "3E_KPiJci6Yp"
      },
      "id": "3E_KPiJci6Yp",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init(mode=\"disabled\")"
      ],
      "metadata": {
        "id": "x5sVWrIhkGCw",
        "outputId": "974b0e49-859c-43a6-b645-f9367b374aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "id": "x5sVWrIhkGCw",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/s4j47d18?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a646a442210>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10\n",
        "EPOCHS = 100\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds = load_dataset(\"mafzaal/thedataguy_embed_ft\")\n",
        "\n",
        "loader = DataLoader(\n",
        "    ds['train'], batch_size=BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "X8AQo76tjQOX"
      },
      "id": "X8AQo76tjQOX",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = ds['train']\n",
        "corpus = train['context']\n",
        "queries = train['question']\n",
        "\n",
        "\n",
        "examples = []\n",
        "for question, context in train:\n",
        "    example = InputExample(texts=[question, context])\n",
        "    examples.append(example)"
      ],
      "metadata": {
        "id": "B_7As0KskvX0"
      },
      "id": "B_7As0KskvX0",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "hRPkocetlOaJ",
        "outputId": "0cee3d98-a646-4d5d-c363-7168e9217224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hRPkocetlOaJ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['---\\ntitle: \"Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications\"\\ndate: 2025-04-26T18:00:00-06:00\\nlayout: blog\\ndescription: \"Explore the essential evaluation framework for LLM applications with Ragas. Learn how to assess performance, ensure accuracy, and improve reliability in Retrieval-Augmented Generation systems.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\",\"Ragas\"]\\ncoverImage: \"https://images.unsplash.com/photo-1593642634367-d91a135587b5?q=80&w=1770&auto=format&fit=crop&ixlib=rb-4.0.3\"\\nreadingTime: 7\\npublished: true\\n---\\n\\nAs Large Language Models (LLMs) become fundamental components of modern applications, effectively evaluating their performance becomes increasingly critical. Whether you\\'re building a question-answering system, a document retrieval tool, or a conversational agent, you need reliable metrics to assess how well your application performs. This is where Ragas steps in.\\n\\n## What is Ragas?',\n",
              " '---\\ntitle: \"Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications\"\\ndate: 2025-04-26T18:00:00-06:00\\nlayout: blog\\ndescription: \"Explore the essential evaluation framework for LLM applications with Ragas. Learn how to assess performance, ensure accuracy, and improve reliability in Retrieval-Augmented Generation systems.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\",\"Ragas\"]\\ncoverImage: \"https://images.unsplash.com/photo-1593642634367-d91a135587b5?q=80&w=1770&auto=format&fit=crop&ixlib=rb-4.0.3\"\\nreadingTime: 7\\npublished: true\\n---\\n\\nAs Large Language Models (LLMs) become fundamental components of modern applications, effectively evaluating their performance becomes increasingly critical. Whether you\\'re building a question-answering system, a document retrieval tool, or a conversational agent, you need reliable metrics to assess how well your application performs. This is where Ragas steps in.\\n\\n## What is Ragas?',\n",
              " \"## What is Ragas?\\n\\n[Ragas](https://docs.ragas.io/en/stable/) is an open-source evaluation framework specifically designed for LLM applications, with particular strengths in Retrieval-Augmented Generation (RAG) systems. Unlike traditional NLP evaluation methods, Ragas provides specialized metrics that address the unique challenges of LLM-powered systems.\\n\\nAt its core, Ragas helps answer crucial questions:\\n- Is my application retrieving the right information?\\n- Are the responses factually accurate and consistent with the retrieved context?\\n- Does the system appropriately address the user's query?\\n- How well does my application handle multi-turn conversations?\\n\\n## Why Evaluate LLM Applications?\\n\\nLLMs are powerful but imperfect. They can hallucinate facts, misinterpret queries, or generate convincing but incorrect responses. For applications where accuracy and reliability matter—like healthcare, finance, or education—proper evaluation is non-negotiable.\",\n",
              " \"## What is Ragas?\\n\\n[Ragas](https://docs.ragas.io/en/stable/) is an open-source evaluation framework specifically designed for LLM applications, with particular strengths in Retrieval-Augmented Generation (RAG) systems. Unlike traditional NLP evaluation methods, Ragas provides specialized metrics that address the unique challenges of LLM-powered systems.\\n\\nAt its core, Ragas helps answer crucial questions:\\n- Is my application retrieving the right information?\\n- Are the responses factually accurate and consistent with the retrieved context?\\n- Does the system appropriately address the user's query?\\n- How well does my application handle multi-turn conversations?\\n\\n## Why Evaluate LLM Applications?\\n\\nLLMs are powerful but imperfect. They can hallucinate facts, misinterpret queries, or generate convincing but incorrect responses. For applications where accuracy and reliability matter—like healthcare, finance, or education—proper evaluation is non-negotiable.\",\n",
              " \"Evaluation serves several key purposes:\\n- **Quality assurance**: Identify and fix issues before they reach users\\n- **Performance tracking**: Monitor how changes impact system performance\\n- **Benchmarking**: Compare different approaches objectively\\n- **Continuous improvement**: Build feedback loops to enhance your application\\n\\n## Key Features of Ragas\\n\\n### 🎯 Specialized Metrics\\nRagas offers both LLM-based and computational metrics tailored to evaluate different aspects of LLM applications:\\n\\n- **Faithfulness**: Measures if the response is factually consistent with the retrieved context\\n- **Context Relevancy**: Evaluates if the retrieved information is relevant to the query\\n- **Answer Relevancy**: Assesses if the response addresses the user's question\\n- **Topic Adherence**: Gauges how well multi-turn conversations stay on topic\",\n",
              " \"Evaluation serves several key purposes:\\n- **Quality assurance**: Identify and fix issues before they reach users\\n- **Performance tracking**: Monitor how changes impact system performance\\n- **Benchmarking**: Compare different approaches objectively\\n- **Continuous improvement**: Build feedback loops to enhance your application\\n\\n## Key Features of Ragas\\n\\n### 🎯 Specialized Metrics\\nRagas offers both LLM-based and computational metrics tailored to evaluate different aspects of LLM applications:\\n\\n- **Faithfulness**: Measures if the response is factually consistent with the retrieved context\\n- **Context Relevancy**: Evaluates if the retrieved information is relevant to the query\\n- **Answer Relevancy**: Assesses if the response addresses the user's question\\n- **Topic Adherence**: Gauges how well multi-turn conversations stay on topic\",\n",
              " \"### 🧪 Test Data Generation\\nCreating high-quality test data is often a bottleneck in evaluation. Ragas helps you generate comprehensive test datasets automatically, saving time and ensuring thorough coverage.\\n\\n### 🔗 Seamless Integrations\\nRagas works with popular LLM frameworks and tools:\\n- [LangChain](https://www.langchain.com/)\\n- [LlamaIndex](https://www.llamaindex.ai/)\\n- [Haystack](https://haystack.deepset.ai/)\\n- [OpenAI](https://openai.com/)\\n\\nObservability platforms \\n- [Phoenix](https://phoenix.arize.com/)\\n- [LangSmith](https://python.langchain.com/docs/introduction/)\\n- [Langfuse](https://www.langfuse.com/)\\n\\n### 📊 Comprehensive Analysis\\nBeyond simple scores, Ragas provides detailed insights into your application's strengths and weaknesses, enabling targeted improvements.\\n\\n## Getting Started with Ragas\\n\\nInstalling Ragas is straightforward:\\n\\n```bash\\nuv init && uv add ragas\\n```\\n\\nHere's a simple example of evaluating a response using Ragas:\",\n",
              " \"### 🧪 Test Data Generation\\nCreating high-quality test data is often a bottleneck in evaluation. Ragas helps you generate comprehensive test datasets automatically, saving time and ensuring thorough coverage.\\n\\n### 🔗 Seamless Integrations\\nRagas works with popular LLM frameworks and tools:\\n- [LangChain](https://www.langchain.com/)\\n- [LlamaIndex](https://www.llamaindex.ai/)\\n- [Haystack](https://haystack.deepset.ai/)\\n- [OpenAI](https://openai.com/)\\n\\nObservability platforms \\n- [Phoenix](https://phoenix.arize.com/)\\n- [LangSmith](https://python.langchain.com/docs/introduction/)\\n- [Langfuse](https://www.langfuse.com/)\\n\\n### 📊 Comprehensive Analysis\\nBeyond simple scores, Ragas provides detailed insights into your application's strengths and weaknesses, enabling targeted improvements.\\n\\n## Getting Started with Ragas\\n\\nInstalling Ragas is straightforward:\\n\\n```bash\\nuv init && uv add ragas\\n```\\n\\nHere's a simple example of evaluating a response using Ragas:\",\n",
              " '## Getting Started with Ragas\\n\\nInstalling Ragas is straightforward:\\n\\n```bash\\nuv init && uv add ragas\\n```\\n\\nHere\\'s a simple example of evaluating a response using Ragas:\\n\\n```python\\nfrom ragas.metrics import Faithfulness\\nfrom ragas.evaluation import EvaluationDataset\\nfrom ragas.dataset_schema import SingleTurnSample\\nfrom langchain_openai import ChatOpenAI\\nfrom ragas.llms import LangchainLLMWrapper\\nfrom langchain_openai import ChatOpenAI\\n\\n# Initialize the LLM, you are going to new OPENAI API key\\nevaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\")) \\n\\n# Your evaluation data\\ntest_data = {\\n    \"user_input\": \"What is the capital of France?\",\\n    \"retrieved_contexts\": [\"Paris is the capital and most populous city of France.\"],\\n    \"response\": \"The capital of France is Paris.\"\\n}\\n\\n# Create a sample\\nsample = SingleTurnSample(**test_data)  # Unpack the dictionary into the constructor',\n",
              " '## Getting Started with Ragas\\n\\nInstalling Ragas is straightforward:\\n\\n```bash\\nuv init && uv add ragas\\n```\\n\\nHere\\'s a simple example of evaluating a response using Ragas:\\n\\n```python\\nfrom ragas.metrics import Faithfulness\\nfrom ragas.evaluation import EvaluationDataset\\nfrom ragas.dataset_schema import SingleTurnSample\\nfrom langchain_openai import ChatOpenAI\\nfrom ragas.llms import LangchainLLMWrapper\\nfrom langchain_openai import ChatOpenAI\\n\\n# Initialize the LLM, you are going to new OPENAI API key\\nevaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\")) \\n\\n# Your evaluation data\\ntest_data = {\\n    \"user_input\": \"What is the capital of France?\",\\n    \"retrieved_contexts\": [\"Paris is the capital and most populous city of France.\"],\\n    \"response\": \"The capital of France is Paris.\"\\n}\\n\\n# Create a sample\\nsample = SingleTurnSample(**test_data)  # Unpack the dictionary into the constructor',\n",
              " '# Create a sample\\nsample = SingleTurnSample(**test_data)  # Unpack the dictionary into the constructor\\n\\n# Create metric\\nfaithfulness = Faithfulness(llm=evaluator_llm)\\n# Calculate the score\\nresult = await faithfulness.single_turn_ascore(sample)\\nprint(f\"Faithfulness score: {result}\")\\n```\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for this workflow:  \\n> [01_Introduction_to_Ragas](https://github.com/mafzaal/intro-to-ragas/blob/master/01_Introduction_to_Ragas.ipynb)\\n\\n## What\\'s Coming in This Blog Series\\n\\nThis introduction is just the beginning. In the upcoming posts, we\\'ll dive deeper into all aspects of evaluating LLM applications with Ragas:\\n\\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\nWe\\'ll explore each metric in detail, explaining when and how to use them effectively.',\n",
              " '# Create a sample\\nsample = SingleTurnSample(**test_data)  # Unpack the dictionary into the constructor\\n\\n# Create metric\\nfaithfulness = Faithfulness(llm=evaluator_llm)\\n# Calculate the score\\nresult = await faithfulness.single_turn_ascore(sample)\\nprint(f\"Faithfulness score: {result}\")\\n```\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for this workflow:  \\n> [01_Introduction_to_Ragas](https://github.com/mafzaal/intro-to-ragas/blob/master/01_Introduction_to_Ragas.ipynb)\\n\\n## What\\'s Coming in This Blog Series\\n\\nThis introduction is just the beginning. In the upcoming posts, we\\'ll dive deeper into all aspects of evaluating LLM applications with Ragas:\\n\\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\nWe\\'ll explore each metric in detail, explaining when and how to use them effectively.',\n",
              " \"**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\nWe'll explore each metric in detail, explaining when and how to use them effectively.\\n\\n**[Part 3: Evaluating RAG Systems](/blog/evaluating-rag-systems-with-ragas/)**  \\nLearn specialized techniques for evaluating retrieval-augmented generation systems, including context precision, recall, and relevance.\\n\\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\nDiscover how to create high-quality test datasets that thoroughly exercise your application's capabilities.\\n\\n**[Part 5: Advanced Evaluation Techniques](/blog/advanced-metrics-and-customization-with-ragas)**  \\nGo beyond basic metrics with custom evaluations, multi-aspect analysis, and domain-specific assessments.\\n\\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\nLearn how to evaluate complex AI agents that engage in multi-turn interactions, use tools, and work toward specific goals.\",\n",
              " \"**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\nWe'll explore each metric in detail, explaining when and how to use them effectively.\\n\\n**[Part 3: Evaluating RAG Systems](/blog/evaluating-rag-systems-with-ragas/)**  \\nLearn specialized techniques for evaluating retrieval-augmented generation systems, including context precision, recall, and relevance.\\n\\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\nDiscover how to create high-quality test datasets that thoroughly exercise your application's capabilities.\\n\\n**[Part 5: Advanced Evaluation Techniques](/blog/advanced-metrics-and-customization-with-ragas)**  \\nGo beyond basic metrics with custom evaluations, multi-aspect analysis, and domain-specific assessments.\\n\\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\nLearn how to evaluate complex AI agents that engage in multi-turn interactions, use tools, and work toward specific goals.\",\n",
              " '**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\nConnect Ragas with your existing tools and platforms for streamlined evaluation workflows.\\n\\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**  \\nLearn how to implement feedback loops that drive continuous improvement in your LLM applications.  \\nTransform evaluation insights into concrete improvements for your LLM applications.\\n\\n## Conclusion\\n\\nIn a world increasingly powered by LLMs, robust evaluation is the difference between reliable applications and unpredictable ones. Ragas provides the tools you need to confidently assess and improve your LLM applications.\\n\\n### Ready to Elevate Your LLM Applications?',\n",
              " '**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\nConnect Ragas with your existing tools and platforms for streamlined evaluation workflows.\\n\\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**  \\nLearn how to implement feedback loops that drive continuous improvement in your LLM applications.  \\nTransform evaluation insights into concrete improvements for your LLM applications.\\n\\n## Conclusion\\n\\nIn a world increasingly powered by LLMs, robust evaluation is the difference between reliable applications and unpredictable ones. Ragas provides the tools you need to confidently assess and improve your LLM applications.\\n\\n### Ready to Elevate Your LLM Applications?',\n",
              " \"### Ready to Elevate Your LLM Applications?\\n\\nStart exploring Ragas today by visiting the [official documentation](https://docs.ragas.io/en/stable/). Share your thoughts, challenges, or success stories. If you're facing specific evaluation hurdles, don't hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we'd love to help!\",\n",
              " \"### Ready to Elevate Your LLM Applications?\\n\\nStart exploring Ragas today by visiting the [official documentation](https://docs.ragas.io/en/stable/). Share your thoughts, challenges, or success stories. If you're facing specific evaluation hurdles, don't hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we'd love to help!\",\n",
              " '---\\ntitle: \"Part 4: Generating Test Data with Ragas\"\\ndate: 2025-04-27T16:00:00-06:00\\nlayout: blog\\ndescription: \"Discover how to generate robust test datasets for evaluating Retrieval-Augmented Generation systems using Ragas, including document-based, domain-specific, and adversarial test generation techniques.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\",\"Data\"]\\ncoverImage: \"/images/generating_test_data.png\"\\nreadingTime: 14\\npublished: true\\n---\\n\\n\\nIn our previous post, we explored how to comprehensively evaluate RAG systems using specialized metrics. However, even the best evaluation framework requires high-quality test data to yield meaningful insights. In this post, we\\'ll dive into how Ragas helps you generate robust test datasets for evaluating your LLM applications.\\n\\n\\n## Why and How to Generate Synthetic Data for RAG Evaluation',\n",
              " '---\\ntitle: \"Part 4: Generating Test Data with Ragas\"\\ndate: 2025-04-27T16:00:00-06:00\\nlayout: blog\\ndescription: \"Discover how to generate robust test datasets for evaluating Retrieval-Augmented Generation systems using Ragas, including document-based, domain-specific, and adversarial test generation techniques.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\",\"Data\"]\\ncoverImage: \"/images/generating_test_data.png\"\\nreadingTime: 14\\npublished: true\\n---\\n\\n\\nIn our previous post, we explored how to comprehensively evaluate RAG systems using specialized metrics. However, even the best evaluation framework requires high-quality test data to yield meaningful insights. In this post, we\\'ll dive into how Ragas helps you generate robust test datasets for evaluating your LLM applications.\\n\\n\\n## Why and How to Generate Synthetic Data for RAG Evaluation',\n",
              " '## Why and How to Generate Synthetic Data for RAG Evaluation\\n\\nIn the world of Retrieval-Augmented Generation (RAG) and LLM-powered applications, **synthetic data generation** is a game-changer for rapid iteration and robust evaluation. This blog post explains why synthetic data is essential, and how you can generate it for your own RAG pipelines—using modern tools like [RAGAS](https://github.com/explodinggradients/ragas) and [LangSmith](https://smith.langchain.com/).\\n\\n---\\n\\n### Why Generate Synthetic Data?\\n\\n1. **Early Signal, Fast Iteration**  \\n   Real-world data is often scarce or expensive to label. Synthetic data lets you quickly create test sets that mimic real user queries and contexts, so you can evaluate your system’s performance before deploying to production.\\n\\n2. **Controlled Complexity**  \\n   You can design synthetic datasets to cover edge cases, multi-hop reasoning, or specific knowledge domains—ensuring your RAG system is robust, not just good at the “easy” cases.',\n",
              " '## Why and How to Generate Synthetic Data for RAG Evaluation\\n\\nIn the world of Retrieval-Augmented Generation (RAG) and LLM-powered applications, **synthetic data generation** is a game-changer for rapid iteration and robust evaluation. This blog post explains why synthetic data is essential, and how you can generate it for your own RAG pipelines—using modern tools like [RAGAS](https://github.com/explodinggradients/ragas) and [LangSmith](https://smith.langchain.com/).\\n\\n---\\n\\n### Why Generate Synthetic Data?\\n\\n1. **Early Signal, Fast Iteration**  \\n   Real-world data is often scarce or expensive to label. Synthetic data lets you quickly create test sets that mimic real user queries and contexts, so you can evaluate your system’s performance before deploying to production.\\n\\n2. **Controlled Complexity**  \\n   You can design synthetic datasets to cover edge cases, multi-hop reasoning, or specific knowledge domains—ensuring your RAG system is robust, not just good at the “easy” cases.',\n",
              " '3. **Benchmarking and Comparison**  \\n   Synthetic test sets provide a repeatable, comparable way to measure improvements as you tweak your pipeline (e.g., changing chunk size, embeddings, or prompts).\\n\\n---\\n\\n### How to Generate Synthetic Data\\n\\n#### 1. **Prepare Your Source Data**\\nStart with a set of documents relevant to your domain. For example, you might download and load HTML blog posts into a document format using tools like LangChain’s `DirectoryLoader`.\\n\\n#### 2. **Build a Knowledge Graph**\\nUse RAGAS to convert your documents into a knowledge graph. This graph captures entities, relationships, and summaries, forming the backbone for generating meaningful queries. RAGAS applies default transformations are dependent on the corpus length, here are some examples:\\n\\n- Producing Summaries -> produces summaries of the documents\\n- Extracting Headlines -> finding the overall headline for the document\\n- Theme Extractor -> extracts broad themes about the documents',\n",
              " '3. **Benchmarking and Comparison**  \\n   Synthetic test sets provide a repeatable, comparable way to measure improvements as you tweak your pipeline (e.g., changing chunk size, embeddings, or prompts).\\n\\n---\\n\\n### How to Generate Synthetic Data\\n\\n#### 1. **Prepare Your Source Data**\\nStart with a set of documents relevant to your domain. For example, you might download and load HTML blog posts into a document format using tools like LangChain’s `DirectoryLoader`.\\n\\n#### 2. **Build a Knowledge Graph**\\nUse RAGAS to convert your documents into a knowledge graph. This graph captures entities, relationships, and summaries, forming the backbone for generating meaningful queries. RAGAS applies default transformations are dependent on the corpus length, here are some examples:\\n\\n- Producing Summaries -> produces summaries of the documents\\n- Extracting Headlines -> finding the overall headline for the document\\n- Theme Extractor -> extracts broad themes about the documents',\n",
              " '- Producing Summaries -> produces summaries of the documents\\n- Extracting Headlines -> finding the overall headline for the document\\n- Theme Extractor -> extracts broad themes about the documents\\n\\nIt then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes. This is a crucial step, as the quality of your knowledge graph directly impacts the relevance and accuracy of the generated queries.\\n\\n#### 3. **Configure Query Synthesizers**\\nRAGAS provides several query synthesizers:\\n- **SingleHopSpecificQuerySynthesizer**: Generates direct, fact-based questions.\\n- **MultiHopAbstractQuerySynthesizer**: Creates broader, multi-step reasoning questions.\\n- **MultiHopSpecificQuerySynthesizer**: Focuses on questions that require connecting specific entities across documents.\\n\\nBy mixing these, you get a diverse and challenging test set.',\n",
              " '- Producing Summaries -> produces summaries of the documents\\n- Extracting Headlines -> finding the overall headline for the document\\n- Theme Extractor -> extracts broad themes about the documents\\n\\nIt then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes. This is a crucial step, as the quality of your knowledge graph directly impacts the relevance and accuracy of the generated queries.\\n\\n#### 3. **Configure Query Synthesizers**\\nRAGAS provides several query synthesizers:\\n- **SingleHopSpecificQuerySynthesizer**: Generates direct, fact-based questions.\\n- **MultiHopAbstractQuerySynthesizer**: Creates broader, multi-step reasoning questions.\\n- **MultiHopSpecificQuerySynthesizer**: Focuses on questions that require connecting specific entities across documents.\\n\\nBy mixing these, you get a diverse and challenging test set.',\n",
              " 'By mixing these, you get a diverse and challenging test set.\\n\\n#### 4. **Generate the Test Set**\\nWith your knowledge graph and query synthesizers, use RAGAS’s `TestsetGenerator` to create a synthetic dataset. This dataset will include questions, reference answers, and supporting contexts.\\n\\n#### 5. **Evaluate and Iterate**\\nLoad your synthetic dataset into an evaluation platform like LangSmith. Run your RAG pipeline against the test set, and use automated evaluators (for accuracy, helpfulness, style, etc.) to identify strengths and weaknesses. Tweak your pipeline and re-evaluate to drive improvements.\\n\\n---\\n\\n### Minimal Example\\n\\nHere’s a high-level pseudocode outline (see the notebook for full details):\\n\\n````python\\n# 1. Load documents\\nfrom langchain_community.document_loaders import DirectoryLoader\\npath = \"data/\"\\nloader = DirectoryLoader(path, glob=\"*.md\")\\ndocs = loader.load()',\n",
              " 'By mixing these, you get a diverse and challenging test set.\\n\\n#### 4. **Generate the Test Set**\\nWith your knowledge graph and query synthesizers, use RAGAS’s `TestsetGenerator` to create a synthetic dataset. This dataset will include questions, reference answers, and supporting contexts.\\n\\n#### 5. **Evaluate and Iterate**\\nLoad your synthetic dataset into an evaluation platform like LangSmith. Run your RAG pipeline against the test set, and use automated evaluators (for accuracy, helpfulness, style, etc.) to identify strengths and weaknesses. Tweak your pipeline and re-evaluate to drive improvements.\\n\\n---\\n\\n### Minimal Example\\n\\nHere’s a high-level pseudocode outline (see the notebook for full details):\\n\\n````python\\n# 1. Load documents\\nfrom langchain_community.document_loaders import DirectoryLoader\\npath = \"data/\"\\nloader = DirectoryLoader(path, glob=\"*.md\")\\ndocs = loader.load()',\n",
              " '````python\\n# 1. Load documents\\nfrom langchain_community.document_loaders import DirectoryLoader\\npath = \"data/\"\\nloader = DirectoryLoader(path, glob=\"*.md\")\\ndocs = loader.load()\\n\\n# 2. Generate data\\nfrom ragas.testset import TestsetGenerator\\nfrom ragas.llms import LangchainLLMWrapper\\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_openai import OpenAIEmbeddings\\n# Initialize the generator with the LLM and embedding model\\ngenerator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\\ngenerator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\\n\\n# Create the test set generator\\ngenerator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\\ndataset = generator.generate_with_langchain_docs(docs, testset_size=10)\\n````\\n\\n`dataset` will now contain a set of questions, answers, and contexts that you can use to evaluate your RAG system.',\n",
              " '````python\\n# 1. Load documents\\nfrom langchain_community.document_loaders import DirectoryLoader\\npath = \"data/\"\\nloader = DirectoryLoader(path, glob=\"*.md\")\\ndocs = loader.load()\\n\\n# 2. Generate data\\nfrom ragas.testset import TestsetGenerator\\nfrom ragas.llms import LangchainLLMWrapper\\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_openai import OpenAIEmbeddings\\n# Initialize the generator with the LLM and embedding model\\ngenerator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\\ngenerator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\\n\\n# Create the test set generator\\ngenerator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\\ndataset = generator.generate_with_langchain_docs(docs, testset_size=10)\\n````\\n\\n`dataset` will now contain a set of questions, answers, and contexts that you can use to evaluate your RAG system.',\n",
              " '`dataset` will now contain a set of questions, answers, and contexts that you can use to evaluate your RAG system.\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> [04_Synthetic_Data_Generation](https://github.com/mafzaal/intro-to-ragas/blob/master/04_Synthetic_Data_Generation.ipynb)\\n\\n### Understanding the Generated Dataset Columns\\n\\nThe synthetic dataset generated by Ragas typically includes the following columns:',\n",
              " '`dataset` will now contain a set of questions, answers, and contexts that you can use to evaluate your RAG system.\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> [04_Synthetic_Data_Generation](https://github.com/mafzaal/intro-to-ragas/blob/master/04_Synthetic_Data_Generation.ipynb)\\n\\n### Understanding the Generated Dataset Columns\\n\\nThe synthetic dataset generated by Ragas typically includes the following columns:',\n",
              " '### Understanding the Generated Dataset Columns\\n\\nThe synthetic dataset generated by Ragas typically includes the following columns:\\n\\n- **`user_input`**: The generated question or query that simulates what a real user might ask. This is the prompt your RAG system will attempt to answer.\\n- **`reference_contexts`**: A list of document snippets or passages that contain the information needed to answer the `user_input`. These serve as the ground truth retrieval targets.\\n- **`reference`**: The ideal answer to the `user_input`, based strictly on the `reference_contexts`. This is used as the gold standard for evaluating answer accuracy.\\n- **`synthesizer_name`**: The name of the query synthesizer (e.g., `SingleHopSpecificQuerySynthesizer`, `MultiHopAbstractQuerySynthesizer`) that generated the question. This helps track the type and complexity of each test case.',\n",
              " '### Understanding the Generated Dataset Columns\\n\\nThe synthetic dataset generated by Ragas typically includes the following columns:\\n\\n- **`user_input`**: The generated question or query that simulates what a real user might ask. This is the prompt your RAG system will attempt to answer.\\n- **`reference_contexts`**: A list of document snippets or passages that contain the information needed to answer the `user_input`. These serve as the ground truth retrieval targets.\\n- **`reference`**: The ideal answer to the `user_input`, based strictly on the `reference_contexts`. This is used as the gold standard for evaluating answer accuracy.\\n- **`synthesizer_name`**: The name of the query synthesizer (e.g., `SingleHopSpecificQuerySynthesizer`, `MultiHopAbstractQuerySynthesizer`) that generated the question. This helps track the type and complexity of each test case.',\n",
              " \"These columns enable comprehensive evaluation by linking each question to its supporting evidence and expected answer, while also providing insight into the diversity and difficulty of the generated queries.\\n\\n\\n## Deep Dive into Test Data Generation\\n\\nSo you have a collection of documents and want to create a robust evaluation dataset for your RAG system using Ragas. The `TestsetGenerator`'s `generate_with_langchain_docs` method is your starting point. But what exactly happens when you call it? Let's peek under the hood.\\n\\n**The Goal:** To take raw Langchain `Document` objects and transform them into a structured Ragas `Testset` containing diverse question-answer pairs grounded in those documents.\\n\\n**The Workflow:**\",\n",
              " \"These columns enable comprehensive evaluation by linking each question to its supporting evidence and expected answer, while also providing insight into the diversity and difficulty of the generated queries.\\n\\n\\n## Deep Dive into Test Data Generation\\n\\nSo you have a collection of documents and want to create a robust evaluation dataset for your RAG system using Ragas. The `TestsetGenerator`'s `generate_with_langchain_docs` method is your starting point. But what exactly happens when you call it? Let's peek under the hood.\\n\\n**The Goal:** To take raw Langchain `Document` objects and transform them into a structured Ragas `Testset` containing diverse question-answer pairs grounded in those documents.\\n\\n**The Workflow:**\",\n",
              " \"**The Goal:** To take raw Langchain `Document` objects and transform them into a structured Ragas `Testset` containing diverse question-answer pairs grounded in those documents.\\n\\n**The Workflow:**\\n\\n1.  **Input & Validation:** The function receives your Langchain `documents`, the desired `testset_size`, and optional configurations for transformations and query types. It first checks if it has the necessary LLM and embedding models to proceed (either provided during `TestsetGenerator` initialization or passed directly to this method).\\n\\n2.  **Setting Up Transformations:** This is a crucial step.\\n    *   **User-Provided:** If you pass a specific `transforms` configuration, the generator uses that.\\n    *   **Default Transformations:** If you *don't* provide `transforms`, the generator calls `ragas.testset.transforms.default_transforms`. This sets up a standard pipeline to process your raw documents into a usable knowledge graph foundation. We'll detail this below.\",\n",
              " \"**The Goal:** To take raw Langchain `Document` objects and transform them into a structured Ragas `Testset` containing diverse question-answer pairs grounded in those documents.\\n\\n**The Workflow:**\\n\\n1.  **Input & Validation:** The function receives your Langchain `documents`, the desired `testset_size`, and optional configurations for transformations and query types. It first checks if it has the necessary LLM and embedding models to proceed (either provided during `TestsetGenerator` initialization or passed directly to this method).\\n\\n2.  **Setting Up Transformations:** This is a crucial step.\\n    *   **User-Provided:** If you pass a specific `transforms` configuration, the generator uses that.\\n    *   **Default Transformations:** If you *don't* provide `transforms`, the generator calls `ragas.testset.transforms.default_transforms`. This sets up a standard pipeline to process your raw documents into a usable knowledge graph foundation. We'll detail this below.\",\n",
              " \"3.  **Document Conversion:** Your Langchain `Document` objects are converted into Ragas' internal `Node` representation, specifically `NodeType.DOCUMENT`. Each node holds the `page_content` and `metadata`.\\n\\n4.  **Initial Knowledge Graph:** A `KnowledgeGraph` object is created, initially containing just these document nodes.\\n\\n5.  **Applying Transformations:** The core processing happens here using `ragas.testset.transforms.apply_transforms`. The chosen `transforms` (default or custom) are executed sequentially on the `KnowledgeGraph`. This modifies the graph by:\\n    *   Adding new nodes (e.g., chunks, questions, answers).\\n    *   Adding relationships between nodes (e.g., linking a question to the chunk it came from).\\n    The generator's internal `knowledge_graph` attribute is updated with this processed graph.\",\n",
              " \"3.  **Document Conversion:** Your Langchain `Document` objects are converted into Ragas' internal `Node` representation, specifically `NodeType.DOCUMENT`. Each node holds the `page_content` and `metadata`.\\n\\n4.  **Initial Knowledge Graph:** A `KnowledgeGraph` object is created, initially containing just these document nodes.\\n\\n5.  **Applying Transformations:** The core processing happens here using `ragas.testset.transforms.apply_transforms`. The chosen `transforms` (default or custom) are executed sequentially on the `KnowledgeGraph`. This modifies the graph by:\\n    *   Adding new nodes (e.g., chunks, questions, answers).\\n    *   Adding relationships between nodes (e.g., linking a question to the chunk it came from).\\n    The generator's internal `knowledge_graph` attribute is updated with this processed graph.\",\n",
              " \"6.  **Delegation to `generate()`:** Now that the foundational knowledge graph with basic Q&A pairs is built (thanks to transformations), `generate_with_langchain_docs` calls the main `self.generate()` method. This method handles the final step of creating the diverse test samples.\\n\\n**Spotlight: Default Transformations (`default_transforms`)**\\n\\nWhen you don't specify custom transformations, Ragas applies a sensible default pipeline to prepare your documents:\",\n",
              " \"6.  **Delegation to `generate()`:** Now that the foundational knowledge graph with basic Q&A pairs is built (thanks to transformations), `generate_with_langchain_docs` calls the main `self.generate()` method. This method handles the final step of creating the diverse test samples.\\n\\n**Spotlight: Default Transformations (`default_transforms`)**\\n\\nWhen you don't specify custom transformations, Ragas applies a sensible default pipeline to prepare your documents:\",\n",
              " \"When you don't specify custom transformations, Ragas applies a sensible default pipeline to prepare your documents:\\n\\n1.  **Chunking (`SentenceChunker`):** Breaks down your large documents into smaller, more manageable chunks (often sentences or groups of sentences). This is essential for focused retrieval and question generation.\\n2.  **Embedding:** Generates vector embeddings for each chunk using the provided embedding model. These are needed for similarity-based operations.\\n3.  **Filtering (`SimilarityFilter`, `InformationFilter`):** Removes redundant chunks (those too similar to others) and potentially low-information chunks to clean up the knowledge base.\\n4.  **Base Q&A Generation (`QAGenerator`):** This is where the initial, simple question-answer pairs are created. The generator looks at individual (filtered) chunks and uses an LLM to formulate straightforward questions whose answers are directly present in that chunk.\",\n",
              " \"When you don't specify custom transformations, Ragas applies a sensible default pipeline to prepare your documents:\\n\\n1.  **Chunking (`SentenceChunker`):** Breaks down your large documents into smaller, more manageable chunks (often sentences or groups of sentences). This is essential for focused retrieval and question generation.\\n2.  **Embedding:** Generates vector embeddings for each chunk using the provided embedding model. These are needed for similarity-based operations.\\n3.  **Filtering (`SimilarityFilter`, `InformationFilter`):** Removes redundant chunks (those too similar to others) and potentially low-information chunks to clean up the knowledge base.\\n4.  **Base Q&A Generation (`QAGenerator`):** This is where the initial, simple question-answer pairs are created. The generator looks at individual (filtered) chunks and uses an LLM to formulate straightforward questions whose answers are directly present in that chunk.\",\n",
              " 'Essentially, the default transformations build a knowledge graph populated with embedded, filtered document chunks and corresponding simple, extractive question-answer pairs.\\n\\n**Spotlight: Query Synthesizers (via `self.generate()` and `default_query_distribution`)**\\n\\nThe `self.generate()` method, called by `generate_with_langchain_docs`, is responsible for taking the foundational graph and creating the final, potentially complex, test questions using **Query Synthesizers** (also referred to as \"evolutions\" or \"scenarios\").',\n",
              " 'Essentially, the default transformations build a knowledge graph populated with embedded, filtered document chunks and corresponding simple, extractive question-answer pairs.\\n\\n**Spotlight: Query Synthesizers (via `self.generate()` and `default_query_distribution`)**\\n\\nThe `self.generate()` method, called by `generate_with_langchain_docs`, is responsible for taking the foundational graph and creating the final, potentially complex, test questions using **Query Synthesizers** (also referred to as \"evolutions\" or \"scenarios\").',\n",
              " '*   **Query Distribution:** `self.generate()` uses a `query_distribution` parameter. If you don\\'t provide one, it calls `ragas.testset.synthesizers.default_query_distribution`.\\n*   **Default Synthesizers:** This default distribution defines a mix of different synthesizer types and the probability of using each one. Common defaults include:\\n    *   **`simple`:** Takes the base Q&A pairs generated during transformation and potentially rephrases them slightly.\\n    *   **`reasoning`:** Creates questions requiring logical inference based on the context in the graph.\\n    *   **`multi_context`:** Generates questions needing information synthesized from multiple different chunks/nodes in the graph.\\n    *   **`conditional`:** Creates questions with \"if/then\" clauses based on information in the graph.',\n",
              " '*   **Query Distribution:** `self.generate()` uses a `query_distribution` parameter. If you don\\'t provide one, it calls `ragas.testset.synthesizers.default_query_distribution`.\\n*   **Default Synthesizers:** This default distribution defines a mix of different synthesizer types and the probability of using each one. Common defaults include:\\n    *   **`simple`:** Takes the base Q&A pairs generated during transformation and potentially rephrases them slightly.\\n    *   **`reasoning`:** Creates questions requiring logical inference based on the context in the graph.\\n    *   **`multi_context`:** Generates questions needing information synthesized from multiple different chunks/nodes in the graph.\\n    *   **`conditional`:** Creates questions with \"if/then\" clauses based on information in the graph.',\n",
              " '*   **`conditional`:** Creates questions with \"if/then\" clauses based on information in the graph.\\n*   **Generation Process:** `self.generate()` calculates how many questions of each type to create based on the `testset_size` and the distribution probabilities. It then uses an `Executor` to run the appropriate synthesizers, generating the final `TestsetSample` objects that make up your evaluation dataset.',\n",
              " '*   **`conditional`:** Creates questions with \"if/then\" clauses based on information in the graph.\\n*   **Generation Process:** `self.generate()` calculates how many questions of each type to create based on the `testset_size` and the distribution probabilities. It then uses an `Executor` to run the appropriate synthesizers, generating the final `TestsetSample` objects that make up your evaluation dataset.',\n",
              " '**In Summary:**\\n\\n`generate_with_langchain_docs` orchestrates a two-phase process:\\n\\n1.  **Transformation Phase:** Uses (typically default) transformations like chunking, filtering, and base Q&A generation to build a foundational knowledge graph from your documents.\\n2.  **Synthesis Phase (via `self.generate`):** Uses (typically default) query synthesizers/evolutions (`simple`, `reasoning`, `multi_context`, etc.) to create diverse and complex questions based on the information stored in the transformed knowledge graph.\\n\\nThis automated pipeline allows you to go from raw documents to a rich, multi-faceted evaluation dataset with minimal configuration.\\n\\n\\n## Best Practices for Test Data Generation',\n",
              " '**In Summary:**\\n\\n`generate_with_langchain_docs` orchestrates a two-phase process:\\n\\n1.  **Transformation Phase:** Uses (typically default) transformations like chunking, filtering, and base Q&A generation to build a foundational knowledge graph from your documents.\\n2.  **Synthesis Phase (via `self.generate`):** Uses (typically default) query synthesizers/evolutions (`simple`, `reasoning`, `multi_context`, etc.) to create diverse and complex questions based on the information stored in the transformed knowledge graph.\\n\\nThis automated pipeline allows you to go from raw documents to a rich, multi-faceted evaluation dataset with minimal configuration.\\n\\n\\n## Best Practices for Test Data Generation',\n",
              " 'This automated pipeline allows you to go from raw documents to a rich, multi-faceted evaluation dataset with minimal configuration.\\n\\n\\n## Best Practices for Test Data Generation\\n\\n1. **Start small and iterate**: Begin with a small test set to verify quality before scaling up\\n2. **Diversify document sources**: Include different document types, styles, and domains\\n3. **Balance question types**: Ensure coverage of simple, complex, and edge-case scenarios\\n4. **Manual review**: Sample-check generated questions for quality and relevance\\n5. **Progressive difficulty**: Include both easy and challenging questions to identify performance thresholds\\n6. **Document metadata**: Retain information about test case generation for later analysis\\n7. **Version control**: Track test set versions alongside your application versions\\n\\n## Conclusion: Building a Test Data Generation Strategy\\n\\nTest data generation should be an integral part of your LLM application development cycle:',\n",
              " 'This automated pipeline allows you to go from raw documents to a rich, multi-faceted evaluation dataset with minimal configuration.\\n\\n\\n## Best Practices for Test Data Generation\\n\\n1. **Start small and iterate**: Begin with a small test set to verify quality before scaling up\\n2. **Diversify document sources**: Include different document types, styles, and domains\\n3. **Balance question types**: Ensure coverage of simple, complex, and edge-case scenarios\\n4. **Manual review**: Sample-check generated questions for quality and relevance\\n5. **Progressive difficulty**: Include both easy and challenging questions to identify performance thresholds\\n6. **Document metadata**: Retain information about test case generation for later analysis\\n7. **Version control**: Track test set versions alongside your application versions\\n\\n## Conclusion: Building a Test Data Generation Strategy\\n\\nTest data generation should be an integral part of your LLM application development cycle:',\n",
              " \"## Conclusion: Building a Test Data Generation Strategy\\n\\nTest data generation should be an integral part of your LLM application development cycle:\\n\\n1. **Initial development**: Generate broad test sets to identify general capabilities and limitations\\n2. **Refinement**: Create targeted test sets for specific features or improvements\\n3. **Regression testing**: Maintain benchmark test sets to ensure changes don't break existing functionality\\n4. **Continuous improvement**: Generate new test cases as your application evolves\\n\\nBy leveraging Ragas for automated test data generation, you can build comprehensive evaluation datasets that thoroughly exercise your LLM applications, leading to more robust, reliable systems.\\n\\nIn our next post, we'll explore advanced metrics and customization techniques for specialized evaluation needs.\\n\\n---\",\n",
              " \"## Conclusion: Building a Test Data Generation Strategy\\n\\nTest data generation should be an integral part of your LLM application development cycle:\\n\\n1. **Initial development**: Generate broad test sets to identify general capabilities and limitations\\n2. **Refinement**: Create targeted test sets for specific features or improvements\\n3. **Regression testing**: Maintain benchmark test sets to ensure changes don't break existing functionality\\n4. **Continuous improvement**: Generate new test cases as your application evolves\\n\\nBy leveraging Ragas for automated test data generation, you can build comprehensive evaluation datasets that thoroughly exercise your LLM applications, leading to more robust, reliable systems.\\n\\nIn our next post, we'll explore advanced metrics and customization techniques for specialized evaluation needs.\\n\\n---\",\n",
              " \"In our next post, we'll explore advanced metrics and customization techniques for specialized evaluation needs.\\n\\n---\\n\\n\\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**   \\n**Part 4: Test Data Generation — _You are here_**  \\n*Next up in the series:*  \\n**[Part 5: Advanced Evaluation Techniques](/blog/advanced-metrics-and-customization-with-ragas)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " \"In our next post, we'll explore advanced metrics and customization techniques for specialized evaluation needs.\\n\\n---\\n\\n\\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**   \\n**Part 4: Test Data Generation — _You are here_**  \\n*Next up in the series:*  \\n**[Part 5: Advanced Evaluation Techniques](/blog/advanced-metrics-and-customization-with-ragas)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " '*How have you implemented feedback loops in your LLM applications? What improvement strategies have been most effective for your use cases? If you’re facing specific evaluation hurdles, don’t hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we’d love to help!*',\n",
              " '*How have you implemented feedback loops in your LLM applications? What improvement strategies have been most effective for your use cases? If you’re facing specific evaluation hurdles, don’t hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we’d love to help!*',\n",
              " '---\\ntitle: \"Part 5: Advanced Metrics and Customization with Ragas\"\\ndate: 2025-04-28T05:00:00-06:00\\nlayout: blog\\ndescription: \"Explore advanced metrics and customization techniques in Ragas for evaluating LLM applications, including creating custom metrics, domain-specific evaluation, composite scoring, and best practices for building a comprehensive evaluation ecosystem.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\",\"Data\"]\\ncoverImage: \"https://plus.unsplash.com/premium_photo-1661368994107-43200954c524?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 9\\npublished: true\\n---\\n\\nIn our previous post, we explored how to generate comprehensive test datasets for evaluating LLM applications. Now, let\\'s dive into one of Ragas\\' most powerful capabilities: advanced metrics and custom evaluation approaches that address specialized evaluation needs.\\n\\n## Beyond the Basics: Why Advanced Metrics Matter',\n",
              " '---\\ntitle: \"Part 5: Advanced Metrics and Customization with Ragas\"\\ndate: 2025-04-28T05:00:00-06:00\\nlayout: blog\\ndescription: \"Explore advanced metrics and customization techniques in Ragas for evaluating LLM applications, including creating custom metrics, domain-specific evaluation, composite scoring, and best practices for building a comprehensive evaluation ecosystem.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\",\"Data\"]\\ncoverImage: \"https://plus.unsplash.com/premium_photo-1661368994107-43200954c524?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 9\\npublished: true\\n---\\n\\nIn our previous post, we explored how to generate comprehensive test datasets for evaluating LLM applications. Now, let\\'s dive into one of Ragas\\' most powerful capabilities: advanced metrics and custom evaluation approaches that address specialized evaluation needs.\\n\\n## Beyond the Basics: Why Advanced Metrics Matter',\n",
              " \"## Beyond the Basics: Why Advanced Metrics Matter\\n\\nWhile Ragas' core metrics cover fundamental evaluation aspects, real-world applications often have unique requirements:\\n\\n- **Domain-specific quality criteria**: Legal, medical, or financial applications have specialized accuracy requirements\\n- **Custom interaction patterns**: Applications with unique conversation flows need tailored evaluation approaches\\n- **Specialized capabilities**: Features like reasoning, code generation, or structured output demand purpose-built metrics\\n- **Business-specific KPIs**: Aligning evaluation with business objectives requires customized metrics\\n\\nLet's explore how to extend Ragas' capabilities to meet these specialized needs.\\n\\n## Understanding Ragas' Metric Architecture\\n\\nBefore creating custom metrics, it's helpful to understand Ragas' metric architecture:\\n\\n### 1. Understand the Metric Base Classes\",\n",
              " \"## Beyond the Basics: Why Advanced Metrics Matter\\n\\nWhile Ragas' core metrics cover fundamental evaluation aspects, real-world applications often have unique requirements:\\n\\n- **Domain-specific quality criteria**: Legal, medical, or financial applications have specialized accuracy requirements\\n- **Custom interaction patterns**: Applications with unique conversation flows need tailored evaluation approaches\\n- **Specialized capabilities**: Features like reasoning, code generation, or structured output demand purpose-built metrics\\n- **Business-specific KPIs**: Aligning evaluation with business objectives requires customized metrics\\n\\nLet's explore how to extend Ragas' capabilities to meet these specialized needs.\\n\\n## Understanding Ragas' Metric Architecture\\n\\nBefore creating custom metrics, it's helpful to understand Ragas' metric architecture:\\n\\n### 1. Understand the Metric Base Classes\",\n",
              " \"## Understanding Ragas' Metric Architecture\\n\\nBefore creating custom metrics, it's helpful to understand Ragas' metric architecture:\\n\\n### 1. Understand the Metric Base Classes\\n\\nAll metrics in Ragas inherit from the abstract `Metric` class (see `metrics/base.py`). For most use cases, you’ll extend one of these:\\n\\n- **SingleTurnMetric**: For metrics that evaluate a single question/response pair.\\n- **MultiTurnMetric**: For metrics that evaluate multi-turn conversations.\\n- **MetricWithLLM**: For metrics that require an LLM for evaluation.\\n- **MetricWithEmbeddings**: For metrics that use embeddings.\\n\\nYou can mix these as needed (e.g., `MetricWithLLM, SingleTurnMetric`).\\n\\nEach metric implements specific scoring methods depending on its type:\\n\\n- `_single_turn_ascore`: For single-turn metrics\\n- `_multi_turn_ascore`: For multi-turn metrics\\n\\n\\n## Creating Your First Custom Metric\\n\\nLet's create a custom metric that evaluates technical accuracy in programming explanations:\",\n",
              " \"## Understanding Ragas' Metric Architecture\\n\\nBefore creating custom metrics, it's helpful to understand Ragas' metric architecture:\\n\\n### 1. Understand the Metric Base Classes\\n\\nAll metrics in Ragas inherit from the abstract `Metric` class (see `metrics/base.py`). For most use cases, you’ll extend one of these:\\n\\n- **SingleTurnMetric**: For metrics that evaluate a single question/response pair.\\n- **MultiTurnMetric**: For metrics that evaluate multi-turn conversations.\\n- **MetricWithLLM**: For metrics that require an LLM for evaluation.\\n- **MetricWithEmbeddings**: For metrics that use embeddings.\\n\\nYou can mix these as needed (e.g., `MetricWithLLM, SingleTurnMetric`).\\n\\nEach metric implements specific scoring methods depending on its type:\\n\\n- `_single_turn_ascore`: For single-turn metrics\\n- `_multi_turn_ascore`: For multi-turn metrics\\n\\n\\n## Creating Your First Custom Metric\\n\\nLet's create a custom metric that evaluates technical accuracy in programming explanations:\",\n",
              " '## Creating Your First Custom Metric\\n\\nLet\\'s create a custom metric that evaluates technical accuracy in programming explanations:\\n\\n```python\\nfrom dataclasses import dataclass, field\\nfrom typing import Dict, Optional, Set\\nimport typing as t\\n\\nfrom ragas.metrics.base import MetricWithLLM, SingleTurnMetric\\nfrom ragas.prompt import PydanticPrompt\\nfrom ragas.metrics import MetricType, MetricOutputType\\nfrom pydantic import BaseModel\\n\\n# Define input/output models for the prompt\\nclass TechnicalAccuracyInput(BaseModel):\\n    question: str\\n    context: str\\n    response: str\\n    programming_language: str = \"python\"\\n\\nclass TechnicalAccuracyOutput(BaseModel):\\n    score: float\\n    feedback: str',\n",
              " '## Creating Your First Custom Metric\\n\\nLet\\'s create a custom metric that evaluates technical accuracy in programming explanations:\\n\\n```python\\nfrom dataclasses import dataclass, field\\nfrom typing import Dict, Optional, Set\\nimport typing as t\\n\\nfrom ragas.metrics.base import MetricWithLLM, SingleTurnMetric\\nfrom ragas.prompt import PydanticPrompt\\nfrom ragas.metrics import MetricType, MetricOutputType\\nfrom pydantic import BaseModel\\n\\n# Define input/output models for the prompt\\nclass TechnicalAccuracyInput(BaseModel):\\n    question: str\\n    context: str\\n    response: str\\n    programming_language: str = \"python\"\\n\\nclass TechnicalAccuracyOutput(BaseModel):\\n    score: float\\n    feedback: str',\n",
              " 'class TechnicalAccuracyOutput(BaseModel):\\n    score: float\\n    feedback: str\\n\\n\\n# Define the prompt\\nclass TechnicalAccuracyPrompt(PydanticPrompt[TechnicalAccuracyInput, TechnicalAccuracyOutput]):\\n    instruction: str = (\\n        \"Evaluate the technical accuracy of the response to a programming question. \"\\n        \"Consider syntax correctness, algorithmic accuracy, and best practices.\"\\n    )\\n    input_model = TechnicalAccuracyInput\\n    output_model = TechnicalAccuracyOutput\\n    examples = [\\n        # Add examples here\\n    ]',\n",
              " 'class TechnicalAccuracyOutput(BaseModel):\\n    score: float\\n    feedback: str\\n\\n\\n# Define the prompt\\nclass TechnicalAccuracyPrompt(PydanticPrompt[TechnicalAccuracyInput, TechnicalAccuracyOutput]):\\n    instruction: str = (\\n        \"Evaluate the technical accuracy of the response to a programming question. \"\\n        \"Consider syntax correctness, algorithmic accuracy, and best practices.\"\\n    )\\n    input_model = TechnicalAccuracyInput\\n    output_model = TechnicalAccuracyOutput\\n    examples = [\\n        # Add examples here\\n    ]',\n",
              " '# Create the metric\\n@dataclass\\nclass TechnicalAccuracy(MetricWithLLM, SingleTurnMetric):\\n    name: str = \"technical_accuracy\"\\n    _required_columns: Dict[MetricType, Set[str]] = field(\\n        default_factory=lambda: {\\n            MetricType.SINGLE_TURN: {\\n                \"user_input\",\\n                \"response\",\\n                \\n            }\\n        }\\n    )\\n    output_type: Optional[MetricOutputType] = MetricOutputType.CONTINUOUS\\n    evaluation_prompt: PydanticPrompt = field(default_factory=TechnicalAccuracyPrompt)\\n    \\n    async def _single_turn_ascore(self, sample, callbacks) -> float:\\n        assert self.llm is not None, \"LLM must be set\"\\n        \\n        question = sample.user_input\\n        response = sample.response\\n        # Extract programming language from question if possible\\n        programming_language = \"python\"  # Default\\n        languages = [\"python\", \"javascript\", \"java\", \"c++\", \"rust\", \"go\"]\\n        for lang in languages:\\n            if lang in question.lower():',\n",
              " '# Create the metric\\n@dataclass\\nclass TechnicalAccuracy(MetricWithLLM, SingleTurnMetric):\\n    name: str = \"technical_accuracy\"\\n    _required_columns: Dict[MetricType, Set[str]] = field(\\n        default_factory=lambda: {\\n            MetricType.SINGLE_TURN: {\\n                \"user_input\",\\n                \"response\",\\n                \\n            }\\n        }\\n    )\\n    output_type: Optional[MetricOutputType] = MetricOutputType.CONTINUOUS\\n    evaluation_prompt: PydanticPrompt = field(default_factory=TechnicalAccuracyPrompt)\\n    \\n    async def _single_turn_ascore(self, sample, callbacks) -> float:\\n        assert self.llm is not None, \"LLM must be set\"\\n        \\n        question = sample.user_input\\n        response = sample.response\\n        # Extract programming language from question if possible\\n        programming_language = \"python\"  # Default\\n        languages = [\"python\", \"javascript\", \"java\", \"c++\", \"rust\", \"go\"]\\n        for lang in languages:\\n            if lang in question.lower():',\n",
              " 'programming_language = \"python\"  # Default\\n        languages = [\"python\", \"javascript\", \"java\", \"c++\", \"rust\", \"go\"]\\n        for lang in languages:\\n            if lang in question.lower():\\n                programming_language = lang\\n                break\\n        \\n        # Get the context\\n        context = \"\\\\n\".join(sample.retrieved_contexts) if sample.retrieved_contexts else \"\"\\n        \\n        # Prepare input for prompt\\n        prompt_input = TechnicalAccuracyInput(\\n            question=question,\\n            context=context,\\n            response=response,\\n            programming_language=programming_language\\n        )\\n        \\n        # Generate evaluation\\n        evaluation = await self.evaluation_prompt.generate(\\n            data=prompt_input, llm=self.llm, callbacks=callbacks\\n        )\\n        \\n        return evaluation.score\\n```\\n## Using the Custom Metric\\nTo use the custom metric, simply include it in your evaluation pipeline:',\n",
              " 'programming_language = \"python\"  # Default\\n        languages = [\"python\", \"javascript\", \"java\", \"c++\", \"rust\", \"go\"]\\n        for lang in languages:\\n            if lang in question.lower():\\n                programming_language = lang\\n                break\\n        \\n        # Get the context\\n        context = \"\\\\n\".join(sample.retrieved_contexts) if sample.retrieved_contexts else \"\"\\n        \\n        # Prepare input for prompt\\n        prompt_input = TechnicalAccuracyInput(\\n            question=question,\\n            context=context,\\n            response=response,\\n            programming_language=programming_language\\n        )\\n        \\n        # Generate evaluation\\n        evaluation = await self.evaluation_prompt.generate(\\n            data=prompt_input, llm=self.llm, callbacks=callbacks\\n        )\\n        \\n        return evaluation.score\\n```\\n## Using the Custom Metric\\nTo use the custom metric, simply include it in your evaluation pipeline:',\n",
              " '```python\\nfrom langchain_openai import ChatOpenAI\\nfrom ragas import SingleTurnSample\\nfrom ragas.llms import LangchainLLMWrapper\\n\\n# Initialize the LLM, you are going to OPENAI API key\\nevaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\")) \\n\\ntest_data = {\\n    \"user_input\": \"Write a function to calculate the factorial of a number in Python.\",\\n    \"retrieved_contexts\": [\"Python is a programming language.\", \"A factorial of a number n is the product of all positive integers less than or equal to n.\"],\\n    \"response\": \"def factorial(n):\\\\n    if n == 0:\\\\n        return 1\\\\n    else:\\\\n        return n * factorial(n-1)\",\\n}',\n",
              " '```python\\nfrom langchain_openai import ChatOpenAI\\nfrom ragas import SingleTurnSample\\nfrom ragas.llms import LangchainLLMWrapper\\n\\n# Initialize the LLM, you are going to OPENAI API key\\nevaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\")) \\n\\ntest_data = {\\n    \"user_input\": \"Write a function to calculate the factorial of a number in Python.\",\\n    \"retrieved_contexts\": [\"Python is a programming language.\", \"A factorial of a number n is the product of all positive integers less than or equal to n.\"],\\n    \"response\": \"def factorial(n):\\\\n    if n == 0:\\\\n        return 1\\\\n    else:\\\\n        return n * factorial(n-1)\",\\n}',\n",
              " '# Create a sample\\nsample = SingleTurnSample(**test_data)  # Unpack the dictionary into the constructor\\ntechnical_accuracy = TechnicalAccuracy(llm=evaluator_llm)\\nscore = await technical_accuracy.single_turn_ascore(sample)\\nprint(f\"Technical Accuracy Score: {score}\")\\n# Note: The above code is a simplified example. In a real-world scenario, you would need to handle exceptions,\\n```\\nYou can also use the `evaluate` function to evaluate a dataset:\\n\\n```python\\nfrom ragas import evaluate\\nfrom ragas import evaluate\\n\\nresults = evaluate(\\n    dataset, # Your dataset of samples\\n    metrics=[TechnicalAccuracy(), ...],\\n    llm=myevaluator_llm_llm\\n)\\n```\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> [05_Advanced_Metrics_and_Customization](https://github.com/mafzaal/intro-to-ragas/blob/master/05_Advanced_Metrics_and_Customization.ipynb)\\n\\n## Customizing Metrics for Your Application',\n",
              " '# Create a sample\\nsample = SingleTurnSample(**test_data)  # Unpack the dictionary into the constructor\\ntechnical_accuracy = TechnicalAccuracy(llm=evaluator_llm)\\nscore = await technical_accuracy.single_turn_ascore(sample)\\nprint(f\"Technical Accuracy Score: {score}\")\\n# Note: The above code is a simplified example. In a real-world scenario, you would need to handle exceptions,\\n```\\nYou can also use the `evaluate` function to evaluate a dataset:\\n\\n```python\\nfrom ragas import evaluate\\nfrom ragas import evaluate\\n\\nresults = evaluate(\\n    dataset, # Your dataset of samples\\n    metrics=[TechnicalAccuracy(), ...],\\n    llm=myevaluator_llm_llm\\n)\\n```\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> [05_Advanced_Metrics_and_Customization](https://github.com/mafzaal/intro-to-ragas/blob/master/05_Advanced_Metrics_and_Customization.ipynb)\\n\\n## Customizing Metrics for Your Application',\n",
              " \"## Customizing Metrics for Your Application\\n\\nYou can further refine your evaluation by customizing existing metrics—such as adjusting thresholds or criteria—to better fit your application's requirements. For multi-turn conversations, you might configure metrics like topic adherence to emphasize specific aspects, such as precision or recall, based on your evaluation objectives.\\n\\nIn specialized domains like healthcare or legal, it's crucial to design custom metrics that capture domain-specific accuracy and compliance needs. For complex applications, consider combining several metrics into composite scores to represent multiple quality dimensions.\\n\\nWhen assessing capabilities like code generation or structured outputs, develop metrics that evaluate execution correctness or schema compliance. For advanced scenarios, you can build metric pipelines that orchestrate several metrics and aggregate their results using strategies like weighted averages or minimum scores.\",\n",
              " \"## Customizing Metrics for Your Application\\n\\nYou can further refine your evaluation by customizing existing metrics—such as adjusting thresholds or criteria—to better fit your application's requirements. For multi-turn conversations, you might configure metrics like topic adherence to emphasize specific aspects, such as precision or recall, based on your evaluation objectives.\\n\\nIn specialized domains like healthcare or legal, it's crucial to design custom metrics that capture domain-specific accuracy and compliance needs. For complex applications, consider combining several metrics into composite scores to represent multiple quality dimensions.\\n\\nWhen assessing capabilities like code generation or structured outputs, develop metrics that evaluate execution correctness or schema compliance. For advanced scenarios, you can build metric pipelines that orchestrate several metrics and aggregate their results using strategies like weighted averages or minimum scores.\",\n",
              " 'By thoughtfully customizing and combining metrics, you can achieve a comprehensive and meaningful evaluation framework tailored to your unique use case.\\n\\n## Best Practices for Custom Metric Development\\n\\n1. **Single Responsibility**: Each metric should evaluate one specific aspect\\n2. **Clear Definition**: Define precisely what your metric measures\\n3. **Bounded Output**: Scores should be normalized, typically in [0,1]\\n4. **Reproducibility**: Minimize randomness in evaluation\\n5. **Documentation**: Document criteria, prompt design, and interpretation guidelines\\n6. **Test with Examples**: Verify metric behavior on clear-cut examples\\n7. **Human Correlation**: Validate that metrics correlate with human judgment\\n\\n## Standardizing Custom Metrics\\n\\nTo ensure consistency across custom metrics, consider the following best practices:',\n",
              " 'By thoughtfully customizing and combining metrics, you can achieve a comprehensive and meaningful evaluation framework tailored to your unique use case.\\n\\n## Best Practices for Custom Metric Development\\n\\n1. **Single Responsibility**: Each metric should evaluate one specific aspect\\n2. **Clear Definition**: Define precisely what your metric measures\\n3. **Bounded Output**: Scores should be normalized, typically in [0,1]\\n4. **Reproducibility**: Minimize randomness in evaluation\\n5. **Documentation**: Document criteria, prompt design, and interpretation guidelines\\n6. **Test with Examples**: Verify metric behavior on clear-cut examples\\n7. **Human Correlation**: Validate that metrics correlate with human judgment\\n\\n## Standardizing Custom Metrics\\n\\nTo ensure consistency across custom metrics, consider the following best practices:',\n",
              " '## Standardizing Custom Metrics\\n\\nTo ensure consistency across custom metrics, consider the following best practices:\\n\\n- Define a clear, human-readable description for each metric.\\n- Provide interpretation guidelines to help users understand score meanings.\\n- Include metadata such as metric name, required columns, and output type.\\n- Use a standardized interface or base class for all custom metrics.\\n\\n## Implementation Patterns for Advanced Metrics\\n\\nWhen developing advanced metrics like topic adherence:\\n\\n- Design multi-step evaluation workflows for complex tasks.\\n- Use specialized prompts for different sub-tasks within the metric.\\n- Allow configurable scoring modes (e.g., precision, recall, F1).\\n- Support conversational context for multi-turn evaluations.\\n\\n## Debugging Custom Metrics\\n\\nEffective debugging strategies include:',\n",
              " '## Standardizing Custom Metrics\\n\\nTo ensure consistency across custom metrics, consider the following best practices:\\n\\n- Define a clear, human-readable description for each metric.\\n- Provide interpretation guidelines to help users understand score meanings.\\n- Include metadata such as metric name, required columns, and output type.\\n- Use a standardized interface or base class for all custom metrics.\\n\\n## Implementation Patterns for Advanced Metrics\\n\\nWhen developing advanced metrics like topic adherence:\\n\\n- Design multi-step evaluation workflows for complex tasks.\\n- Use specialized prompts for different sub-tasks within the metric.\\n- Allow configurable scoring modes (e.g., precision, recall, F1).\\n- Support conversational context for multi-turn evaluations.\\n\\n## Debugging Custom Metrics\\n\\nEffective debugging strategies include:',\n",
              " \"## Debugging Custom Metrics\\n\\nEffective debugging strategies include:\\n\\n- Implementing a debug mode to capture prompt inputs, outputs, and intermediate results.\\n- Logging detailed evaluation steps for easier troubleshooting.\\n- Reviewing final scores alongside intermediate calculations to identify issues.\\n\\n\\n## Conclusion: Building an Evaluation Ecosystem\\n\\nCustom metrics allow you to build a comprehensive evaluation ecosystem tailored to your application's specific needs:\\n\\n1. **Baseline metrics**: Start with Ragas' core metrics for fundamental quality aspects\\n2. **Domain adaptation**: Add specialized metrics for your application domain\\n3. **Feature-specific metrics**: Develop metrics for unique features of your system\\n4. **Business alignment**: Create metrics that reflect specific business KPIs and requirements\",\n",
              " \"## Debugging Custom Metrics\\n\\nEffective debugging strategies include:\\n\\n- Implementing a debug mode to capture prompt inputs, outputs, and intermediate results.\\n- Logging detailed evaluation steps for easier troubleshooting.\\n- Reviewing final scores alongside intermediate calculations to identify issues.\\n\\n\\n## Conclusion: Building an Evaluation Ecosystem\\n\\nCustom metrics allow you to build a comprehensive evaluation ecosystem tailored to your application's specific needs:\\n\\n1. **Baseline metrics**: Start with Ragas' core metrics for fundamental quality aspects\\n2. **Domain adaptation**: Add specialized metrics for your application domain\\n3. **Feature-specific metrics**: Develop metrics for unique features of your system\\n4. **Business alignment**: Create metrics that reflect specific business KPIs and requirements\",\n",
              " \"By extending Ragas with custom metrics, you can create evaluation frameworks that precisely measure what matters most for your LLM applications, leading to more meaningful improvements and better user experiences.\\n\\nIn our next post, we'll explore how to integrate Ragas with popular frameworks and observability tools for seamless evaluation workflows.\",\n",
              " \"By extending Ragas with custom metrics, you can create evaluation frameworks that precisely measure what matters most for your LLM applications, leading to more meaningful improvements and better user experiences.\\n\\nIn our next post, we'll explore how to integrate Ragas with popular frameworks and observability tools for seamless evaluation workflows.\",\n",
              " \"In our next post, we'll explore how to integrate Ragas with popular frameworks and observability tools for seamless evaluation workflows.\\n\\n---\\n \\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**   \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas)**  \\n**Part 5: Advanced Evaluation Techniques — _You are here_**  \\n*Next up in the series:*  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " \"In our next post, we'll explore how to integrate Ragas with popular frameworks and observability tools for seamless evaluation workflows.\\n\\n---\\n \\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**   \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas)**  \\n**Part 5: Advanced Evaluation Techniques — _You are here_**  \\n*Next up in the series:*  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " '*How have you implemented feedback loops in your LLM applications? What improvement strategies have been most effective for your use cases? If you’re facing specific evaluation hurdles, don’t hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we’d love to help!*',\n",
              " '*How have you implemented feedback loops in your LLM applications? What improvement strategies have been most effective for your use cases? If you’re facing specific evaluation hurdles, don’t hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we’d love to help!*',\n",
              " '---\\nlayout: blog\\ntitle: Building a Research Agent with RSS Feed Support\\ndate: 2025-04-20T00:00:00-06:00\\ndescription: How I created a comprehensive research assistant that combines web search, academic papers, RSS feeds, and document analysis to revolutionize information discovery.\\ncategories: [\"AI\", \"LLM\", \"Research\", \"Technology\", \"Agents\"]\\ncoverImage: \"https://images.unsplash.com/photo-1507842217343-583bb7270b66?q=80&w=2290&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 5\\npublished: true\\n---',\n",
              " '---\\nlayout: blog\\ntitle: Building a Research Agent with RSS Feed Support\\ndate: 2025-04-20T00:00:00-06:00\\ndescription: How I created a comprehensive research assistant that combines web search, academic papers, RSS feeds, and document analysis to revolutionize information discovery.\\ncategories: [\"AI\", \"LLM\", \"Research\", \"Technology\", \"Agents\"]\\ncoverImage: \"https://images.unsplash.com/photo-1507842217343-583bb7270b66?q=80&w=2290&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 5\\npublished: true\\n---',\n",
              " \"In the age of information overload, finding the right data efficiently has become increasingly challenging. Whether you're conducting academic research, staying updated on industry trends, or investigating specific topics, the process often involves juggling multiple tools and platforms. This fragmentation inspired me to create a comprehensive solution: a research agent with RSS feed support that brings together multiple information sources in one unified interface.\\n\\n## Why Build a Research Agent?\\n\\nAs someone who regularly conducts research across different domains, I've experienced the frustration of switching between search engines, academic databases, news aggregators, and document analysis tools. Each context switch breaks concentration and slows down the discovery process. I wanted a tool that could:\",\n",
              " \"In the age of information overload, finding the right data efficiently has become increasingly challenging. Whether you're conducting academic research, staying updated on industry trends, or investigating specific topics, the process often involves juggling multiple tools and platforms. This fragmentation inspired me to create a comprehensive solution: a research agent with RSS feed support that brings together multiple information sources in one unified interface.\\n\\n## Why Build a Research Agent?\\n\\nAs someone who regularly conducts research across different domains, I've experienced the frustration of switching between search engines, academic databases, news aggregators, and document analysis tools. Each context switch breaks concentration and slows down the discovery process. I wanted a tool that could:\",\n",
              " \"- Search across multiple information sources simultaneously\\n- Analyze uploaded documents in the context of web information\\n- Provide transparent reasoning about its research process\\n- Deliver structured, well-cited reports\\n\\nThe result is the [Research Agent](https://huggingface.co/spaces/mafzaal/AIE6-ResearchAgent) - an LLM-powered assistant that brings together web search, academic papers, RSS feeds, and document analysis into a single, coherent workflow.\\n\\n## Multi-Source Research Architecture\\n\\nThe agent's strength comes from its ability to tap into various information streams:\\n\\n### Web Search Integration\\n\\nFor real-time information and general knowledge, the agent leverages both Tavily and DuckDuckGo APIs to perform semantic searches across the web. This provides access to current events, recent developments, and general information that might not be available in academic sources.\\n\\n### Academic Research Pipeline\",\n",
              " \"- Search across multiple information sources simultaneously\\n- Analyze uploaded documents in the context of web information\\n- Provide transparent reasoning about its research process\\n- Deliver structured, well-cited reports\\n\\nThe result is the [Research Agent](https://huggingface.co/spaces/mafzaal/AIE6-ResearchAgent) - an LLM-powered assistant that brings together web search, academic papers, RSS feeds, and document analysis into a single, coherent workflow.\\n\\n## Multi-Source Research Architecture\\n\\nThe agent's strength comes from its ability to tap into various information streams:\\n\\n### Web Search Integration\\n\\nFor real-time information and general knowledge, the agent leverages both Tavily and DuckDuckGo APIs to perform semantic searches across the web. This provides access to current events, recent developments, and general information that might not be available in academic sources.\\n\\n### Academic Research Pipeline\",\n",
              " \"### Academic Research Pipeline\\n\\nResearch often requires scholarly sources. The agent connects to arXiv's extensive database of scientific papers, allowing it to retrieve relevant academic articles complete with titles, authors, and abstracts. This is particularly valuable for technical topics that require peer-reviewed information.\\n\\n### RSS Feed Aggregation\\n\\nFor targeted news monitoring and industry updates, the RSS feed reader component allows the agent to retrieve content from specific publications and blogs. This is ideal for tracking industry trends or following particular news sources relevant to your research topic.\\n\\n### Document Analysis Engine\",\n",
              " \"### Academic Research Pipeline\\n\\nResearch often requires scholarly sources. The agent connects to arXiv's extensive database of scientific papers, allowing it to retrieve relevant academic articles complete with titles, authors, and abstracts. This is particularly valuable for technical topics that require peer-reviewed information.\\n\\n### RSS Feed Aggregation\\n\\nFor targeted news monitoring and industry updates, the RSS feed reader component allows the agent to retrieve content from specific publications and blogs. This is ideal for tracking industry trends or following particular news sources relevant to your research topic.\\n\\n### Document Analysis Engine\",\n",
              " '### Document Analysis Engine\\n\\nPerhaps the most powerful feature is the document analysis capability, which uses Retrieval Augmented Generation (RAG) to process uploaded PDFs or text files. By breaking documents into semantic chunks and creating vector embeddings, the agent can answer questions specifically about your documents while incorporating relevant information from other sources.\\n\\n## Behind the Scenes: LangGraph Workflow\\n\\nWhat makes this agent particularly powerful is its LangGraph-based architecture, which provides a structured framework for reasoning and tool orchestration:\\n\\n![Research Agent Graph](/images/building-research-agent-01.png)\\n\\nThis workflow provides several key advantages:',\n",
              " '### Document Analysis Engine\\n\\nPerhaps the most powerful feature is the document analysis capability, which uses Retrieval Augmented Generation (RAG) to process uploaded PDFs or text files. By breaking documents into semantic chunks and creating vector embeddings, the agent can answer questions specifically about your documents while incorporating relevant information from other sources.\\n\\n## Behind the Scenes: LangGraph Workflow\\n\\nWhat makes this agent particularly powerful is its LangGraph-based architecture, which provides a structured framework for reasoning and tool orchestration:\\n\\n![Research Agent Graph](/images/building-research-agent-01.png)\\n\\nThis workflow provides several key advantages:',\n",
              " '![Research Agent Graph](/images/building-research-agent-01.png)\\n\\nThis workflow provides several key advantages:\\n\\n1. **Contextual Awareness**: The agent maintains context throughout the research process\\n2. **Dynamic Tool Selection**: It intelligently chooses which information sources to query based on your question\\n3. **Transparent Reasoning**: You can see each step of the research process\\n4. **Consistent Output Structure**: Results are formatted into comprehensive reports with proper citations\\n\\n## The Technology Stack\\n\\nBuilding the Research Agent required integrating several cutting-edge technologies:',\n",
              " '![Research Agent Graph](/images/building-research-agent-01.png)\\n\\nThis workflow provides several key advantages:\\n\\n1. **Contextual Awareness**: The agent maintains context throughout the research process\\n2. **Dynamic Tool Selection**: It intelligently chooses which information sources to query based on your question\\n3. **Transparent Reasoning**: You can see each step of the research process\\n4. **Consistent Output Structure**: Results are formatted into comprehensive reports with proper citations\\n\\n## The Technology Stack\\n\\nBuilding the Research Agent required integrating several cutting-edge technologies:',\n",
              " '## The Technology Stack\\n\\nBuilding the Research Agent required integrating several cutting-edge technologies:\\n\\n- **LangChain**: Provides the foundation for LLM application development\\n- **LangGraph**: Enables sophisticated workflow orchestration \\n- **Chainlit**: Powers the interactive chat interface\\n- **Qdrant**: Serves as the vector database for document embeddings\\n- **OpenAI**: Supplies the GPT-4o language model and embeddings\\n- **Tavily/DuckDuckGo**: Delivers web search capabilities\\n- **arXiv API**: Connects to academic paper repositories\\n- **Feedparser**: Handles RSS feed processing\\n\\n## The Research Process in Action\\n\\nWhen you ask the Research Agent a question, it follows a systematic process:',\n",
              " '## The Technology Stack\\n\\nBuilding the Research Agent required integrating several cutting-edge technologies:\\n\\n- **LangChain**: Provides the foundation for LLM application development\\n- **LangGraph**: Enables sophisticated workflow orchestration \\n- **Chainlit**: Powers the interactive chat interface\\n- **Qdrant**: Serves as the vector database for document embeddings\\n- **OpenAI**: Supplies the GPT-4o language model and embeddings\\n- **Tavily/DuckDuckGo**: Delivers web search capabilities\\n- **arXiv API**: Connects to academic paper repositories\\n- **Feedparser**: Handles RSS feed processing\\n\\n## The Research Process in Action\\n\\nWhen you ask the Research Agent a question, it follows a systematic process:',\n",
              " \"## The Research Process in Action\\n\\nWhen you ask the Research Agent a question, it follows a systematic process:\\n\\n1. **Query Analysis**: It first analyzes your question to determine which information sources would be most relevant\\n2. **Multi-Tool Research**: Depending on the query, it executes searches across selected tools\\n3. **Context Retrieval**: If you've uploaded documents, it retrieves relevant passages from them\\n4. **Research Transparency**: It shows each step of its research process for full transparency\\n5. **Information Synthesis**: It analyzes and combines information from all sources\\n6. **Structured Reporting**: It delivers a comprehensive response with proper citations\\n\\n## Real-World Applications\\n\\nThe Research Agent has proven valuable across various use cases:\",\n",
              " \"## The Research Process in Action\\n\\nWhen you ask the Research Agent a question, it follows a systematic process:\\n\\n1. **Query Analysis**: It first analyzes your question to determine which information sources would be most relevant\\n2. **Multi-Tool Research**: Depending on the query, it executes searches across selected tools\\n3. **Context Retrieval**: If you've uploaded documents, it retrieves relevant passages from them\\n4. **Research Transparency**: It shows each step of its research process for full transparency\\n5. **Information Synthesis**: It analyzes and combines information from all sources\\n6. **Structured Reporting**: It delivers a comprehensive response with proper citations\\n\\n## Real-World Applications\\n\\nThe Research Agent has proven valuable across various use cases:\",\n",
              " '## Real-World Applications\\n\\nThe Research Agent has proven valuable across various use cases:\\n\\n- **Academic Research**: Gathering information across multiple scholarly sources\\n- **Competitive Analysis**: Staying updated on industry competitors\\n- **Technical Deep Dives**: Understanding complex technical topics\\n- **News Monitoring**: Tracking specific events across multiple sources\\n- **Document Q&A**: Asking questions about specific documents in broader context\\n\\n## Lessons Learned and Future Directions\\n\\nBuilding this agent taught me several valuable lessons about LLM application development:',\n",
              " '## Real-World Applications\\n\\nThe Research Agent has proven valuable across various use cases:\\n\\n- **Academic Research**: Gathering information across multiple scholarly sources\\n- **Competitive Analysis**: Staying updated on industry competitors\\n- **Technical Deep Dives**: Understanding complex technical topics\\n- **News Monitoring**: Tracking specific events across multiple sources\\n- **Document Q&A**: Asking questions about specific documents in broader context\\n\\n## Lessons Learned and Future Directions\\n\\nBuilding this agent taught me several valuable lessons about LLM application development:',\n",
              " \"## Lessons Learned and Future Directions\\n\\nBuilding this agent taught me several valuable lessons about LLM application development:\\n\\n1. **Tool Integration Complexity**: Combining multiple data sources requires careful consideration of data formats and query patterns\\n2. **Context Management**: Maintaining context across different research steps is critical for coherent outputs\\n3. **Transparency Matters**: Users trust AI more when they can see how it reached its conclusions\\n4. **LangGraph Power**: The graph-based approach to LLM workflows provides significant advantages over simpler chains\\n\\nLooking ahead, I'm exploring several enhancements:\\n\\n- Expanded academic database integration beyond arXiv\\n- More sophisticated document analysis with multi-document reasoning\\n- Improved citation formats and bibliographic support\\n- Enhanced visualization of research findings\\n\\n## Try It Yourself\",\n",
              " \"## Lessons Learned and Future Directions\\n\\nBuilding this agent taught me several valuable lessons about LLM application development:\\n\\n1. **Tool Integration Complexity**: Combining multiple data sources requires careful consideration of data formats and query patterns\\n2. **Context Management**: Maintaining context across different research steps is critical for coherent outputs\\n3. **Transparency Matters**: Users trust AI more when they can see how it reached its conclusions\\n4. **LangGraph Power**: The graph-based approach to LLM workflows provides significant advantages over simpler chains\\n\\nLooking ahead, I'm exploring several enhancements:\\n\\n- Expanded academic database integration beyond arXiv\\n- More sophisticated document analysis with multi-document reasoning\\n- Improved citation formats and bibliographic support\\n- Enhanced visualization of research findings\\n\\n## Try It Yourself\",\n",
              " \"## Try It Yourself\\n\\nThe Research Agent is available as an open-source project, and you can try it directly on Hugging Face Spaces:\\n\\n- **Live Demo**: [Hugging Face Space](https://huggingface.co/spaces/mafzaal/AIE6-ResearchAgent)\\n- **Source Code**: [GitHub Repository](https://github.com/mafzaal/AIE6-ResearchAgent)\\n\\nIf you're interested in deploying your own instance, the GitHub repository includes detailed setup instructions for both local development and Docker deployment.\\n\\n---\\n\\n*Have you used the Research Agent or built similar tools? I'd love to hear about your experiences and any suggestions for improvements. Feel free to reach out through the contact form or connect with me on social media!*\",\n",
              " \"## Try It Yourself\\n\\nThe Research Agent is available as an open-source project, and you can try it directly on Hugging Face Spaces:\\n\\n- **Live Demo**: [Hugging Face Space](https://huggingface.co/spaces/mafzaal/AIE6-ResearchAgent)\\n- **Source Code**: [GitHub Repository](https://github.com/mafzaal/AIE6-ResearchAgent)\\n\\nIf you're interested in deploying your own instance, the GitHub repository includes detailed setup instructions for both local development and Docker deployment.\\n\\n---\\n\\n*Have you used the Research Agent or built similar tools? I'd love to hear about your experiences and any suggestions for improvements. Feel free to reach out through the contact form or connect with me on social media!*\",\n",
              " '---\\ntitle: \"Subscribe to Our Blog via RSS\"\\ndate: 2025-05-03T00:00:00-06:00\\ndescription: \"Stay updated with our latest content by subscribing to our new RSS feed\"\\ncategories: [\"Announcements\", \"Blog\"]\\npublished: true\\nlayout: blog\\ncoverImage: \"/images/rss-announcement.png\"\\nreadingTime: 2\\n---\\n\\n# Subscribe to Our Blog via RSS\\n\\nI\\'m excited to announce that TheDataGuy blog now supports RSS feeds! This means you can now easily stay updated with all the latest posts without having to manually check the website.\\n\\n## What is RSS?\\n\\nRSS (Really Simple Syndication) is a web feed that allows you to subscribe to updates from websites you follow. When new content is published, your RSS reader will automatically notify you and display the latest posts.\\n\\n## Why Use RSS?\\n\\nThere are several benefits to using RSS:',\n",
              " '---\\ntitle: \"Subscribe to Our Blog via RSS\"\\ndate: 2025-05-03T00:00:00-06:00\\ndescription: \"Stay updated with our latest content by subscribing to our new RSS feed\"\\ncategories: [\"Announcements\", \"Blog\"]\\npublished: true\\nlayout: blog\\ncoverImage: \"/images/rss-announcement.png\"\\nreadingTime: 2\\n---\\n\\n# Subscribe to Our Blog via RSS\\n\\nI\\'m excited to announce that TheDataGuy blog now supports RSS feeds! This means you can now easily stay updated with all the latest posts without having to manually check the website.\\n\\n## What is RSS?\\n\\nRSS (Really Simple Syndication) is a web feed that allows you to subscribe to updates from websites you follow. When new content is published, your RSS reader will automatically notify you and display the latest posts.\\n\\n## Why Use RSS?\\n\\nThere are several benefits to using RSS:',\n",
              " \"## Why Use RSS?\\n\\nThere are several benefits to using RSS:\\n\\n- **No algorithms**: Unlike social media, RSS feeds show you everything from the sources you subscribe to, in chronological order.\\n- **No ads or distractions**: Get pure content without the clutter.\\n- **Privacy**: RSS readers don't track you like social media platforms do.\\n- **Efficiency**: Check all your favorite sites in one place instead of visiting each individually.\\n\\n## How to Subscribe\\n\\nYou can subscribe to our RSS feed in a few easy steps:\\n\\n1. Copy this link: `https://thedataguy.pro/rss.xml`\\n2. Open your favorite RSS reader (like Feedly, Inoreader, NewsBlur, or even built-in RSS features in browsers like Vivaldi)\\n3. Add a new subscription and paste the link\\n\\nAlternatively, just click the RSS button in the navigation bar of our blog.\\n\\n## Popular RSS Readers\\n\\nIf you don't have an RSS reader yet, here are some popular options:\",\n",
              " \"## Why Use RSS?\\n\\nThere are several benefits to using RSS:\\n\\n- **No algorithms**: Unlike social media, RSS feeds show you everything from the sources you subscribe to, in chronological order.\\n- **No ads or distractions**: Get pure content without the clutter.\\n- **Privacy**: RSS readers don't track you like social media platforms do.\\n- **Efficiency**: Check all your favorite sites in one place instead of visiting each individually.\\n\\n## How to Subscribe\\n\\nYou can subscribe to our RSS feed in a few easy steps:\\n\\n1. Copy this link: `https://thedataguy.pro/rss.xml`\\n2. Open your favorite RSS reader (like Feedly, Inoreader, NewsBlur, or even built-in RSS features in browsers like Vivaldi)\\n3. Add a new subscription and paste the link\\n\\nAlternatively, just click the RSS button in the navigation bar of our blog.\\n\\n## Popular RSS Readers\\n\\nIf you don't have an RSS reader yet, here are some popular options:\",\n",
              " \"Alternatively, just click the RSS button in the navigation bar of our blog.\\n\\n## Popular RSS Readers\\n\\nIf you don't have an RSS reader yet, here are some popular options:\\n\\n- [Feedly](https://feedly.com/)\\n- [Inoreader](https://www.inoreader.com/)\\n- [NewsBlur](https://newsblur.com/)\\n- [Feedbin](https://feedbin.com/)\\n- [The Old Reader](https://theoldreader.com/)\\n\\nMany browsers like Firefox and Vivaldi also have built-in RSS capabilities.\\n\\n## What's Next?\\n\\nI'll continue to improve the blog experience based on your feedback. If you have any suggestions or feature requests, feel free to [reach out](https://www.linkedin.com/in/muhammadafzaal/).\\n\\nHappy reading!\",\n",
              " \"Alternatively, just click the RSS button in the navigation bar of our blog.\\n\\n## Popular RSS Readers\\n\\nIf you don't have an RSS reader yet, here are some popular options:\\n\\n- [Feedly](https://feedly.com/)\\n- [Inoreader](https://www.inoreader.com/)\\n- [NewsBlur](https://newsblur.com/)\\n- [Feedbin](https://feedbin.com/)\\n- [The Old Reader](https://theoldreader.com/)\\n\\nMany browsers like Firefox and Vivaldi also have built-in RSS capabilities.\\n\\n## What's Next?\\n\\nI'll continue to improve the blog experience based on your feedback. If you have any suggestions or feature requests, feel free to [reach out](https://www.linkedin.com/in/muhammadafzaal/).\\n\\nHappy reading!\",\n",
              " '---\\ntitle: \"Metric-Driven Development: Make Smarter Decisions, Faster\"\\ndate: 2025-05-05T00:00:00-06:00\\nlayout: blog\\ndescription: \"Your Team\\'s Secret Weapon for Cutting Through Noise and Driving Real Progress. Learn how to use clear metrics to eliminate guesswork and make faster, smarter progress in your projects.\"\\ncategories: [\"Development\", \"Productivity\", \"AI\", \"Management\"]\\ncoverImage: \"/images/metric-driven-development.png\"\\nreadingTime: 9\\npublished: true\\n---\\n\\nIn today\\'s data-driven world, success depends increasingly on our ability to measure the right things at the right time. Whether you\\'re developing AI systems, building web applications, or managing projects, having clear metrics guides your team toward meaningful progress while eliminating subjective debates.\\n\\n## The Power of Metrics in AI Evaluation',\n",
              " '---\\ntitle: \"Metric-Driven Development: Make Smarter Decisions, Faster\"\\ndate: 2025-05-05T00:00:00-06:00\\nlayout: blog\\ndescription: \"Your Team\\'s Secret Weapon for Cutting Through Noise and Driving Real Progress. Learn how to use clear metrics to eliminate guesswork and make faster, smarter progress in your projects.\"\\ncategories: [\"Development\", \"Productivity\", \"AI\", \"Management\"]\\ncoverImage: \"/images/metric-driven-development.png\"\\nreadingTime: 9\\npublished: true\\n---\\n\\nIn today\\'s data-driven world, success depends increasingly on our ability to measure the right things at the right time. Whether you\\'re developing AI systems, building web applications, or managing projects, having clear metrics guides your team toward meaningful progress while eliminating subjective debates.\\n\\n## The Power of Metrics in AI Evaluation',\n",
              " '## The Power of Metrics in AI Evaluation\\n\\nRecent advances in generative AI and large language models (LLMs) highlight the critical importance of proper evaluation frameworks. Projects like RAGAS (Retrieval Augmented Generation Assessment System) demonstrate how specialized metrics can transform vague goals into actionable insights.\\n\\nFor example, when evaluating retrieval-augmented generation systems, generic metrics like BLEU or ROUGE scores often fail to capture what truly matters - the accuracy, relevance, and contextual understanding of the generated responses. RAGAS instead introduces metrics specifically designed for RAG systems:',\n",
              " '## The Power of Metrics in AI Evaluation\\n\\nRecent advances in generative AI and large language models (LLMs) highlight the critical importance of proper evaluation frameworks. Projects like RAGAS (Retrieval Augmented Generation Assessment System) demonstrate how specialized metrics can transform vague goals into actionable insights.\\n\\nFor example, when evaluating retrieval-augmented generation systems, generic metrics like BLEU or ROUGE scores often fail to capture what truly matters - the accuracy, relevance, and contextual understanding of the generated responses. RAGAS instead introduces metrics specifically designed for RAG systems:',\n",
              " \"* **Faithfulness**: Measures how well the generated answer aligns with the retrieved context\\n* **Answer Relevancy**: Evaluates whether the response correctly addresses the user's query\\n* **Context Relevancy**: Assesses if the system retrieves information that's actually needed\\n* **Context Precision**: Quantifies how efficiently the system uses retrieved information\\n\\nThese targeted metrics provide clearer direction than general-purpose evaluations, allowing teams to make precise improvements where they matter most.\\nImagine two teams building a new feature for a streaming platform:\",\n",
              " \"* **Faithfulness**: Measures how well the generated answer aligns with the retrieved context\\n* **Answer Relevancy**: Evaluates whether the response correctly addresses the user's query\\n* **Context Relevancy**: Assesses if the system retrieves information that's actually needed\\n* **Context Precision**: Quantifies how efficiently the system uses retrieved information\\n\\nThese targeted metrics provide clearer direction than general-purpose evaluations, allowing teams to make precise improvements where they matter most.\\nImagine two teams building a new feature for a streaming platform:\",\n",
              " '*   **Team A** is stuck in debates. Should they focus on improving video load speed or making the recommendation engine more accurate? One engineer insists, \"Faster videos keep users from leaving!\" Another counters, \"But better recommendations are what make them subscribe!\" They argue based on gut feelings.\\n*   **Team B** operates differently. They have a clear, agreed-upon goal: ***Improve the average \"Watch Time per User\" metric, while ensuring video buffering times stay below 2 seconds.*** They rapidly test ideas, measuring the impact of each change against this specific target.\\n\\nWhich team do you think will make faster, smarter progress?\\n\\n\\nTeam B has the edge because they\\'re using **Metric-Driven Development (MDD)**. This is a powerful strategy where teams unite around measurable goals to eliminate guesswork and make real strides. Let\\'s break down how it works, what makes a metric truly useful, and see how industries from healthcare to e-commerce use it to succeed.',\n",
              " '*   **Team A** is stuck in debates. Should they focus on improving video load speed or making the recommendation engine more accurate? One engineer insists, \"Faster videos keep users from leaving!\" Another counters, \"But better recommendations are what make them subscribe!\" They argue based on gut feelings.\\n*   **Team B** operates differently. They have a clear, agreed-upon goal: ***Improve the average \"Watch Time per User\" metric, while ensuring video buffering times stay below 2 seconds.*** They rapidly test ideas, measuring the impact of each change against this specific target.\\n\\nWhich team do you think will make faster, smarter progress?\\n\\n\\nTeam B has the edge because they\\'re using **Metric-Driven Development (MDD)**. This is a powerful strategy where teams unite around measurable goals to eliminate guesswork and make real strides. Let\\'s break down how it works, what makes a metric truly useful, and see how industries from healthcare to e-commerce use it to succeed.',\n",
              " '## What Exactly is Metric-Driven Development?\\n\\nMetric-Driven Development (MDD) is a simple but effective framework where teams:\\n\\n1.  **Define Clear, Measurable Goals:** Set specific numerical targets (e.g., \"Increase user sign-ups by 20% this quarter\").\\n2.  **Base Decisions on Data:** Rely on evidence and measurements, not just opinions or assumptions.\\n3.  **Iterate and Learn Quickly:** Continuously measure the impact of changes to see what works and what doesn\\'t.\\n\\nThink of MDD as a **GPS for your project**. Without clear metrics, you\\'re driving in the fog, hoping you\\'re heading in the right direction. With MDD, you get real-time feedback, ensuring you\\'re moving towards your destination efficiently.\\n\\n## Why Teams Struggle Without Clear Metrics\\n\\nWithout a metric-driven approach, teams often fall into common traps:',\n",
              " '## What Exactly is Metric-Driven Development?\\n\\nMetric-Driven Development (MDD) is a simple but effective framework where teams:\\n\\n1.  **Define Clear, Measurable Goals:** Set specific numerical targets (e.g., \"Increase user sign-ups by 20% this quarter\").\\n2.  **Base Decisions on Data:** Rely on evidence and measurements, not just opinions or assumptions.\\n3.  **Iterate and Learn Quickly:** Continuously measure the impact of changes to see what works and what doesn\\'t.\\n\\nThink of MDD as a **GPS for your project**. Without clear metrics, you\\'re driving in the fog, hoping you\\'re heading in the right direction. With MDD, you get real-time feedback, ensuring you\\'re moving towards your destination efficiently.\\n\\n## Why Teams Struggle Without Clear Metrics\\n\\nWithout a metric-driven approach, teams often fall into common traps:',\n",
              " '## Why Teams Struggle Without Clear Metrics\\n\\nWithout a metric-driven approach, teams often fall into common traps:\\n\\n*   **Chasing Too Many Goals:** Trying to improve everything at once (\"We need higher accuracy *and* faster speed *and* lower costs!\") leads to scattered effort and slow progress.\\n*   **Endless Subjective Debates:** Arguments arise that are hard to resolve with data (\"Is Model A\\'s slightly better performance worth the extra complexity?\").\\n*   **Difficulty Measuring Progress:** It\\'s hard to know if you\\'re actually improving (\"Are we doing better than last quarter? How can we be sure?\").\\n\\nIn **machine learning (ML)**, this often happens when teams track various technical scores (like precision, recall, or F1 score – measures of model accuracy) without a single, unifying metric tied to the *actual business outcome* they want to achieve.\\n\\n## What Makes a Metric Great? The Key Ingredients\\n\\nNot all numbers are helpful. A truly effective metric has these essential traits:',\n",
              " '## Why Teams Struggle Without Clear Metrics\\n\\nWithout a metric-driven approach, teams often fall into common traps:\\n\\n*   **Chasing Too Many Goals:** Trying to improve everything at once (\"We need higher accuracy *and* faster speed *and* lower costs!\") leads to scattered effort and slow progress.\\n*   **Endless Subjective Debates:** Arguments arise that are hard to resolve with data (\"Is Model A\\'s slightly better performance worth the extra complexity?\").\\n*   **Difficulty Measuring Progress:** It\\'s hard to know if you\\'re actually improving (\"Are we doing better than last quarter? How can we be sure?\").\\n\\nIn **machine learning (ML)**, this often happens when teams track various technical scores (like precision, recall, or F1 score – measures of model accuracy) without a single, unifying metric tied to the *actual business outcome* they want to achieve.\\n\\n## What Makes a Metric Great? The Key Ingredients\\n\\nNot all numbers are helpful. A truly effective metric has these essential traits:',\n",
              " '1.  **Measurable:** It must be quantifiable and objective. *\"95% accuracy\"* is measurable; *\"a better user experience\"* is not, unless defined by specific, measurable indicators.\\n2.  **Actionable:** Your team must be able to influence the metric through their work. For example, changing a website\\'s design *can* affect the \"click-through rate.\"\\n3.  **Aligned with Business Goals:** The metric should directly contribute to the overall success of the product or business. If user retention is key, optimizing for ad clicks might be counterproductive.\\n4.  **Simple & Understandable:** It should be easy for everyone on the team (and stakeholders) to grasp and track. *\"Monthly Active Users\"* is usually simpler than a complex, weighted formula.',\n",
              " '1.  **Measurable:** It must be quantifiable and objective. *\"95% accuracy\"* is measurable; *\"a better user experience\"* is not, unless defined by specific, measurable indicators.\\n2.  **Actionable:** Your team must be able to influence the metric through their work. For example, changing a website\\'s design *can* affect the \"click-through rate.\"\\n3.  **Aligned with Business Goals:** The metric should directly contribute to the overall success of the product or business. If user retention is key, optimizing for ad clicks might be counterproductive.\\n4.  **Simple & Understandable:** It should be easy for everyone on the team (and stakeholders) to grasp and track. *\"Monthly Active Users\"* is usually simpler than a complex, weighted formula.',\n",
              " '4.  **Simple & Understandable:** It should be easy for everyone on the team (and stakeholders) to grasp and track. *\"Monthly Active Users\"* is usually simpler than a complex, weighted formula.\\n5.  **Robust (Hard to Game):** The metric shouldn\\'t be easily manipulated in ways that don\\'t reflect real progress. *Example:* A ride-sharing app tracking only \"rides booked\" could be fooled by drivers booking and immediately canceling rides. A better metric might be \"completed rides lasting over 1 minute.\"\\n6.  **Directional:** The desired direction of the metric should be clear – whether you\\'re trying to maximize it (like conversion rate or user retention) or minimize it (like error rate or load time). This clarity helps teams understand exactly what success looks like without ambiguity.',\n",
              " '4.  **Simple & Understandable:** It should be easy for everyone on the team (and stakeholders) to grasp and track. *\"Monthly Active Users\"* is usually simpler than a complex, weighted formula.\\n5.  **Robust (Hard to Game):** The metric shouldn\\'t be easily manipulated in ways that don\\'t reflect real progress. *Example:* A ride-sharing app tracking only \"rides booked\" could be fooled by drivers booking and immediately canceling rides. A better metric might be \"completed rides lasting over 1 minute.\"\\n6.  **Directional:** The desired direction of the metric should be clear – whether you\\'re trying to maximize it (like conversion rate or user retention) or minimize it (like error rate or load time). This clarity helps teams understand exactly what success looks like without ambiguity.',\n",
              " \"## Deep Dive: Reward Functions in AI – Metrics in Action\\n\\nA fascinating application of MDD principles comes from **Reinforcement Learning (RL)**, a type of AI where agents learn through trial and error. In RL, learning is guided by a **reward function**: a numerical score that tells the AI how well it's doing.\\n\\nThink of it like training a dog:\\n*   Good behavior (sitting on command) gets a treat (positive reward).\\n*   Bad behavior (chewing shoes) gets a scold (negative reward or penalty).\\n\\nExamples in AI:\\n*   A chess-playing AI might get +1 for winning, -1 for losing, and 0 for a draw.\\n*   A self-driving car simulation might receive rewards for smooth driving and staying in its lane, and penalties for sudden braking or collisions.\\n\\n**Why Reward Functions Showcase MDD:**\\n\\nReward functions are essentially highly specialized metrics that:\",\n",
              " \"## Deep Dive: Reward Functions in AI – Metrics in Action\\n\\nA fascinating application of MDD principles comes from **Reinforcement Learning (RL)**, a type of AI where agents learn through trial and error. In RL, learning is guided by a **reward function**: a numerical score that tells the AI how well it's doing.\\n\\nThink of it like training a dog:\\n*   Good behavior (sitting on command) gets a treat (positive reward).\\n*   Bad behavior (chewing shoes) gets a scold (negative reward or penalty).\\n\\nExamples in AI:\\n*   A chess-playing AI might get +1 for winning, -1 for losing, and 0 for a draw.\\n*   A self-driving car simulation might receive rewards for smooth driving and staying in its lane, and penalties for sudden braking or collisions.\\n\\n**Why Reward Functions Showcase MDD:**\\n\\nReward functions are essentially highly specialized metrics that:\",\n",
              " '**Why Reward Functions Showcase MDD:**\\n\\nReward functions are essentially highly specialized metrics that:\\n\\n*   **Define Priorities Clearly:** A robot arm designed to pack boxes might get rewards for speed and gentle handling, but penalties for crushing items. The reward function dictates the trade-offs.\\n*   **Guide Behavior in Real-Time:** Unlike metrics evaluated after a project phase, reward functions shape the AI\\'s learning process continuously.\\n*   **Require Careful Design to Avoid \"Gaming\":** Just like business metrics, a poorly designed reward can lead to unintended shortcuts. An RL agent in a game might discover a way to rack up points by repeatedly performing a trivial action, instead of actually trying to win the level. This highlights the importance of the \"Robust\" trait we discussed earlier.\\n\\nReward functions embody the core MDD idea: set a clear, measurable goal, and let it guide actions towards success.\\n\\n## Metric-Driven Development Across Industries: Real-World Examples',\n",
              " '**Why Reward Functions Showcase MDD:**\\n\\nReward functions are essentially highly specialized metrics that:\\n\\n*   **Define Priorities Clearly:** A robot arm designed to pack boxes might get rewards for speed and gentle handling, but penalties for crushing items. The reward function dictates the trade-offs.\\n*   **Guide Behavior in Real-Time:** Unlike metrics evaluated after a project phase, reward functions shape the AI\\'s learning process continuously.\\n*   **Require Careful Design to Avoid \"Gaming\":** Just like business metrics, a poorly designed reward can lead to unintended shortcuts. An RL agent in a game might discover a way to rack up points by repeatedly performing a trivial action, instead of actually trying to win the level. This highlights the importance of the \"Robust\" trait we discussed earlier.\\n\\nReward functions embody the core MDD idea: set a clear, measurable goal, and let it guide actions towards success.\\n\\n## Metric-Driven Development Across Industries: Real-World Examples',\n",
              " \"Reward functions embody the core MDD idea: set a clear, measurable goal, and let it guide actions towards success.\\n\\n## Metric-Driven Development Across Industries: Real-World Examples\\n\\nMDD isn't just for software. Here's how different fields use it:\",\n",
              " \"Reward functions embody the core MDD idea: set a clear, measurable goal, and let it guide actions towards success.\\n\\n## Metric-Driven Development Across Industries: Real-World Examples\\n\\nMDD isn't just for software. Here's how different fields use it:\",\n",
              " '*   **E-Commerce: Conversion Rate**\\n    *   **Metric:** Percentage of website visitors who make a purchase.\\n    *   **Impact:** Directly ties development efforts (like A/B testing checkout flows) to revenue growth.\\n*   **Healthcare: Patient Readmission Rate**\\n    *   **Metric:** Percentage of patients readmitted to the hospital within 30 days of discharge.\\n    *   **Impact:** Focuses efforts on improving care quality and follow-up, leading to better patient outcomes and lower costs.\\n*   **Manufacturing: Defect Rate**\\n    *   **Metric:** Percentage of products produced with flaws.\\n    *   **Impact:** Drives process improvements on the factory floor, saving costs and enhancing brand reputation.\\n*   **Gaming (AI Development): Player Performance Score**\\n    *   **Metric:** A combined score, e.g., `Points Scored - (Time Taken * Penalty Factor)`.\\n    *   **Impact:** Trains AI opponents that are challenging but fair, balancing speed and skill.',\n",
              " '*   **E-Commerce: Conversion Rate**\\n    *   **Metric:** Percentage of website visitors who make a purchase.\\n    *   **Impact:** Directly ties development efforts (like A/B testing checkout flows) to revenue growth.\\n*   **Healthcare: Patient Readmission Rate**\\n    *   **Metric:** Percentage of patients readmitted to the hospital within 30 days of discharge.\\n    *   **Impact:** Focuses efforts on improving care quality and follow-up, leading to better patient outcomes and lower costs.\\n*   **Manufacturing: Defect Rate**\\n    *   **Metric:** Percentage of products produced with flaws.\\n    *   **Impact:** Drives process improvements on the factory floor, saving costs and enhancing brand reputation.\\n*   **Gaming (AI Development): Player Performance Score**\\n    *   **Metric:** A combined score, e.g., `Points Scored - (Time Taken * Penalty Factor)`.\\n    *   **Impact:** Trains AI opponents that are challenging but fair, balancing speed and skill.',\n",
              " '*   **Metric:** A combined score, e.g., `Points Scored - (Time Taken * Penalty Factor)`.\\n    *   **Impact:** Trains AI opponents that are challenging but fair, balancing speed and skill.\\n*   **Autonomous Vehicles: Safety & Comfort Score**\\n    *   **Metric:** Combination of factors like smooth acceleration/braking, lane adherence, and deductions for interventions or near-misses.\\n    *   **Impact:** Guides development towards vehicles that are not only safe but also provide a comfortable ride.',\n",
              " '*   **Metric:** A combined score, e.g., `Points Scored - (Time Taken * Penalty Factor)`.\\n    *   **Impact:** Trains AI opponents that are challenging but fair, balancing speed and skill.\\n*   **Autonomous Vehicles: Safety & Comfort Score**\\n    *   **Metric:** Combination of factors like smooth acceleration/braking, lane adherence, and deductions for interventions or near-misses.\\n    *   **Impact:** Guides development towards vehicles that are not only safe but also provide a comfortable ride.',\n",
              " '## Smart Tactics: Optimizing vs. Satisficing Metrics\\n\\nSometimes, you have competing priorities. MDD offers a smart way to handle this using two types of metrics:\\n\\n*   **Optimizing Metric:** The main goal you want to maximize or minimize (your \"North Star\").\\n*   **Satisficing Metrics:** Other important factors that just need to meet a minimum acceptable level (\"good enough\").\\n\\n*Example: Developing a voice assistant like Alexa or Google Assistant:*\\n\\n*   **Optimizing Metric:** *Minimize missed commands (false negatives)* – You want it to respond reliably when you speak the wake-word.\\n*   **Satisficing Metric:** *Keep false activations below 1 per day (false positives)* – You don\\'t want it waking up constantly when you haven\\'t addressed it, but perfect prevention might hurt its responsiveness.\\n\\nThis approach prevents teams from sacrificing critical aspects (like basic usability) in the pursuit of perfecting a single metric.\\n\\n## Don\\'t Forget Early Signals: The Role of Leading Indicators',\n",
              " '## Smart Tactics: Optimizing vs. Satisficing Metrics\\n\\nSometimes, you have competing priorities. MDD offers a smart way to handle this using two types of metrics:\\n\\n*   **Optimizing Metric:** The main goal you want to maximize or minimize (your \"North Star\").\\n*   **Satisficing Metrics:** Other important factors that just need to meet a minimum acceptable level (\"good enough\").\\n\\n*Example: Developing a voice assistant like Alexa or Google Assistant:*\\n\\n*   **Optimizing Metric:** *Minimize missed commands (false negatives)* – You want it to respond reliably when you speak the wake-word.\\n*   **Satisficing Metric:** *Keep false activations below 1 per day (false positives)* – You don\\'t want it waking up constantly when you haven\\'t addressed it, but perfect prevention might hurt its responsiveness.\\n\\nThis approach prevents teams from sacrificing critical aspects (like basic usability) in the pursuit of perfecting a single metric.\\n\\n## Don\\'t Forget Early Signals: The Role of Leading Indicators',\n",
              " 'This approach prevents teams from sacrificing critical aspects (like basic usability) in the pursuit of perfecting a single metric.\\n\\n## Don\\'t Forget Early Signals: The Role of Leading Indicators\\n\\nIn machine learning projects, **training loss** is a common metric monitored during development. Think of it as a **\"practice test score\"** for the model – it shows how well the model is learning the patterns in the training data *before* it faces the real world.\\n\\nWhile a low training loss is good (it means the model is learning *something*), it\\'s a **leading indicator**. It doesn\\'t guarantee success on its own. You still need **lagging indicators** – metrics that measure real-world performance, like user satisfaction, task completion rates, or the ultimate business goal (e.g., user retention).',\n",
              " 'This approach prevents teams from sacrificing critical aspects (like basic usability) in the pursuit of perfecting a single metric.\\n\\n## Don\\'t Forget Early Signals: The Role of Leading Indicators\\n\\nIn machine learning projects, **training loss** is a common metric monitored during development. Think of it as a **\"practice test score\"** for the model – it shows how well the model is learning the patterns in the training data *before* it faces the real world.\\n\\nWhile a low training loss is good (it means the model is learning *something*), it\\'s a **leading indicator**. It doesn\\'t guarantee success on its own. You still need **lagging indicators** – metrics that measure real-world performance, like user satisfaction, task completion rates, or the ultimate business goal (e.g., user retention).',\n",
              " 'MDD reminds us to track both:\\n*   **Leading indicators** (like training loss, code coverage) to monitor progress during development.\\n*   **Lagging indicators** (like user engagement, revenue, customer support tickets) to measure the actual impact.\\n\\n## The Takeaway: Use Metrics as Your Compass\\nMetric-Driven Development isn\\'t a complex theory reserved for tech giants. It\\'s a fundamental mindset applicable everywhere:\\n\\n*   A local bakery might track *\"Daily Units Sold per Pastry Type\"* to optimize baking schedules.\\n*   A city planner could use *\"Average Commute Time Reduction\"* to evaluate the success of new traffic light patterns.\\n*   A project manager might measure progress through *\"Sprint Velocity\"* or *\"Percentage of On-Time Task Completions\"* rather than subjective assessments of how \"busy\" the team appears.\\n\\n\\nBy choosing metrics that are **measurable, actionable, aligned, simple, and robust**, you transform ambiguity into clarity and opinion into evidence.',\n",
              " 'MDD reminds us to track both:\\n*   **Leading indicators** (like training loss, code coverage) to monitor progress during development.\\n*   **Lagging indicators** (like user engagement, revenue, customer support tickets) to measure the actual impact.\\n\\n## The Takeaway: Use Metrics as Your Compass\\nMetric-Driven Development isn\\'t a complex theory reserved for tech giants. It\\'s a fundamental mindset applicable everywhere:\\n\\n*   A local bakery might track *\"Daily Units Sold per Pastry Type\"* to optimize baking schedules.\\n*   A city planner could use *\"Average Commute Time Reduction\"* to evaluate the success of new traffic light patterns.\\n*   A project manager might measure progress through *\"Sprint Velocity\"* or *\"Percentage of On-Time Task Completions\"* rather than subjective assessments of how \"busy\" the team appears.\\n\\n\\nBy choosing metrics that are **measurable, actionable, aligned, simple, and robust**, you transform ambiguity into clarity and opinion into evidence.',\n",
              " \"By choosing metrics that are **measurable, actionable, aligned, simple, and robust**, you transform ambiguity into clarity and opinion into evidence.\\n\\nWhether you're building sophisticated AI or launching a simple website feature, MDD empowers your team to:\\n\\n1.  **Move Faster:** Make decisions quickly based on clear success criteria.\\n2.  **Collaborate Effectively:** Unite everyone around shared, objective goals.\\n3.  **Know When You've Won:** Celebrate real, measurable progress.\\n\\nSo, the next time your team feels stuck or unsure about the path forward, ask the crucial question: ***What's our metric?***\\n\\nFinding that answer might just be the compass you need to navigate towards success.\\n\\n---\\n*Inspired by insights from Andrew Ng's [Machine Learning Yearning](https://info.deeplearning.ai/machine-learning-yearning-book). Remember: A great metric doesn't just measure success—it actively helps create it.*\",\n",
              " \"By choosing metrics that are **measurable, actionable, aligned, simple, and robust**, you transform ambiguity into clarity and opinion into evidence.\\n\\nWhether you're building sophisticated AI or launching a simple website feature, MDD empowers your team to:\\n\\n1.  **Move Faster:** Make decisions quickly based on clear success criteria.\\n2.  **Collaborate Effectively:** Unite everyone around shared, objective goals.\\n3.  **Know When You've Won:** Celebrate real, measurable progress.\\n\\nSo, the next time your team feels stuck or unsure about the path forward, ask the crucial question: ***What's our metric?***\\n\\nFinding that answer might just be the compass you need to navigate towards success.\\n\\n---\\n*Inspired by insights from Andrew Ng's [Machine Learning Yearning](https://info.deeplearning.ai/machine-learning-yearning-book). Remember: A great metric doesn't just measure success—it actively helps create it.*\",\n",
              " '---\\ntitle: \"Part 2: Basic Evaluation Workflow with Ragas\"\\ndate: 2025-04-26T19:00:00-06:00\\nlayout: blog\\ndescription: \"Learn how to set up a basic evaluation workflow for LLM applications using Ragas. This guide walks you through data preparation, metric selection, and result analysis.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\"]\\ncoverImage: \"https://images.unsplash.com/photo-1600132806370-bf17e65e942f?q=80&w=1988&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 8\\npublished: true\\n---\\n\\nIn our previous post, we introduced Ragas as a powerful framework for evaluating LLM applications. Now, let\\'s dive into the practical aspects of setting up your first evaluation pipeline.\\n\\n## Understanding the Evaluation Workflow\\n\\nA typical Ragas evaluation workflow consists of four key steps:',\n",
              " '---\\ntitle: \"Part 2: Basic Evaluation Workflow with Ragas\"\\ndate: 2025-04-26T19:00:00-06:00\\nlayout: blog\\ndescription: \"Learn how to set up a basic evaluation workflow for LLM applications using Ragas. This guide walks you through data preparation, metric selection, and result analysis.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\"]\\ncoverImage: \"https://images.unsplash.com/photo-1600132806370-bf17e65e942f?q=80&w=1988&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 8\\npublished: true\\n---\\n\\nIn our previous post, we introduced Ragas as a powerful framework for evaluating LLM applications. Now, let\\'s dive into the practical aspects of setting up your first evaluation pipeline.\\n\\n## Understanding the Evaluation Workflow\\n\\nA typical Ragas evaluation workflow consists of four key steps:',\n",
              " \"## Understanding the Evaluation Workflow\\n\\nA typical Ragas evaluation workflow consists of four key steps:\\n\\n1. **Prepare your data**: Collect queries, contexts, responses, and reference answers\\n2. **Select appropriate metrics**: Choose metrics that align with what you want to evaluate\\n3. **Run the evaluation**: Process your data through the selected metrics\\n4. **Analyze the results**: Interpret scores and identify areas for improvement\\n\\nLet's walk through each step with practical examples.\\n\\n## Step 1: Setting Up Your Environment\\n\\nFirst, ensure you have Ragas installed:\\n\\n```bash\\nuv add ragas\\n```\\n\\nNext, import the necessary components:\\n\\n```python\\nimport pandas as pd\\nfrom ragas import EvaluationDataset\\nfrom ragas import evaluate, RunConfig\\nfrom ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\\n```\\n\\n## Step 2: Preparing Your Evaluation Data\\n\\nFor a RAG system evaluation, you'll need:\",\n",
              " \"## Understanding the Evaluation Workflow\\n\\nA typical Ragas evaluation workflow consists of four key steps:\\n\\n1. **Prepare your data**: Collect queries, contexts, responses, and reference answers\\n2. **Select appropriate metrics**: Choose metrics that align with what you want to evaluate\\n3. **Run the evaluation**: Process your data through the selected metrics\\n4. **Analyze the results**: Interpret scores and identify areas for improvement\\n\\nLet's walk through each step with practical examples.\\n\\n## Step 1: Setting Up Your Environment\\n\\nFirst, ensure you have Ragas installed:\\n\\n```bash\\nuv add ragas\\n```\\n\\nNext, import the necessary components:\\n\\n```python\\nimport pandas as pd\\nfrom ragas import EvaluationDataset\\nfrom ragas import evaluate, RunConfig\\nfrom ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\\n```\\n\\n## Step 2: Preparing Your Evaluation Data\\n\\nFor a RAG system evaluation, you'll need:\",\n",
              " \"## Step 2: Preparing Your Evaluation Data\\n\\nFor a RAG system evaluation, you'll need:\\n\\n- **Questions**: User queries to your system\\n- **Contexts**: Documents or chunks retrieved by your system\\n- **Responses**: Answers generated by your system\\n- **Ground truth** (optional): Reference answers or documents for comparison\\n\\nHere's how to organize this data:\",\n",
              " \"## Step 2: Preparing Your Evaluation Data\\n\\nFor a RAG system evaluation, you'll need:\\n\\n- **Questions**: User queries to your system\\n- **Contexts**: Documents or chunks retrieved by your system\\n- **Responses**: Answers generated by your system\\n- **Ground truth** (optional): Reference answers or documents for comparison\\n\\nHere's how to organize this data:\",\n",
              " '```python\\n# Sample data\\ndata = {\\n    \"user_input\": [\\n        \"What are the main symptoms of COVID-19?\",\\n        \"How does machine learning differ from deep learning?\"\\n    ],\\n    \"retrieved_contexts\": [\\n        [\\n            \"Common symptoms of COVID-19 include fever, cough, and fatigue. Some patients also report loss of taste or smell, body aches, and difficulty breathing.\",\\n            \"COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory droplets.\"\\n        ],\\n        [\\n            \"Machine learning is a subset of AI focused on algorithms that learn from data without being explicitly programmed.\",\\n            \"Deep learning is a specialized form of machine learning using neural networks with many layers (deep neural networks).\"\\n        ]\\n    ],\\n    \"response\": [\\n        \"The main symptoms of COVID-19 include fever, cough, fatigue, and sometimes loss of taste or smell, body aches, and breathing difficulties.\",',\n",
              " '```python\\n# Sample data\\ndata = {\\n    \"user_input\": [\\n        \"What are the main symptoms of COVID-19?\",\\n        \"How does machine learning differ from deep learning?\"\\n    ],\\n    \"retrieved_contexts\": [\\n        [\\n            \"Common symptoms of COVID-19 include fever, cough, and fatigue. Some patients also report loss of taste or smell, body aches, and difficulty breathing.\",\\n            \"COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory droplets.\"\\n        ],\\n        [\\n            \"Machine learning is a subset of AI focused on algorithms that learn from data without being explicitly programmed.\",\\n            \"Deep learning is a specialized form of machine learning using neural networks with many layers (deep neural networks).\"\\n        ]\\n    ],\\n    \"response\": [\\n        \"The main symptoms of COVID-19 include fever, cough, fatigue, and sometimes loss of taste or smell, body aches, and breathing difficulties.\",',\n",
              " ']\\n    ],\\n    \"response\": [\\n        \"The main symptoms of COVID-19 include fever, cough, fatigue, and sometimes loss of taste or smell, body aches, and breathing difficulties.\",\\n        \"Machine learning is a subset of AI that focuses on algorithms learning from data, while deep learning is a specialized form of machine learning that uses deep neural networks with multiple layers.\"\\n    ],\\n    \"reference\": [\\n        \"COVID-19 symptoms commonly include fever, dry cough, fatigue, loss of taste or smell, body aches, sore throat, and in severe cases, difficulty breathing.\",\\n        \"Machine learning is a branch of AI where systems learn from data, identify patterns, and make decisions with minimal human intervention. Deep learning is a subset of machine learning that uses neural networks with multiple layers (deep neural networks) to analyze various factors of data.\"\\n    ]\\n}',\n",
              " ']\\n    ],\\n    \"response\": [\\n        \"The main symptoms of COVID-19 include fever, cough, fatigue, and sometimes loss of taste or smell, body aches, and breathing difficulties.\",\\n        \"Machine learning is a subset of AI that focuses on algorithms learning from data, while deep learning is a specialized form of machine learning that uses deep neural networks with multiple layers.\"\\n    ],\\n    \"reference\": [\\n        \"COVID-19 symptoms commonly include fever, dry cough, fatigue, loss of taste or smell, body aches, sore throat, and in severe cases, difficulty breathing.\",\\n        \"Machine learning is a branch of AI where systems learn from data, identify patterns, and make decisions with minimal human intervention. Deep learning is a subset of machine learning that uses neural networks with multiple layers (deep neural networks) to analyze various factors of data.\"\\n    ]\\n}',\n",
              " 'eval_data = pd.DataFrame(data)\\n\\n# Convert to a format Ragas can use\\nevaluation_dataset = EvaluationDataset.from_pandas(eval_data)\\nevaluation_dataset\\n\\n```\\n\\n## Step 3: Selecting and Configuring Metrics\\n\\nRagas offers various metrics to evaluate different aspects of your system:\\n\\n### Core RAG Metrics:\\n\\n- **Faithfulness**: Measures if the response is factually consistent with the provided context.\\n- **Factual Correctness**: Assesses if the response is accurate and free from factual errors.\\n- **Response Relevancy**: Evaluates if the response directly addresses the user query.\\n- **Context Entity Recall**: Measures how well the retrieved context captures relevant entities from the ground truth.\\n- **Noise Sensitivity**: Assesses the robustness of the response to irrelevant or noisy context.\\n- **LLM Context Recall**: Evaluates how effectively the LLM utilizes the provided context to generate the response.',\n",
              " 'eval_data = pd.DataFrame(data)\\n\\n# Convert to a format Ragas can use\\nevaluation_dataset = EvaluationDataset.from_pandas(eval_data)\\nevaluation_dataset\\n\\n```\\n\\n## Step 3: Selecting and Configuring Metrics\\n\\nRagas offers various metrics to evaluate different aspects of your system:\\n\\n### Core RAG Metrics:\\n\\n- **Faithfulness**: Measures if the response is factually consistent with the provided context.\\n- **Factual Correctness**: Assesses if the response is accurate and free from factual errors.\\n- **Response Relevancy**: Evaluates if the response directly addresses the user query.\\n- **Context Entity Recall**: Measures how well the retrieved context captures relevant entities from the ground truth.\\n- **Noise Sensitivity**: Assesses the robustness of the response to irrelevant or noisy context.\\n- **LLM Context Recall**: Evaluates how effectively the LLM utilizes the provided context to generate the response.',\n",
              " 'For metrics that require an LLM (like faithfulness), you need to configure the LLM provider:\\n\\n```python\\n# Configure LLM for evaluation\\nfrom langchain_openai import ChatOpenAI\\nfrom ragas.llms import LangchainLLMWrapper\\n\\n# Initialize the LLM, you are going to OPENAI API key\\nevaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\")) \\n\\n# Define metrics to use\\nmetrics = [\\n    Faithfulness(), \\n    FactualCorrectness(),\\n    ResponseRelevancy(), \\n    ContextEntityRecall(), \\n    NoiseSensitivity(),\\n    LLMContextRecall()\\n]\\n```\\n\\n## Step 4: Running the Evaluation\\n\\nNow, run the evaluation with your selected metrics:\\n\\n```python\\n# Run evaluation\\nresults = evaluate(\\n    evaluation_dataset,\\n    metrics=metrics,\\n    llm=evaluator_llm  # Required for LLM-based metrics\\n)\\n\\n# View results\\nprint(results)\\n```\\n### Output:\\n\\n*Values will vary based on your data and LLM performance.*',\n",
              " 'For metrics that require an LLM (like faithfulness), you need to configure the LLM provider:\\n\\n```python\\n# Configure LLM for evaluation\\nfrom langchain_openai import ChatOpenAI\\nfrom ragas.llms import LangchainLLMWrapper\\n\\n# Initialize the LLM, you are going to OPENAI API key\\nevaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\")) \\n\\n# Define metrics to use\\nmetrics = [\\n    Faithfulness(), \\n    FactualCorrectness(),\\n    ResponseRelevancy(), \\n    ContextEntityRecall(), \\n    NoiseSensitivity(),\\n    LLMContextRecall()\\n]\\n```\\n\\n## Step 4: Running the Evaluation\\n\\nNow, run the evaluation with your selected metrics:\\n\\n```python\\n# Run evaluation\\nresults = evaluate(\\n    evaluation_dataset,\\n    metrics=metrics,\\n    llm=evaluator_llm  # Required for LLM-based metrics\\n)\\n\\n# View results\\nprint(results)\\n```\\n### Output:\\n\\n*Values will vary based on your data and LLM performance.*',\n",
              " '# View results\\nprint(results)\\n```\\n### Output:\\n\\n*Values will vary based on your data and LLM performance.*\\n\\n```python\\n{\\n    \"faithfulness\": 1.0000,\\n    \"factual_correctness\": 0.6750,\\n    \"answer_relevancy\": 0.9897,\\n    \"context_entity_recall\": 0.8889,\\n    \"noise_sensitivity_relevant\": 0.1667,\\n    \"context_recall\": 0.5000\\n}\\n```\\n\\n\\n## Step 5: Interpreting Results\\n\\nRagas metrics typically return scores between 0 and 1, where higher is better:\\n\\n### Understanding Score Ranges:\\n\\n- **0.8-1.0**: Excellent performance\\n- **0.6-0.8**: Good performance\\n- **0.4-0.6**: Moderate performance, needs improvement\\n- **0.4 or lower**: Poor performance, requires significant attention\\n\\n## Advanced Use: Custom Evaluation for Specific Examples\\n\\nFor more detailed analysis of specific examples:\\n\\n```python\\nfrom ragas import SingleTurnSample\\nfrom ragas.metrics import AspectCritic',\n",
              " '# View results\\nprint(results)\\n```\\n### Output:\\n\\n*Values will vary based on your data and LLM performance.*\\n\\n```python\\n{\\n    \"faithfulness\": 1.0000,\\n    \"factual_correctness\": 0.6750,\\n    \"answer_relevancy\": 0.9897,\\n    \"context_entity_recall\": 0.8889,\\n    \"noise_sensitivity_relevant\": 0.1667,\\n    \"context_recall\": 0.5000\\n}\\n```\\n\\n\\n## Step 5: Interpreting Results\\n\\nRagas metrics typically return scores between 0 and 1, where higher is better:\\n\\n### Understanding Score Ranges:\\n\\n- **0.8-1.0**: Excellent performance\\n- **0.6-0.8**: Good performance\\n- **0.4-0.6**: Moderate performance, needs improvement\\n- **0.4 or lower**: Poor performance, requires significant attention\\n\\n## Advanced Use: Custom Evaluation for Specific Examples\\n\\nFor more detailed analysis of specific examples:\\n\\n```python\\nfrom ragas import SingleTurnSample\\nfrom ragas.metrics import AspectCritic',\n",
              " '## Advanced Use: Custom Evaluation for Specific Examples\\n\\nFor more detailed analysis of specific examples:\\n\\n```python\\nfrom ragas import SingleTurnSample\\nfrom ragas.metrics import AspectCritic\\n\\n# Define a specific test case\\ntest_data = {\\n    \"user_input\": \"What are quantum computers?\",\\n    \"response\": \"Quantum computers use quantum bits or qubits that can exist in multiple states simultaneously, unlike classical bits that can only be 0 or 1.\",\\n    \"retrieved_contexts\": [\"Quantum computing is a type of computation that harnesses quantum mechanical phenomena.\"]\\n}\\n\\n# Create a custom evaluation metric\\ncustom_metric = AspectCritic(\\n    name=\"quantum_accuracy\", \\n    llm=llm,\\n    definition=\"Verify if the explanation of quantum computing is accurate and complete.\"\\n)',\n",
              " '## Advanced Use: Custom Evaluation for Specific Examples\\n\\nFor more detailed analysis of specific examples:\\n\\n```python\\nfrom ragas import SingleTurnSample\\nfrom ragas.metrics import AspectCritic\\n\\n# Define a specific test case\\ntest_data = {\\n    \"user_input\": \"What are quantum computers?\",\\n    \"response\": \"Quantum computers use quantum bits or qubits that can exist in multiple states simultaneously, unlike classical bits that can only be 0 or 1.\",\\n    \"retrieved_contexts\": [\"Quantum computing is a type of computation that harnesses quantum mechanical phenomena.\"]\\n}\\n\\n# Create a custom evaluation metric\\ncustom_metric = AspectCritic(\\n    name=\"quantum_accuracy\", \\n    llm=llm,\\n    definition=\"Verify if the explanation of quantum computing is accurate and complete.\"\\n)',\n",
              " '# Score the sample\\nsample = SingleTurnSample(**test_data)\\nscore = await custom_metric.single_turn_ascore(sample)\\nprint(f\"Quantum accuracy score: {score}\")\\n```\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for this workflow:  \\n> [02_Basic_Evaluation_Workflow_with_Ragas](https://github.com/mafzaal/intro-to-ragas/blob/master/02_Basic_Evaluation_Workflow_with_Ragas.ipynb)\\n\\n## Common Evaluation Patterns and Metrics\\n\\nBelow is a matrix mapping evaluation patterns to the metrics used, along with definitions for each metric:',\n",
              " '# Score the sample\\nsample = SingleTurnSample(**test_data)\\nscore = await custom_metric.single_turn_ascore(sample)\\nprint(f\"Quantum accuracy score: {score}\")\\n```\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for this workflow:  \\n> [02_Basic_Evaluation_Workflow_with_Ragas](https://github.com/mafzaal/intro-to-ragas/blob/master/02_Basic_Evaluation_Workflow_with_Ragas.ipynb)\\n\\n## Common Evaluation Patterns and Metrics\\n\\nBelow is a matrix mapping evaluation patterns to the metrics used, along with definitions for each metric:',\n",
              " '| **Metric**                  | **Comprehensive RAG Evaluation** | **Content Quality Evaluation** | **Retrieval Quality Evaluation** |\\n|-----------------------------|----------------------------------|---------------------------------|-----------------------------------|\\n| **Faithfulness**            | ✓                                 | ✓                               |                                   |\\n| **Answer Relevancy**        | ✓                                 | ✓                               |                                   |\\n| **Context Recall**          | ✓                                 |                                 | ✓                                 |\\n| **Context Precision**       | ✓                                 |                                 | ✓                                 |\\n| **Harmfulness**             |                                   | ✓                               |                                   |',\n",
              " '| **Metric**                  | **Comprehensive RAG Evaluation** | **Content Quality Evaluation** | **Retrieval Quality Evaluation** |\\n|-----------------------------|----------------------------------|---------------------------------|-----------------------------------|\\n| **Faithfulness**            | ✓                                 | ✓                               |                                   |\\n| **Answer Relevancy**        | ✓                                 | ✓                               |                                   |\\n| **Context Recall**          | ✓                                 |                                 | ✓                                 |\\n| **Context Precision**       | ✓                                 |                                 | ✓                                 |\\n| **Harmfulness**             |                                   | ✓                               |                                   |',\n",
              " '| **Harmfulness**             |                                   | ✓                               |                                   |\\n| **Coherence**               |                                   | ✓                               |                                   |\\n| **Context Relevancy**       |                                   |                                 | ✓                                 |',\n",
              " '| **Harmfulness**             |                                   | ✓                               |                                   |\\n| **Coherence**               |                                   | ✓                               |                                   |\\n| **Context Relevancy**       |                                   |                                 | ✓                                 |',\n",
              " '### Metric Definitions\\n\\n- **Faithfulness**: Measures if the response is factually consistent with the provided context.\\n- **Answer Relevancy**: Assesses if the response addresses the question.\\n- **Context Recall**: Measures how well the retrieved context covers the information in the ground truth.\\n- **Context Precision**: Evaluates the proportion of relevant information in the retrieved context.\\n- **Harmfulness**: Evaluates if the response contains harmful or inappropriate content.\\n- **Coherence**: Measures the logical flow and clarity of the response.\\n- **Context Relevancy**: Evaluates if the retrieved context is relevant to the question.\\n\\nThis matrix provides a clear overview of which metrics to use for specific evaluation patterns and their respective definitions.\\n\\n## Best Practices for Ragas Evaluation',\n",
              " '### Metric Definitions\\n\\n- **Faithfulness**: Measures if the response is factually consistent with the provided context.\\n- **Answer Relevancy**: Assesses if the response addresses the question.\\n- **Context Recall**: Measures how well the retrieved context covers the information in the ground truth.\\n- **Context Precision**: Evaluates the proportion of relevant information in the retrieved context.\\n- **Harmfulness**: Evaluates if the response contains harmful or inappropriate content.\\n- **Coherence**: Measures the logical flow and clarity of the response.\\n- **Context Relevancy**: Evaluates if the retrieved context is relevant to the question.\\n\\nThis matrix provides a clear overview of which metrics to use for specific evaluation patterns and their respective definitions.\\n\\n## Best Practices for Ragas Evaluation',\n",
              " 'This matrix provides a clear overview of which metrics to use for specific evaluation patterns and their respective definitions.\\n\\n## Best Practices for Ragas Evaluation\\n\\n1. **Start simple**: Begin with core metrics before adding more specialized ones\\n2. **Use diverse test cases**: Include a variety of questions, from simple to complex\\n3. **Consider edge cases**: Test with queries that might challenge your system\\n4. **Compare versions**: Track metrics across different versions of your application\\n5. **Combine with human evaluation**: Use Ragas alongside human feedback for a comprehensive assessment\\n\\n## Conclusion\\n\\nSetting up a basic evaluation workflow with Ragas is straightforward yet powerful. By systematically evaluating your LLM applications, you gain objective insights into their performance and clear directions for improvement.',\n",
              " 'This matrix provides a clear overview of which metrics to use for specific evaluation patterns and their respective definitions.\\n\\n## Best Practices for Ragas Evaluation\\n\\n1. **Start simple**: Begin with core metrics before adding more specialized ones\\n2. **Use diverse test cases**: Include a variety of questions, from simple to complex\\n3. **Consider edge cases**: Test with queries that might challenge your system\\n4. **Compare versions**: Track metrics across different versions of your application\\n5. **Combine with human evaluation**: Use Ragas alongside human feedback for a comprehensive assessment\\n\\n## Conclusion\\n\\nSetting up a basic evaluation workflow with Ragas is straightforward yet powerful. By systematically evaluating your LLM applications, you gain objective insights into their performance and clear directions for improvement.',\n",
              " \"In our next post, we'll delve deeper into specialized evaluation techniques for RAG systems, exploring advanced metrics and evaluation strategies for retrieval-augmented generation applications.\\n\\n---\\n \\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**Part 2: Basic Evaluation Workflow — _You are here_**  \\n*Next up in the series:*  \\n**[Part 3: Evaluating RAG Systems](/blog/evaluating-rag-systems-with-ragas/)**  \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Evaluation Techniques](/blog/advanced-metrics-and-customization-with-ragas)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " \"In our next post, we'll delve deeper into specialized evaluation techniques for RAG systems, exploring advanced metrics and evaluation strategies for retrieval-augmented generation applications.\\n\\n---\\n \\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**Part 2: Basic Evaluation Workflow — _You are here_**  \\n*Next up in the series:*  \\n**[Part 3: Evaluating RAG Systems](/blog/evaluating-rag-systems-with-ragas/)**  \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Evaluation Techniques](/blog/advanced-metrics-and-customization-with-ragas)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " '*Have you set up your first Ragas evaluation? What aspects of your LLM application are you most interested in measuring? If you’re facing specific evaluation hurdles, don’t hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we’d love to help!*',\n",
              " '*Have you set up your first Ragas evaluation? What aspects of your LLM application are you most interested in measuring? If you’re facing specific evaluation hurdles, don’t hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we’d love to help!*',\n",
              " '---\\nlayout: blog\\ntitle: A C# Programmer\\'s Perspective on LangChain Expression Language\\ndate: 2025-04-16T00:00:00-06:00\\ndescription: My experiences transitioning from C# to LangChain Expression Language, exploring the pipe operator abstraction challenges and the surprising simplicity of parallel execution.\\ncategories: [\"Technology\", \"AI\", \"Programming\"]\\ncoverImage: \"https://images.unsplash.com/photo-1555066931-4365d14bab8c?q=80&w=1770&auto=format&fit=crop&ixlib=rb-4.0.3\"\\nreadingTime: 3\\npublished: true\\n---\\n\\n\\nAs a C# developer diving into [LangChain Expression Language (LCEL)](https://langchain-ai.github.io/langgraph/), I\\'ve encountered both challenges and pleasant surprises. Here\\'s what stood out most during my transition.\\n\\n## The Pipe Operator Abstraction Challenge\\n\\nIn C#, processing pipelines are explicit:\\n\\n```csharp\\nvar result = inputData\\n    .Where(item => item.IsValid)\\n    .Select(item => TransformItem(item))\\n    .ToList()\\n    .ForEach(item => ProcessItem(item));\\n```',\n",
              " '---\\nlayout: blog\\ntitle: A C# Programmer\\'s Perspective on LangChain Expression Language\\ndate: 2025-04-16T00:00:00-06:00\\ndescription: My experiences transitioning from C# to LangChain Expression Language, exploring the pipe operator abstraction challenges and the surprising simplicity of parallel execution.\\ncategories: [\"Technology\", \"AI\", \"Programming\"]\\ncoverImage: \"https://images.unsplash.com/photo-1555066931-4365d14bab8c?q=80&w=1770&auto=format&fit=crop&ixlib=rb-4.0.3\"\\nreadingTime: 3\\npublished: true\\n---\\n\\n\\nAs a C# developer diving into [LangChain Expression Language (LCEL)](https://langchain-ai.github.io/langgraph/), I\\'ve encountered both challenges and pleasant surprises. Here\\'s what stood out most during my transition.\\n\\n## The Pipe Operator Abstraction Challenge\\n\\nIn C#, processing pipelines are explicit:\\n\\n```csharp\\nvar result = inputData\\n    .Where(item => item.IsValid)\\n    .Select(item => TransformItem(item))\\n    .ToList()\\n    .ForEach(item => ProcessItem(item));\\n```',\n",
              " '```csharp\\nvar result = inputData\\n    .Where(item => item.IsValid)\\n    .Select(item => TransformItem(item))\\n    .ToList()\\n    .ForEach(item => ProcessItem(item));\\n```\\n\\nLCEL\\'s pipe operator creates a different flow:\\n\\n```python\\nchain = (\\n    ChatPromptTemplate.from_messages([\\n        (\"system\", \"You are a helpful assistant specialized in {topic}.\"),\\n        (\"human\", \"{query}\")\\n    ])\\n    | ChatOpenAI(temperature=0.7)\\n    | (lambda llm_result: llm_result.content)\\n    | (lambda content: content.split(\"\\\\n\"))\\n    | (lambda lines: [line for line in lines if line.strip()])\\n    | (lambda filtered_lines: \"\\\\n\".join(filtered_lines))\\n)\\n```\\n\\nWith complex chains, questions arise:\\n- What exactly passes through each step?\\n- How can I inspect intermediate results?\\n- How do I debug unexpected outcomes?\\n\\nThis becomes more apparent in real-world examples:',\n",
              " '```csharp\\nvar result = inputData\\n    .Where(item => item.IsValid)\\n    .Select(item => TransformItem(item))\\n    .ToList()\\n    .ForEach(item => ProcessItem(item));\\n```\\n\\nLCEL\\'s pipe operator creates a different flow:\\n\\n```python\\nchain = (\\n    ChatPromptTemplate.from_messages([\\n        (\"system\", \"You are a helpful assistant specialized in {topic}.\"),\\n        (\"human\", \"{query}\")\\n    ])\\n    | ChatOpenAI(temperature=0.7)\\n    | (lambda llm_result: llm_result.content)\\n    | (lambda content: content.split(\"\\\\n\"))\\n    | (lambda lines: [line for line in lines if line.strip()])\\n    | (lambda filtered_lines: \"\\\\n\".join(filtered_lines))\\n)\\n```\\n\\nWith complex chains, questions arise:\\n- What exactly passes through each step?\\n- How can I inspect intermediate results?\\n- How do I debug unexpected outcomes?\\n\\nThis becomes more apparent in real-world examples:',\n",
              " 'This becomes more apparent in real-world examples:\\n\\n```python\\nretrieval_chain = (\\n    {\"query\": RunnablePassthrough(), \"context\": retriever | format_docs}\\n    | prompt\\n    | llm\\n    | StrOutputParser()\\n)\\n```\\n\\n## Surprisingly Simple Parallel Execution\\n\\nDespite abstraction challenges, LCEL handles parallel execution elegantly.\\n\\nIn C#:\\n```csharp\\nvar task1 = Task.Run(() => ProcessData(data1));\\nvar task2 = Task.Run(() => ProcessData(data2));\\nvar task3 = Task.Run(() => ProcessData(data3));\\n\\nawait Task.WhenAll(task1, task2, task3);\\nvar results = new[] { task1.Result, task2.Result, task3.Result };\\n```\\n\\nIn LCEL:\\n```python\\nparallel_chain = RunnableMap({\\n    \"summary\": prompt_summary | llm | StrOutputParser(),\\n    \"translation\": prompt_translate | llm | StrOutputParser(),\\n    \"analysis\": prompt_analyze | llm | StrOutputParser()\\n})\\n\\nresult = parallel_chain.invoke({\"input\": user_query})\\n```\\n\\nThis approach eliminates manual task management, handling everything behind the scenes.',\n",
              " 'This becomes more apparent in real-world examples:\\n\\n```python\\nretrieval_chain = (\\n    {\"query\": RunnablePassthrough(), \"context\": retriever | format_docs}\\n    | prompt\\n    | llm\\n    | StrOutputParser()\\n)\\n```\\n\\n## Surprisingly Simple Parallel Execution\\n\\nDespite abstraction challenges, LCEL handles parallel execution elegantly.\\n\\nIn C#:\\n```csharp\\nvar task1 = Task.Run(() => ProcessData(data1));\\nvar task2 = Task.Run(() => ProcessData(data2));\\nvar task3 = Task.Run(() => ProcessData(data3));\\n\\nawait Task.WhenAll(task1, task2, task3);\\nvar results = new[] { task1.Result, task2.Result, task3.Result };\\n```\\n\\nIn LCEL:\\n```python\\nparallel_chain = RunnableMap({\\n    \"summary\": prompt_summary | llm | StrOutputParser(),\\n    \"translation\": prompt_translate | llm | StrOutputParser(),\\n    \"analysis\": prompt_analyze | llm | StrOutputParser()\\n})\\n\\nresult = parallel_chain.invoke({\"input\": user_query})\\n```\\n\\nThis approach eliminates manual task management, handling everything behind the scenes.',\n",
              " 'result = parallel_chain.invoke({\"input\": user_query})\\n```\\n\\nThis approach eliminates manual task management, handling everything behind the scenes.\\n\\n## Best Practices I\\'ve Adopted\\n\\nTo balance LCEL\\'s expressiveness with clarity:\\n\\n1. Break complex chains into named subcomponents\\n2. Comment non-obvious transformations\\n3. Create visualization helpers for debugging\\n4. Embrace functional thinking\\n\\n## Conclusion\\n\\nFor C# developers exploring LCEL, approach it with an open mind. The initial learning curve is worth it, especially for AI workflows where LCEL\\'s parallel execution shines.\\n\\nWant to see these concepts in practice? Check out my [Pythonic RAG repository](https://github.com/mafzaal/AIE6-DeployPythonicRAG) for working examples.\\n\\n---\\n\\n*If you found this useful or have questions about transitioning from C# to LCEL, feel free to [reach out](https://www.linkedin.com/in/muhammadafzaal/) — we’d love to help!*',\n",
              " 'result = parallel_chain.invoke({\"input\": user_query})\\n```\\n\\nThis approach eliminates manual task management, handling everything behind the scenes.\\n\\n## Best Practices I\\'ve Adopted\\n\\nTo balance LCEL\\'s expressiveness with clarity:\\n\\n1. Break complex chains into named subcomponents\\n2. Comment non-obvious transformations\\n3. Create visualization helpers for debugging\\n4. Embrace functional thinking\\n\\n## Conclusion\\n\\nFor C# developers exploring LCEL, approach it with an open mind. The initial learning curve is worth it, especially for AI workflows where LCEL\\'s parallel execution shines.\\n\\nWant to see these concepts in practice? Check out my [Pythonic RAG repository](https://github.com/mafzaal/AIE6-DeployPythonicRAG) for working examples.\\n\\n---\\n\\n*If you found this useful or have questions about transitioning from C# to LCEL, feel free to [reach out](https://www.linkedin.com/in/muhammadafzaal/) — we’d love to help!*',\n",
              " '---\\ntitle: \"Part 6: Evaluating AI Agents: Beyond Simple Answers with Ragas\"\\ndate: 2025-04-28T06:00:00-06:00\\nlayout: blog\\ndescription: \"Learn how to evaluate complex AI agents using Ragas\\' specialized metrics for goal accuracy, tool call accuracy, and topic adherence to build more reliable and effective agent-based applications.\"\\ncategories: [\"AI\", \"Agents\", \"Evaluation\", \"Ragas\", \"LLM\"]\\ncoverImage: \"/images/ai_agent_evaluation.png\"   \\nreadingTime: 8\\npublished: true\\n---\\n\\nIn our previous posts, we\\'ve explored how Ragas evaluates RAG systems and enables custom metrics for specialized applications. As LLMs evolve beyond simple question-answering to become powerful AI agents, evaluation needs have grown more sophisticated too. In this post, we\\'ll explore Ragas\\' specialized metrics for evaluating AI agents that engage in multi-turn interactions, use tools, and work toward specific goals.\\n\\n## The Challenge of Evaluating AI Agents',\n",
              " '---\\ntitle: \"Part 6: Evaluating AI Agents: Beyond Simple Answers with Ragas\"\\ndate: 2025-04-28T06:00:00-06:00\\nlayout: blog\\ndescription: \"Learn how to evaluate complex AI agents using Ragas\\' specialized metrics for goal accuracy, tool call accuracy, and topic adherence to build more reliable and effective agent-based applications.\"\\ncategories: [\"AI\", \"Agents\", \"Evaluation\", \"Ragas\", \"LLM\"]\\ncoverImage: \"/images/ai_agent_evaluation.png\"   \\nreadingTime: 8\\npublished: true\\n---\\n\\nIn our previous posts, we\\'ve explored how Ragas evaluates RAG systems and enables custom metrics for specialized applications. As LLMs evolve beyond simple question-answering to become powerful AI agents, evaluation needs have grown more sophisticated too. In this post, we\\'ll explore Ragas\\' specialized metrics for evaluating AI agents that engage in multi-turn interactions, use tools, and work toward specific goals.\\n\\n## The Challenge of Evaluating AI Agents',\n",
              " \"## The Challenge of Evaluating AI Agents\\n\\nUnlike traditional RAG systems, AI agents present unique evaluation challenges:\\n\\n- **Multi-turn interactions**: Agents maintain context across multiple exchanges\\n- **Tool usage**: Agents call external tools and APIs to accomplish tasks\\n- **Goal-oriented behavior**: Success means achieving the user's ultimate objective\\n- **Boundaries and constraints**: Agents must operate within defined topic boundaries\\n\\nStandard metrics like faithfulness or answer relevancy don't fully capture these dimensions. Let's explore three specialized metrics Ragas provides for agent evaluation.\\n\\n## Evaluating AI Agents: Beyond Simple Answers with Ragas\\n\\n### 1. Goal Accuracy (`agent_goal_accuracy`)\\n\\n**What it measures:** Did the agent successfully achieve the user's ultimate objective over the course of the interaction?\",\n",
              " \"## The Challenge of Evaluating AI Agents\\n\\nUnlike traditional RAG systems, AI agents present unique evaluation challenges:\\n\\n- **Multi-turn interactions**: Agents maintain context across multiple exchanges\\n- **Tool usage**: Agents call external tools and APIs to accomplish tasks\\n- **Goal-oriented behavior**: Success means achieving the user's ultimate objective\\n- **Boundaries and constraints**: Agents must operate within defined topic boundaries\\n\\nStandard metrics like faithfulness or answer relevancy don't fully capture these dimensions. Let's explore three specialized metrics Ragas provides for agent evaluation.\\n\\n## Evaluating AI Agents: Beyond Simple Answers with Ragas\\n\\n### 1. Goal Accuracy (`agent_goal_accuracy`)\\n\\n**What it measures:** Did the agent successfully achieve the user's ultimate objective over the course of the interaction?\",\n",
              " \"### 1. Goal Accuracy (`agent_goal_accuracy`)\\n\\n**What it measures:** Did the agent successfully achieve the user's ultimate objective over the course of the interaction?\\n\\n**How it works:**\\nThis metric analyzes the entire agent workflow (user inputs, AI responses, tool calls).\\n*   It uses an LLM (`InferGoalOutcomePrompt`) to identify the `user_goal` and the `end_state` (what actually happened).\\n*   It then compares the `end_state` to either:\\n    *   A provided `reference` outcome (**`AgentGoalAccuracyWithReference`**).\\n    *   The inferred `user_goal` (**`AgentGoalAccuracyWithoutReference`**).\\n*   An LLM (`CompareOutcomePrompt`) determines if the achieved outcome matches the desired one, resulting in a binary score (1 for success, 0 for failure).\\n\\n**Why it's important:** For task-oriented agents (like booking systems or assistants), success isn't about individual responses but about completing the overall task correctly. This metric directly measures that end-to-end success.\",\n",
              " \"### 1. Goal Accuracy (`agent_goal_accuracy`)\\n\\n**What it measures:** Did the agent successfully achieve the user's ultimate objective over the course of the interaction?\\n\\n**How it works:**\\nThis metric analyzes the entire agent workflow (user inputs, AI responses, tool calls).\\n*   It uses an LLM (`InferGoalOutcomePrompt`) to identify the `user_goal` and the `end_state` (what actually happened).\\n*   It then compares the `end_state` to either:\\n    *   A provided `reference` outcome (**`AgentGoalAccuracyWithReference`**).\\n    *   The inferred `user_goal` (**`AgentGoalAccuracyWithoutReference`**).\\n*   An LLM (`CompareOutcomePrompt`) determines if the achieved outcome matches the desired one, resulting in a binary score (1 for success, 0 for failure).\\n\\n**Why it's important:** For task-oriented agents (like booking systems or assistants), success isn't about individual responses but about completing the overall task correctly. This metric directly measures that end-to-end success.\",\n",
              " \"### 2. Tool Call Accuracy (`tool_call_accuracy`)\\n\\n**What it measures:** Did the agent use the correct tools, in the right order, and with the right arguments?\\n\\n**How it works:**\\nThis metric compares the sequence and details of tool calls made by the agent against a `reference_tool_calls` list.\\n*   It checks if the *sequence* of tool names called by the agent aligns with the reference sequence (`is_sequence_aligned`).\\n*   For each matching tool call, it compares the arguments provided by the agent to the reference arguments, often using a sub-metric like `ExactMatch` (`_get_arg_score`).\\n*   The final score reflects both the sequence alignment and the argument correctness.\\n\\n**Why it's important:** Many agents rely on external tools (APIs, databases, etc.). Incorrect tool usage (wrong tool, bad parameters) leads to task failure. This metric pinpoints issues in the agent's interaction with its tools.\\n\\n### 3. Topic Adherence (`topic_adherence`)\",\n",
              " \"### 2. Tool Call Accuracy (`tool_call_accuracy`)\\n\\n**What it measures:** Did the agent use the correct tools, in the right order, and with the right arguments?\\n\\n**How it works:**\\nThis metric compares the sequence and details of tool calls made by the agent against a `reference_tool_calls` list.\\n*   It checks if the *sequence* of tool names called by the agent aligns with the reference sequence (`is_sequence_aligned`).\\n*   For each matching tool call, it compares the arguments provided by the agent to the reference arguments, often using a sub-metric like `ExactMatch` (`_get_arg_score`).\\n*   The final score reflects both the sequence alignment and the argument correctness.\\n\\n**Why it's important:** Many agents rely on external tools (APIs, databases, etc.). Incorrect tool usage (wrong tool, bad parameters) leads to task failure. This metric pinpoints issues in the agent's interaction with its tools.\\n\\n### 3. Topic Adherence (`topic_adherence`)\",\n",
              " \"### 3. Topic Adherence (`topic_adherence`)\\n\\n**What it measures:** Did the agent stick to the allowed topics and appropriately handle requests about restricted topics?\\n\\n**How it works:**\\nThis metric evaluates conversations against a list of `reference_topics`.\\n*   It extracts the topics discussed in the user's input (`TopicExtractionPrompt`).\\n*   It checks if the agent refused to answer questions related to specific topics (`TopicRefusedPrompt`).\\n*   It classifies whether the discussed topics fall within the allowed `reference_topics` (`TopicClassificationPrompt`).\\n*   Based on these classifications and refusals, it calculates a score (Precision, Recall, or F1) indicating how well the agent adhered to the topic constraints.\\n\\n**Why it's important:** Ensures agents stay focused, avoid generating content on forbidden subjects (safety, policy), and handle out-of-scope requests gracefully.\\n\\n## Implementing Agent Evaluation in Practice\",\n",
              " \"### 3. Topic Adherence (`topic_adherence`)\\n\\n**What it measures:** Did the agent stick to the allowed topics and appropriately handle requests about restricted topics?\\n\\n**How it works:**\\nThis metric evaluates conversations against a list of `reference_topics`.\\n*   It extracts the topics discussed in the user's input (`TopicExtractionPrompt`).\\n*   It checks if the agent refused to answer questions related to specific topics (`TopicRefusedPrompt`).\\n*   It classifies whether the discussed topics fall within the allowed `reference_topics` (`TopicClassificationPrompt`).\\n*   Based on these classifications and refusals, it calculates a score (Precision, Recall, or F1) indicating how well the agent adhered to the topic constraints.\\n\\n**Why it's important:** Ensures agents stay focused, avoid generating content on forbidden subjects (safety, policy), and handle out-of-scope requests gracefully.\\n\\n## Implementing Agent Evaluation in Practice\",\n",
              " '## Implementing Agent Evaluation in Practice\\n\\nLet\\'s look at a practical example of evaluating an AI agent using these metrics:\\n\\n```python\\nfrom ragas.metrics import AgentGoalAccuracyWithoutReference, ToolCallAccuracy, TopicAdherenceScore\\nfrom ragas.evaluation import EvaluationDataset\\nfrom ragas.dataset_schema import MultiTurnSample\\nfrom langchain_openai import ChatOpenAI\\nfrom ragas.llms import LangchainLLMWrapper\\n\\n# Initialize the LLM\\nevaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))',\n",
              " '## Implementing Agent Evaluation in Practice\\n\\nLet\\'s look at a practical example of evaluating an AI agent using these metrics:\\n\\n```python\\nfrom ragas.metrics import AgentGoalAccuracyWithoutReference, ToolCallAccuracy, TopicAdherenceScore\\nfrom ragas.evaluation import EvaluationDataset\\nfrom ragas.dataset_schema import MultiTurnSample\\nfrom langchain_openai import ChatOpenAI\\nfrom ragas.llms import LangchainLLMWrapper\\n\\n# Initialize the LLM\\nevaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))',\n",
              " '# Example conversation with a travel booking agent\\ntest_data = {\\n    \"user_input\": [\\n        {\"role\": \"user\", \"content\": \"I need to book a flight from New York to London next Friday\"},\\n        {\"role\": \"assistant\", \"content\": \"I\\'d be happy to help you book a flight. Let me search for options...\", \\n         \"tool_calls\": [{\"name\": \"search_flights\", \"arguments\": {\"origin\": \"NYC\", \"destination\": \"LON\", \"date\": \"next Friday\"}}]},\\n        {\"role\": \"tool\", \"name\": \"search_flights\", \"content\": \"Found 5 flights: Flight 1 (Delta, $750), Flight 2 (British Airways, $820)...\"},\\n        {\"role\": \"assistant\", \"content\": \"I found several flights from New York to London next Friday. The cheapest option is Delta for $750. Would you like to book this one?\"},\\n        {\"role\": \"user\", \"content\": \"Yes, please book the Delta flight\"},\\n        {\"role\": \"assistant\", \"content\": \"I\\'ll book that for you now.\",',\n",
              " '# Example conversation with a travel booking agent\\ntest_data = {\\n    \"user_input\": [\\n        {\"role\": \"user\", \"content\": \"I need to book a flight from New York to London next Friday\"},\\n        {\"role\": \"assistant\", \"content\": \"I\\'d be happy to help you book a flight. Let me search for options...\", \\n         \"tool_calls\": [{\"name\": \"search_flights\", \"arguments\": {\"origin\": \"NYC\", \"destination\": \"LON\", \"date\": \"next Friday\"}}]},\\n        {\"role\": \"tool\", \"name\": \"search_flights\", \"content\": \"Found 5 flights: Flight 1 (Delta, $750), Flight 2 (British Airways, $820)...\"},\\n        {\"role\": \"assistant\", \"content\": \"I found several flights from New York to London next Friday. The cheapest option is Delta for $750. Would you like to book this one?\"},\\n        {\"role\": \"user\", \"content\": \"Yes, please book the Delta flight\"},\\n        {\"role\": \"assistant\", \"content\": \"I\\'ll book that for you now.\",',\n",
              " '{\"role\": \"user\", \"content\": \"Yes, please book the Delta flight\"},\\n        {\"role\": \"assistant\", \"content\": \"I\\'ll book that for you now.\", \\n         \"tool_calls\": [{\"name\": \"book_flight\", \"arguments\": {\"flight_id\": \"delta_123\", \"price\": \"$750\"}}]},\\n        {\"role\": \"tool\", \"name\": \"book_flight\", \"content\": \"Booking confirmed. Confirmation #: ABC123\"},\\n        {\"role\": \"assistant\", \"content\": \"Great news! Your flight is confirmed. Your confirmation number is ABC123. The flight is scheduled for next Friday. Is there anything else you need help with?\"}\\n    ],\\n    \"reference_topics\": [\"travel\", \"flight booking\", \"schedules\", \"prices\"],\\n    \"reference_tool_calls\": [\\n        {\"name\": \"search_flights\", \"args\": {\"origin\": \"NYC\", \"destination\": \"LON\", \"date\": \"next Friday\"}},\\n        {\"name\": \"book_flight\", \"args\": {\"flight_id\": \"delta_123\", \"price\": \"$750\"}}\\n    ]\\n}',\n",
              " '{\"role\": \"user\", \"content\": \"Yes, please book the Delta flight\"},\\n        {\"role\": \"assistant\", \"content\": \"I\\'ll book that for you now.\", \\n         \"tool_calls\": [{\"name\": \"book_flight\", \"arguments\": {\"flight_id\": \"delta_123\", \"price\": \"$750\"}}]},\\n        {\"role\": \"tool\", \"name\": \"book_flight\", \"content\": \"Booking confirmed. Confirmation #: ABC123\"},\\n        {\"role\": \"assistant\", \"content\": \"Great news! Your flight is confirmed. Your confirmation number is ABC123. The flight is scheduled for next Friday. Is there anything else you need help with?\"}\\n    ],\\n    \"reference_topics\": [\"travel\", \"flight booking\", \"schedules\", \"prices\"],\\n    \"reference_tool_calls\": [\\n        {\"name\": \"search_flights\", \"args\": {\"origin\": \"NYC\", \"destination\": \"LON\", \"date\": \"next Friday\"}},\\n        {\"name\": \"book_flight\", \"args\": {\"flight_id\": \"delta_123\", \"price\": \"$750\"}}\\n    ]\\n}',\n",
              " '# Create a sample\\nsample = MultiTurnSample(**test_data)\\n\\n# Initialize metrics\\ngoal_accuracy = AgentGoalAccuracyWithoutReference(llm=evaluator_llm)\\ntool_accuracy = ToolCallAccuracy()\\ntopic_adherence = TopicAdherenceScore(llm=evaluator_llm)\\n\\n# Calculate scores\\ngoal_score = await goal_accuracy.multi_turn_ascore(sample)\\ntool_score = tool_accuracy.multi_turn_score(sample)\\ntopic_score = await topic_adherence.multi_turn_ascore(sample)\\n\\nprint(f\"Goal Accuracy: {goal_score}\")\\nprint(f\"Tool Call Accuracy: {tool_score}\")\\nprint(f\"Topic Adherence: {topic_score}\")\\n```\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for agent evaluation:  \\n> [06_Evaluating_AI_Agents](https://github.com/mafzaal/intro-to-ragas/blob/master/06_Evaluating_AI_Agents.ipynb)\\n\\n## Advanced Agent Evaluation Techniques\\n\\n### Combining Metrics for Comprehensive Evaluation\\n\\nFor a complete assessment of agent capabilities, combine multiple metrics:\\n\\n```python\\nfrom ragas import evaluate',\n",
              " '# Create a sample\\nsample = MultiTurnSample(**test_data)\\n\\n# Initialize metrics\\ngoal_accuracy = AgentGoalAccuracyWithoutReference(llm=evaluator_llm)\\ntool_accuracy = ToolCallAccuracy()\\ntopic_adherence = TopicAdherenceScore(llm=evaluator_llm)\\n\\n# Calculate scores\\ngoal_score = await goal_accuracy.multi_turn_ascore(sample)\\ntool_score = tool_accuracy.multi_turn_score(sample)\\ntopic_score = await topic_adherence.multi_turn_ascore(sample)\\n\\nprint(f\"Goal Accuracy: {goal_score}\")\\nprint(f\"Tool Call Accuracy: {tool_score}\")\\nprint(f\"Topic Adherence: {topic_score}\")\\n```\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for agent evaluation:  \\n> [06_Evaluating_AI_Agents](https://github.com/mafzaal/intro-to-ragas/blob/master/06_Evaluating_AI_Agents.ipynb)\\n\\n## Advanced Agent Evaluation Techniques\\n\\n### Combining Metrics for Comprehensive Evaluation\\n\\nFor a complete assessment of agent capabilities, combine multiple metrics:\\n\\n```python\\nfrom ragas import evaluate',\n",
              " '### Combining Metrics for Comprehensive Evaluation\\n\\nFor a complete assessment of agent capabilities, combine multiple metrics:\\n\\n```python\\nfrom ragas import evaluate\\n\\nresults = evaluate(\\n    dataset,  # Your dataset of agent conversations\\n    metrics=[\\n        AgentGoalAccuracyWithoutReference(llm=evaluator_llm),\\n        ToolCallAccuracy(),\\n        TopicAdherence(llm=evaluator_llm)\\n    ]\\n)\\n```\\n\\n## Best Practices for Agent Evaluation\\n\\n1. **Test scenario coverage:** Include a diverse range of interaction scenarios\\n2. **Edge case handling:** Test how agents handle unexpected inputs or failures\\n3. **Longitudinal evaluation:** Track performance over time to identify regressions\\n4. **Human-in-the-loop validation:** Periodically verify metric alignment with human judgments\\n5. **Continuous feedback loops:** Use evaluation insights to guide agent improvements\\n\\n## Conclusion',\n",
              " '### Combining Metrics for Comprehensive Evaluation\\n\\nFor a complete assessment of agent capabilities, combine multiple metrics:\\n\\n```python\\nfrom ragas import evaluate\\n\\nresults = evaluate(\\n    dataset,  # Your dataset of agent conversations\\n    metrics=[\\n        AgentGoalAccuracyWithoutReference(llm=evaluator_llm),\\n        ToolCallAccuracy(),\\n        TopicAdherence(llm=evaluator_llm)\\n    ]\\n)\\n```\\n\\n## Best Practices for Agent Evaluation\\n\\n1. **Test scenario coverage:** Include a diverse range of interaction scenarios\\n2. **Edge case handling:** Test how agents handle unexpected inputs or failures\\n3. **Longitudinal evaluation:** Track performance over time to identify regressions\\n4. **Human-in-the-loop validation:** Periodically verify metric alignment with human judgments\\n5. **Continuous feedback loops:** Use evaluation insights to guide agent improvements\\n\\n## Conclusion',\n",
              " \"## Conclusion\\n\\nEvaluating AI agents requires specialized metrics that go beyond traditional RAG evaluation. Ragas' `agent_goal_accuracy`, `tool_call_accuracy`, and `topic_adherence` provide crucial insights into whether an agent can successfully complete tasks, use tools correctly, and stay within designated boundaries.\\n\\nBy incorporating these metrics into your evaluation pipeline, you can build more reliable and effective AI agents that truly deliver on the promise of helpful, goal-oriented AI assistants.\\n\\nIn our next post, we'll explore how to integrate Ragas with popular frameworks and observability tools for seamless evaluation workflows.\",\n",
              " \"## Conclusion\\n\\nEvaluating AI agents requires specialized metrics that go beyond traditional RAG evaluation. Ragas' `agent_goal_accuracy`, `tool_call_accuracy`, and `topic_adherence` provide crucial insights into whether an agent can successfully complete tasks, use tools correctly, and stay within designated boundaries.\\n\\nBy incorporating these metrics into your evaluation pipeline, you can build more reliable and effective AI agents that truly deliver on the promise of helpful, goal-oriented AI assistants.\\n\\nIn our next post, we'll explore how to integrate Ragas with popular frameworks and observability tools for seamless evaluation workflows.\",\n",
              " \"In our next post, we'll explore how to integrate Ragas with popular frameworks and observability tools for seamless evaluation workflows.\\n\\n---\\n \\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**   \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Metrics and Customization](/blog/advanced-metrics-and-customization-with-ragas/)**  \\n**Part 6: Evaluating AI Agents — _You are here_**  \\n*Next up in the series:*  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " \"In our next post, we'll explore how to integrate Ragas with popular frameworks and observability tools for seamless evaluation workflows.\\n\\n---\\n \\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**   \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Metrics and Customization](/blog/advanced-metrics-and-customization-with-ragas/)**  \\n**Part 6: Evaluating AI Agents — _You are here_**  \\n*Next up in the series:*  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " \"*How are you evaluating your AI agents? What challenges have you encountered in measuring agent performance? If you're facing specific evaluation hurdles, don't hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we'd love to help!*\",\n",
              " \"*How are you evaluating your AI agents? What challenges have you encountered in measuring agent performance? If you're facing specific evaluation hurdles, don't hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we'd love to help!*\",\n",
              " '---\\ntitle: \"Part 7: Integrations and Observability with Ragas\"\\ndate: 2025-04-30T07:00:00-06:00\\nlayout: blog\\ndescription: \"Discover how to generate robust test datasets for evaluating Retrieval-Augmented Generation systems using Ragas, including document-based, domain-specific, and adversarial test generation techniques.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\",\"Data\"]\\ncoverImage: \"/images/integrations-and-observability.png\"\\nreadingTime: 12\\npublished: true\\n---\\n\\n# Part 6: Integrations and Observability with Ragas\\n\\nIn our previous post, we explored how to evaluate complex AI agents using Ragas\\' specialized metrics for goal accuracy, tool call accuracy, and topic adherence to build more reliable and effective agent-based applications. Now, let\\'s discuss how to integrate Ragas into your broader LLM development ecosystem and establish observability practices that transform evaluation from a one-time exercise into a continuous improvement cycle.',\n",
              " '---\\ntitle: \"Part 7: Integrations and Observability with Ragas\"\\ndate: 2025-04-30T07:00:00-06:00\\nlayout: blog\\ndescription: \"Discover how to generate robust test datasets for evaluating Retrieval-Augmented Generation systems using Ragas, including document-based, domain-specific, and adversarial test generation techniques.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\",\"Data\"]\\ncoverImage: \"/images/integrations-and-observability.png\"\\nreadingTime: 12\\npublished: true\\n---\\n\\n# Part 6: Integrations and Observability with Ragas\\n\\nIn our previous post, we explored how to evaluate complex AI agents using Ragas\\' specialized metrics for goal accuracy, tool call accuracy, and topic adherence to build more reliable and effective agent-based applications. Now, let\\'s discuss how to integrate Ragas into your broader LLM development ecosystem and establish observability practices that transform evaluation from a one-time exercise into a continuous improvement cycle.',\n",
              " \"## Why Integrations and Observability Matter\\n\\nEvaluation is most powerful when it's:\\n\\n- **Integrated** into your existing workflow and tools\\n- **Automated** to run consistently with minimal friction\\n- **Observable** so insights are easily accessible and actionable\\n- **Continuous** rather than a one-time or sporadic effort\\n\\nLet's explore how Ragas helps you achieve these goals through its extensive integration capabilities.\\n\\n## Framework Integrations\\n\\nRagas seamlessly connects with popular LLM application frameworks, allowing you to evaluate systems built with your preferred tools.\\n\\n### LangChain Integration\\nFor LangChain-based applications, Ragas provides dedicated integration support. Here’s how you can integrate Ragas step by step:\",\n",
              " \"## Why Integrations and Observability Matter\\n\\nEvaluation is most powerful when it's:\\n\\n- **Integrated** into your existing workflow and tools\\n- **Automated** to run consistently with minimal friction\\n- **Observable** so insights are easily accessible and actionable\\n- **Continuous** rather than a one-time or sporadic effort\\n\\nLet's explore how Ragas helps you achieve these goals through its extensive integration capabilities.\\n\\n## Framework Integrations\\n\\nRagas seamlessly connects with popular LLM application frameworks, allowing you to evaluate systems built with your preferred tools.\\n\\n### LangChain Integration\\nFor LangChain-based applications, Ragas provides dedicated integration support. Here’s how you can integrate Ragas step by step:\",\n",
              " '1. **Prepare your documents**: Load your source documents and split them into manageable chunks for retrieval.\\n2. **Set up vector storage**: Embed the document chunks and store them in a vector database to enable efficient retrieval.\\n3. **Configure the retriever and QA chain**: Use LangChain components to create a retriever and a question-answering (QA) chain powered by your chosen language model.\\n4. **Generate a test set**: Use Ragas to automatically generate a set of test questions and answers from your documents, or supply your own.\\n5. **Evaluate retrieval and QA performance**: Apply Ragas metrics to assess both the retriever and the full QA chain, measuring aspects like context relevancy, faithfulness, and answer quality.\\n6. **Review results**: Analyze the evaluation outputs to identify strengths and areas for improvement in your RAG pipeline.',\n",
              " '1. **Prepare your documents**: Load your source documents and split them into manageable chunks for retrieval.\\n2. **Set up vector storage**: Embed the document chunks and store them in a vector database to enable efficient retrieval.\\n3. **Configure the retriever and QA chain**: Use LangChain components to create a retriever and a question-answering (QA) chain powered by your chosen language model.\\n4. **Generate a test set**: Use Ragas to automatically generate a set of test questions and answers from your documents, or supply your own.\\n5. **Evaluate retrieval and QA performance**: Apply Ragas metrics to assess both the retriever and the full QA chain, measuring aspects like context relevancy, faithfulness, and answer quality.\\n6. **Review results**: Analyze the evaluation outputs to identify strengths and areas for improvement in your RAG pipeline.',\n",
              " 'This integration allows you to continuously measure and improve the effectiveness of your retrieval and generation components within the LangChain framework.\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> [07_Integrations_and_Observability](https://github.com/mafzaal/intro-to-ragas/blob/master/07_Integrations_and_Observability.ipynb)\\n\\nRagas supports integration with a variety of popular LLM and RAG frameworks beyond LangChain, including LlamaIndex and Haystack. These integrations enable seamless evaluation of retrieval and generation components within your preferred stack. If you need guidance or code examples for integrating Ragas with platforms such as LlamaIndex, Haystack, or others, support and tailored examples can be provided on demand to fit your specific workflow and requirements.\\n\\n## Observability Platform Integrations',\n",
              " 'This integration allows you to continuously measure and improve the effectiveness of your retrieval and generation components within the LangChain framework.\\n\\n> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> [07_Integrations_and_Observability](https://github.com/mafzaal/intro-to-ragas/blob/master/07_Integrations_and_Observability.ipynb)\\n\\nRagas supports integration with a variety of popular LLM and RAG frameworks beyond LangChain, including LlamaIndex and Haystack. These integrations enable seamless evaluation of retrieval and generation components within your preferred stack. If you need guidance or code examples for integrating Ragas with platforms such as LlamaIndex, Haystack, or others, support and tailored examples can be provided on demand to fit your specific workflow and requirements.\\n\\n## Observability Platform Integrations',\n",
              " '## Observability Platform Integrations\\n\\nBeyond framework integrations, Ragas connects with leading observability platforms to help you monitor, track, and analyze evaluation results over time.\\n\\n### LangSmith Integration\\nFor LangChain users, LangSmith provides comprehensive tracing and evaluation. To integrate Ragas evaluation with LangSmith, follow these steps:\\n\\n1. **Set up your environment**  \\n2. **Upload dataset to LangSmith**  \\n3. **Define your LLM or chain**  \\n4. **Select Ragas metrics**  \\n5. **Run evaluation with LangSmith**  \\n\\nYou can now view detailed experiment results in your LangSmith project dashboard. This integration enables you to trace, evaluate, and monitor your RAG pipeline performance directly within LangSmith, leveraging Ragas metrics for deeper insights.',\n",
              " '## Observability Platform Integrations\\n\\nBeyond framework integrations, Ragas connects with leading observability platforms to help you monitor, track, and analyze evaluation results over time.\\n\\n### LangSmith Integration\\nFor LangChain users, LangSmith provides comprehensive tracing and evaluation. To integrate Ragas evaluation with LangSmith, follow these steps:\\n\\n1. **Set up your environment**  \\n2. **Upload dataset to LangSmith**  \\n3. **Define your LLM or chain**  \\n4. **Select Ragas metrics**  \\n5. **Run evaluation with LangSmith**  \\n\\nYou can now view detailed experiment results in your LangSmith project dashboard. This integration enables you to trace, evaluate, and monitor your RAG pipeline performance directly within LangSmith, leveraging Ragas metrics for deeper insights.',\n",
              " '> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> [07_Integrations_and_Observability](https://github.com/mafzaal/intro-to-ragas/blob/master/07_Integrations_and_Observability.ipynb)\\n\\n\\n### Other Platform Integrations\\n\\nRagas can be integrated with a range of observability and monitoring platforms beyond LangSmith, such as Langfuse and others. If you need help connecting Ragas to platforms like Langfuse or have specific requirements for your observability stack, tailored support and examples are available to fit your workflow.\\n\\n## Building Automated Evaluation Pipelines\\n\\nTo ensure evaluation is a continuous part of your development process, set up automated pipelines that run evaluations regularly and automatically.\\n\\n### CI/CD Integration',\n",
              " '> 💡 **Try it yourself:**  \\n> Explore the hands-on notebook for synthetic data generation:  \\n> [07_Integrations_and_Observability](https://github.com/mafzaal/intro-to-ragas/blob/master/07_Integrations_and_Observability.ipynb)\\n\\n\\n### Other Platform Integrations\\n\\nRagas can be integrated with a range of observability and monitoring platforms beyond LangSmith, such as Langfuse and others. If you need help connecting Ragas to platforms like Langfuse or have specific requirements for your observability stack, tailored support and examples are available to fit your workflow.\\n\\n## Building Automated Evaluation Pipelines\\n\\nTo ensure evaluation is a continuous part of your development process, set up automated pipelines that run evaluations regularly and automatically.\\n\\n### CI/CD Integration',\n",
              " 'To ensure evaluation is a continuous part of your development process, set up automated pipelines that run evaluations regularly and automatically.\\n\\n### CI/CD Integration\\n\\nYou can incorporate Ragas into your CI/CD pipeline so that every code change is automatically evaluated. This helps catch regressions early and ensures your RAG system maintains high performance before merging new changes.\\n\\n### Scheduled Evaluations\\n\\nRegularly scheduled evaluations allow you to monitor your system’s performance over time. By running evaluations at set intervals, you can track trends, spot regressions, and ensure your system continues to meet quality standards.\\n\\n## Monitoring Evaluation Metrics Over Time\\n\\nTracking evaluation metrics over time helps you identify performance trends and quickly detect any drops in quality. By visualizing these metrics, you can better understand how changes to your system impact its effectiveness.\\n\\n## Creating Custom Dashboards',\n",
              " 'To ensure evaluation is a continuous part of your development process, set up automated pipelines that run evaluations regularly and automatically.\\n\\n### CI/CD Integration\\n\\nYou can incorporate Ragas into your CI/CD pipeline so that every code change is automatically evaluated. This helps catch regressions early and ensures your RAG system maintains high performance before merging new changes.\\n\\n### Scheduled Evaluations\\n\\nRegularly scheduled evaluations allow you to monitor your system’s performance over time. By running evaluations at set intervals, you can track trends, spot regressions, and ensure your system continues to meet quality standards.\\n\\n## Monitoring Evaluation Metrics Over Time\\n\\nTracking evaluation metrics over time helps you identify performance trends and quickly detect any drops in quality. By visualizing these metrics, you can better understand how changes to your system impact its effectiveness.\\n\\n## Creating Custom Dashboards',\n",
              " '## Creating Custom Dashboards\\n\\nBuilding custom dashboards gives you a comprehensive view of your evaluation results. Dashboards can display current performance, trends, and detailed breakdowns of recent evaluations, making it easier to monitor your system and identify areas for improvement.\\n\\nWith these practices, you can make evaluation an ongoing, automated, and visible part of your development workflow, leading to more reliable and robust RAG systems.\\n\\n## Best Practices for Observability',\n",
              " '## Creating Custom Dashboards\\n\\nBuilding custom dashboards gives you a comprehensive view of your evaluation results. Dashboards can display current performance, trends, and detailed breakdowns of recent evaluations, making it easier to monitor your system and identify areas for improvement.\\n\\nWith these practices, you can make evaluation an ongoing, automated, and visible part of your development workflow, leading to more reliable and robust RAG systems.\\n\\n## Best Practices for Observability',\n",
              " '## Best Practices for Observability\\n\\n1. **Define clear thresholds**: Establish performance baselines and alert thresholds for each metric\\n2. **Segment evaluations**: Break down results by query type, data source, or other relevant factors\\n3. **Historical tracking**: Maintain historical evaluation data to identify trends and regressions\\n4. **Correlation analysis**: Link evaluation metrics to user feedback and business outcomes\\n5. **Regular benchmarking**: Periodically evaluate against fixed test sets to ensure consistency\\n6. **Alert on regressions**: Implement automated alerts when metrics drop below thresholds\\n7. **Contextualize metrics**: Include example failures alongside aggregate metrics for better understanding\\n\\n## Building a Feedback Loop\\n\\nThe ultimate goal of evaluation is to drive improvements. Establish a feedback loop:',\n",
              " '## Best Practices for Observability\\n\\n1. **Define clear thresholds**: Establish performance baselines and alert thresholds for each metric\\n2. **Segment evaluations**: Break down results by query type, data source, or other relevant factors\\n3. **Historical tracking**: Maintain historical evaluation data to identify trends and regressions\\n4. **Correlation analysis**: Link evaluation metrics to user feedback and business outcomes\\n5. **Regular benchmarking**: Periodically evaluate against fixed test sets to ensure consistency\\n6. **Alert on regressions**: Implement automated alerts when metrics drop below thresholds\\n7. **Contextualize metrics**: Include example failures alongside aggregate metrics for better understanding\\n\\n## Building a Feedback Loop\\n\\nThe ultimate goal of evaluation is to drive improvements. Establish a feedback loop:',\n",
              " \"## Building a Feedback Loop\\n\\nThe ultimate goal of evaluation is to drive improvements. Establish a feedback loop:\\n\\n1. **Capture evaluation results** with Ragas\\n2. **Identify patterns** in failures and underperforming areas\\n3. **Prioritize improvements** based on impact and effort\\n4. **Implement changes** to your RAG components\\n5. **Validate improvements** with focused re-evaluation\\n6. **Monitor continuously** to catch regressions\\n\\n## Conclusion: From Evaluation to Action\\n\\nIntegrating Ragas with your frameworks and observability tools transforms evaluation from a point-in-time activity to a continuous improvement cycle. By making evaluation metrics visible, actionable, and integrated into your workflows, you create a foundation for systematic improvement of your LLM applications.\\n\\nThe most successful teams don't just evaluate occasionally — they build evaluation into their development culture, making data-driven decisions based on objective metrics rather than subjective impressions.\",\n",
              " \"## Building a Feedback Loop\\n\\nThe ultimate goal of evaluation is to drive improvements. Establish a feedback loop:\\n\\n1. **Capture evaluation results** with Ragas\\n2. **Identify patterns** in failures and underperforming areas\\n3. **Prioritize improvements** based on impact and effort\\n4. **Implement changes** to your RAG components\\n5. **Validate improvements** with focused re-evaluation\\n6. **Monitor continuously** to catch regressions\\n\\n## Conclusion: From Evaluation to Action\\n\\nIntegrating Ragas with your frameworks and observability tools transforms evaluation from a point-in-time activity to a continuous improvement cycle. By making evaluation metrics visible, actionable, and integrated into your workflows, you create a foundation for systematic improvement of your LLM applications.\\n\\nThe most successful teams don't just evaluate occasionally — they build evaluation into their development culture, making data-driven decisions based on objective metrics rather than subjective impressions.\",\n",
              " \"In our final post, we'll explore how to build effective feedback loops that translate evaluation insights into concrete improvements for your LLM applications.\\n\\n---\\n\\n \\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**   \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Metrics and Customization](/blog/advanced-metrics-and-customization-with-ragas/)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**Part 7: Integrations and Observability with Ragas — _You are here_**  \\n*Next up in the series:*  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " \"In our final post, we'll explore how to build effective feedback loops that translate evaluation insights into concrete improvements for your LLM applications.\\n\\n---\\n\\n \\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**   \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Metrics and Customization](/blog/advanced-metrics-and-customization-with-ragas/)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**Part 7: Integrations and Observability with Ragas — _You are here_**  \\n*Next up in the series:*  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " \"*How are you evaluating your AI agents? What challenges have you encountered in measuring agent performance? If you're facing specific evaluation hurdles, don't hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we'd love to help!*\",\n",
              " \"*How are you evaluating your AI agents? What challenges have you encountered in measuring agent performance? If you're facing specific evaluation hurdles, don't hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we'd love to help!*\",\n",
              " '---\\ntitle: \"Part 8: Building Feedback Loops with Ragas\"\\ndate: 2025-05-04T00:00:00-06:00\\nlayout: blog\\ndescription: \"A research-driven guide to designing robust, actionable feedback loops for LLM and RAG systems using Ragas. Learn how to select metrics, set baselines, define thresholds, and incorporate user and human feedback for continuous improvement.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\", \"Data\"]\\ncoverImage: \"/images/building-feedback-loops.png\"\\nreadingTime: 10\\npublished: true\\n---\\n\\n\\nA high-performing LLM or RAG system is never static. The most successful teams treat evaluation as a continuous, iterative process—one that closes the loop between measurement, analysis, and improvement. In this post, we’ll design a research-backed feedback loop process using Ragas, focusing on actionable activities at each stage and strategies for integrating user and human feedback.\\n\\n\\n## Designing the Feedback Loop: A Stepwise Process',\n",
              " '---\\ntitle: \"Part 8: Building Feedback Loops with Ragas\"\\ndate: 2025-05-04T00:00:00-06:00\\nlayout: blog\\ndescription: \"A research-driven guide to designing robust, actionable feedback loops for LLM and RAG systems using Ragas. Learn how to select metrics, set baselines, define thresholds, and incorporate user and human feedback for continuous improvement.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\", \"Data\"]\\ncoverImage: \"/images/building-feedback-loops.png\"\\nreadingTime: 10\\npublished: true\\n---\\n\\n\\nA high-performing LLM or RAG system is never static. The most successful teams treat evaluation as a continuous, iterative process—one that closes the loop between measurement, analysis, and improvement. In this post, we’ll design a research-backed feedback loop process using Ragas, focusing on actionable activities at each stage and strategies for integrating user and human feedback.\\n\\n\\n## Designing the Feedback Loop: A Stepwise Process',\n",
              " '## Designing the Feedback Loop: A Stepwise Process\\n\\nThe feedback loop process is a systematic approach to continuously improve your LLM or RAG system. It consists of seven key steps, each building on the previous one to create a sustainable cycle of evidence-driven progress.  \\n\\n![Feedback Loop Process](/images/feedback-loop-process.png)\\n\\n### 1. Select the Right Metric\\n\\n**Purpose:**  \\nIdentify metrics that best reflect your application’s goals and user needs.\\n\\n**Activities:**  \\n- Map business objectives to measurable outcomes (e.g., accuracy, faithfulness, relevancy).\\n- Review available Ragas metrics and select those most aligned with your use case.\\n- Periodically revisit metric selection as your product or user base evolves.\\n\\n### 2. Develop and Measure Baseline Metrics\\n\\n**Purpose:**  \\nEstablish a reference point for current system performance.',\n",
              " '## Designing the Feedback Loop: A Stepwise Process\\n\\nThe feedback loop process is a systematic approach to continuously improve your LLM or RAG system. It consists of seven key steps, each building on the previous one to create a sustainable cycle of evidence-driven progress.  \\n\\n![Feedback Loop Process](/images/feedback-loop-process.png)\\n\\n### 1. Select the Right Metric\\n\\n**Purpose:**  \\nIdentify metrics that best reflect your application’s goals and user needs.\\n\\n**Activities:**  \\n- Map business objectives to measurable outcomes (e.g., accuracy, faithfulness, relevancy).\\n- Review available Ragas metrics and select those most aligned with your use case.\\n- Periodically revisit metric selection as your product or user base evolves.\\n\\n### 2. Develop and Measure Baseline Metrics\\n\\n**Purpose:**  \\nEstablish a reference point for current system performance.',\n",
              " '### 2. Develop and Measure Baseline Metrics\\n\\n**Purpose:**  \\nEstablish a reference point for current system performance.\\n\\n**Activities:**  \\n- Assemble a representative evaluation dataset.\\n- Run your system and record metric scores for each example.\\n- Document baseline results for all selected metrics.\\n- Ensure the baseline dataset remains stable for future comparisons.\\n\\n### 3. Analyze and Define Acceptable Threshold Values\\n\\n**Purpose:**  \\nSet clear, actionable standards for what constitutes “good enough” performance.\\n\\n**Activities:**  \\n- Analyze baseline metric distributions (mean, variance, outliers).\\n- Consult stakeholders to define minimum acceptable values for each metric.\\n- Document thresholds and rationale for transparency.\\n- Consider different thresholds for different segments (e.g., critical vs. non-critical queries).\\n\\n### 4. Evaluate and Select Improvement Areas\\n\\n**Purpose:**  \\nIdentify where your system most often fails to meet thresholds and prioritize improvements.',\n",
              " '### 2. Develop and Measure Baseline Metrics\\n\\n**Purpose:**  \\nEstablish a reference point for current system performance.\\n\\n**Activities:**  \\n- Assemble a representative evaluation dataset.\\n- Run your system and record metric scores for each example.\\n- Document baseline results for all selected metrics.\\n- Ensure the baseline dataset remains stable for future comparisons.\\n\\n### 3. Analyze and Define Acceptable Threshold Values\\n\\n**Purpose:**  \\nSet clear, actionable standards for what constitutes “good enough” performance.\\n\\n**Activities:**  \\n- Analyze baseline metric distributions (mean, variance, outliers).\\n- Consult stakeholders to define minimum acceptable values for each metric.\\n- Document thresholds and rationale for transparency.\\n- Consider different thresholds for different segments (e.g., critical vs. non-critical queries).\\n\\n### 4. Evaluate and Select Improvement Areas\\n\\n**Purpose:**  \\nIdentify where your system most often fails to meet thresholds and prioritize improvements.',\n",
              " '### 4. Evaluate and Select Improvement Areas\\n\\n**Purpose:**  \\nIdentify where your system most often fails to meet thresholds and prioritize improvements.\\n\\n**Activities:**  \\n- Segment evaluation results by metric, query type, or user group.\\n- Identify patterns or clusters of failure (e.g., certain topics, long queries).\\n- Prioritize areas with the greatest impact on user experience or business goals.\\n- Formulate hypotheses about root causes.\\n\\n### 5. Implement Improvements\\n\\n**Purpose:**  \\nTake targeted actions to address identified weaknesses.\\n\\n**Activities:**  \\n- Design and implement changes (e.g., prompt tuning, retrieval upgrades, model fine-tuning).\\n- Document all interventions and their intended effects.\\n- Ensure changes are isolated for clear attribution of impact.\\n\\n\\n### 6. Record Metrics for History\\n\\n**Purpose:**  \\nBuild a longitudinal record to track progress and avoid regressions.',\n",
              " '### 4. Evaluate and Select Improvement Areas\\n\\n**Purpose:**  \\nIdentify where your system most often fails to meet thresholds and prioritize improvements.\\n\\n**Activities:**  \\n- Segment evaluation results by metric, query type, or user group.\\n- Identify patterns or clusters of failure (e.g., certain topics, long queries).\\n- Prioritize areas with the greatest impact on user experience or business goals.\\n- Formulate hypotheses about root causes.\\n\\n### 5. Implement Improvements\\n\\n**Purpose:**  \\nTake targeted actions to address identified weaknesses.\\n\\n**Activities:**  \\n- Design and implement changes (e.g., prompt tuning, retrieval upgrades, model fine-tuning).\\n- Document all interventions and their intended effects.\\n- Ensure changes are isolated for clear attribution of impact.\\n\\n\\n### 6. Record Metrics for History\\n\\n**Purpose:**  \\nBuild a longitudinal record to track progress and avoid regressions.',\n",
              " '### 6. Record Metrics for History\\n\\n**Purpose:**  \\nBuild a longitudinal record to track progress and avoid regressions.\\n\\n**Activities:**  \\n- After each improvement, re-evaluate on the same baseline dataset.\\n- Log metric scores, system version, date, and description of changes.\\n- Visualize trends over time to inform future decisions.\\n\\n**Metric Record Log Schema Example:**\\n\\n| Timestamp           | System Version | Metric Name       | Value  | Dataset Name | Change Description         |\\n|---------------------|---------------|-------------------|--------|--------------|---------------------------|\\n| 2025-05-04T12:00:00 | v1.2.0        | faithfulness      | 0.78   | baseline_v1  | Added re-ranking to retriever |\\n| 2025-05-04T12:00:00 | v1.2.0        | answer_relevancy  | 0.81   | baseline_v1  | Added re-ranking to retriever |\\n| ...                 | ...           | ...               | ...    | ...          | ...                       |\\n\\n\\n### 7. Repeat: Analyze, Evaluate, Implement, Record',\n",
              " '### 6. Record Metrics for History\\n\\n**Purpose:**  \\nBuild a longitudinal record to track progress and avoid regressions.\\n\\n**Activities:**  \\n- After each improvement, re-evaluate on the same baseline dataset.\\n- Log metric scores, system version, date, and description of changes.\\n- Visualize trends over time to inform future decisions.\\n\\n**Metric Record Log Schema Example:**\\n\\n| Timestamp           | System Version | Metric Name       | Value  | Dataset Name | Change Description         |\\n|---------------------|---------------|-------------------|--------|--------------|---------------------------|\\n| 2025-05-04T12:00:00 | v1.2.0        | faithfulness      | 0.78   | baseline_v1  | Added re-ranking to retriever |\\n| 2025-05-04T12:00:00 | v1.2.0        | answer_relevancy  | 0.81   | baseline_v1  | Added re-ranking to retriever |\\n| ...                 | ...           | ...               | ...    | ...          | ...                       |\\n\\n\\n### 7. Repeat: Analyze, Evaluate, Implement, Record',\n",
              " '### 7. Repeat: Analyze, Evaluate, Implement, Record\\n\\n**Purpose:**  \\nEstablish a sustainable, iterative cycle of improvement.\\n\\n**Activities:**  \\n- Regularly revisit analysis as new data or feedback emerges.\\n- Continuously refine thresholds and priorities.\\n- Maintain a culture of evidence-based iteration.\\n\\n\\n## Integrating User Feedback in Production\\n\\n### Purpose\\n\\nUser feedback provides real-world validation and uncovers blind spots in automated metrics. Incorporating it closes the gap between technical evaluation and actual user satisfaction.\\n\\n### Strategies',\n",
              " '### 7. Repeat: Analyze, Evaluate, Implement, Record\\n\\n**Purpose:**  \\nEstablish a sustainable, iterative cycle of improvement.\\n\\n**Activities:**  \\n- Regularly revisit analysis as new data or feedback emerges.\\n- Continuously refine thresholds and priorities.\\n- Maintain a culture of evidence-based iteration.\\n\\n\\n## Integrating User Feedback in Production\\n\\n### Purpose\\n\\nUser feedback provides real-world validation and uncovers blind spots in automated metrics. Incorporating it closes the gap between technical evaluation and actual user satisfaction.\\n\\n### Strategies',\n",
              " 'User feedback provides real-world validation and uncovers blind spots in automated metrics. Incorporating it closes the gap between technical evaluation and actual user satisfaction.\\n\\n### Strategies\\n\\n- **In-Product Feedback Widgets:** Allow users to rate answers or flag issues directly in the interface.\\n- **Passive Signals:** Analyze user behavior (e.g., follow-up queries, abandonment) as implicit feedback.\\n- **Feedback Sampling:** Periodically sample user sessions for manual review.\\n- **Feedback Aggregation:** Aggregate and categorize feedback to identify recurring pain points.\\n- **Metric Correlation:** Analyze how user feedback correlates with automated metrics to calibrate thresholds.\\n\\n### Recording User Feedback\\n\\n**User Feedback Log Schema Example:**',\n",
              " 'User feedback provides real-world validation and uncovers blind spots in automated metrics. Incorporating it closes the gap between technical evaluation and actual user satisfaction.\\n\\n### Strategies\\n\\n- **In-Product Feedback Widgets:** Allow users to rate answers or flag issues directly in the interface.\\n- **Passive Signals:** Analyze user behavior (e.g., follow-up queries, abandonment) as implicit feedback.\\n- **Feedback Sampling:** Periodically sample user sessions for manual review.\\n- **Feedback Aggregation:** Aggregate and categorize feedback to identify recurring pain points.\\n- **Metric Correlation:** Analyze how user feedback correlates with automated metrics to calibrate thresholds.\\n\\n### Recording User Feedback\\n\\n**User Feedback Log Schema Example:**',\n",
              " '### Recording User Feedback\\n\\n**User Feedback Log Schema Example:**\\n\\n| Timestamp           | User ID | Query ID | User Rating | Feedback Text         | Metric Scores | System Version |\\n|---------------------|---------|----------|-------------|----------------------|--------------|---------------|\\n| 2025-05-04T13:00:00 | 12345   | q_987    | 2           | \"Answer was off-topic\" | `{faithfulness: 0.6, answer_relevancy: 0.5}` | v1.2.0 |\\n| 2025-05-04T13:00:00 | 67890   | q_654    | 4           | \"Good answer, but could be more concise\" | `{faithfulness: 0.8, answer_relevancy: 0.9}` | v1.2.0 |\\n| ...                 | ...     | ...      | ...         | ...                  | ...          | ...           |\\n\\n## Including Human Labelers in Evaluation\\n\\n### Purpose\\n\\nHuman labelers provide high-quality, nuanced judgments that automated metrics may miss, especially for ambiguous or complex queries.\\n\\n### Strategies',\n",
              " '### Recording User Feedback\\n\\n**User Feedback Log Schema Example:**\\n\\n| Timestamp           | User ID | Query ID | User Rating | Feedback Text         | Metric Scores | System Version |\\n|---------------------|---------|----------|-------------|----------------------|--------------|---------------|\\n| 2025-05-04T13:00:00 | 12345   | q_987    | 2           | \"Answer was off-topic\" | `{faithfulness: 0.6, answer_relevancy: 0.5}` | v1.2.0 |\\n| 2025-05-04T13:00:00 | 67890   | q_654    | 4           | \"Good answer, but could be more concise\" | `{faithfulness: 0.8, answer_relevancy: 0.9}` | v1.2.0 |\\n| ...                 | ...     | ...      | ...         | ...                  | ...          | ...           |\\n\\n## Including Human Labelers in Evaluation\\n\\n### Purpose\\n\\nHuman labelers provide high-quality, nuanced judgments that automated metrics may miss, especially for ambiguous or complex queries.\\n\\n### Strategies',\n",
              " '### Purpose\\n\\nHuman labelers provide high-quality, nuanced judgments that automated metrics may miss, especially for ambiguous or complex queries.\\n\\n### Strategies\\n\\n- **Periodic Human Review:** Regularly sample evaluation outputs for human annotation.\\n- **Disagreement Analysis:** Focus human review on cases where user feedback and metrics disagree.\\n- **Labeler Training:** Provide clear guidelines and calibration sessions to ensure consistency.\\n- **Hybrid Scoring:** Combine human and automated scores for a more holistic evaluation.\\n- **Continuous Calibration:** Use human labels to refine and validate automated metric thresholds.\\n\\n\\n## Conclusion',\n",
              " '### Purpose\\n\\nHuman labelers provide high-quality, nuanced judgments that automated metrics may miss, especially for ambiguous or complex queries.\\n\\n### Strategies\\n\\n- **Periodic Human Review:** Regularly sample evaluation outputs for human annotation.\\n- **Disagreement Analysis:** Focus human review on cases where user feedback and metrics disagree.\\n- **Labeler Training:** Provide clear guidelines and calibration sessions to ensure consistency.\\n- **Hybrid Scoring:** Combine human and automated scores for a more holistic evaluation.\\n- **Continuous Calibration:** Use human labels to refine and validate automated metric thresholds.\\n\\n\\n## Conclusion',\n",
              " '## Conclusion\\n\\nA robust feedback loop is the foundation of sustainable improvement for LLM and RAG systems. By systematically selecting metrics, measuring baselines, setting thresholds, and integrating both user and human feedback, you create a virtuous cycle of evidence-driven progress. The most effective teams treat evaluation as an ongoing process—one that is deeply connected to real user outcomes and grounded in transparent, repeatable measurement.\\n\\n---\\n*This is the eighth part of a series on Ragas, a research-driven evaluation framework for LLM and RAG systems. If you missed the previous parts, check them out below:*',\n",
              " '## Conclusion\\n\\nA robust feedback loop is the foundation of sustainable improvement for LLM and RAG systems. By systematically selecting metrics, measuring baselines, setting thresholds, and integrating both user and human feedback, you create a virtuous cycle of evidence-driven progress. The most effective teams treat evaluation as an ongoing process—one that is deeply connected to real user outcomes and grounded in transparent, repeatable measurement.\\n\\n---\\n*This is the eighth part of a series on Ragas, a research-driven evaluation framework for LLM and RAG systems. If you missed the previous parts, check them out below:*',\n",
              " '---\\n*This is the eighth part of a series on Ragas, a research-driven evaluation framework for LLM and RAG systems. If you missed the previous parts, check them out below:*\\n\\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**  \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Metrics and Customization](/blog/advanced-metrics-and-customization-with-ragas/)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**Part 8: Building Feedback Loops — _You are here_**',\n",
              " '---\\n*This is the eighth part of a series on Ragas, a research-driven evaluation framework for LLM and RAG systems. If you missed the previous parts, check them out below:*\\n\\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**[Part 3: Evaluating RAG Systems with Ragas](/blog/evaluating-rag-systems-with-ragas/)**  \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Metrics and Customization](/blog/advanced-metrics-and-customization-with-ragas/)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**Part 8: Building Feedback Loops — _You are here_**',\n",
              " '*Have questions or want to share your feedback loop strategies? [Connect with me on LinkedIn](https://www.linkedin.com/in/muhammadafzaal/) for discussion or collaboration!*',\n",
              " '*Have questions or want to share your feedback loop strategies? [Connect with me on LinkedIn](https://www.linkedin.com/in/muhammadafzaal/) for discussion or collaboration!*',\n",
              " '---\\nlayout: blog\\ntitle: Coming Back to AI Roots - My Professional Journey\\ndate: 2025-04-14T00:00:00-06:00\\ndescription: A personal reflection on my career journey from AI to web and enterprise software development, and why I\\'m returning to my original passion for artificial intelligence.\\ncategories: [\"AI\", \"Personal Journey\", \"Technology\"]\\ncoverVideo: \"/videos/back_to_future.mp4\"\\nreadingTime: 4\\npublished: true\\n---\\n\\n\\nHave you ever felt that life has a way of bringing you full circle? That\\'s exactly how I feel about my career trajectory. My name is Muhammad Afzaal, and I\\'d like to share the story of my professional journey - from my early fascination with artificial intelligence, through years of web and enterprise software development, and now back to where it all began.\\n\\n## The Early AI Days',\n",
              " '---\\nlayout: blog\\ntitle: Coming Back to AI Roots - My Professional Journey\\ndate: 2025-04-14T00:00:00-06:00\\ndescription: A personal reflection on my career journey from AI to web and enterprise software development, and why I\\'m returning to my original passion for artificial intelligence.\\ncategories: [\"AI\", \"Personal Journey\", \"Technology\"]\\ncoverVideo: \"/videos/back_to_future.mp4\"\\nreadingTime: 4\\npublished: true\\n---\\n\\n\\nHave you ever felt that life has a way of bringing you full circle? That\\'s exactly how I feel about my career trajectory. My name is Muhammad Afzaal, and I\\'d like to share the story of my professional journey - from my early fascination with artificial intelligence, through years of web and enterprise software development, and now back to where it all began.\\n\\n## The Early AI Days',\n",
              " '## The Early AI Days\\n\\nMy professional journey began with a deep fascination for artificial intelligence. As a student, I was captivated by the potential of machines that could learn and make decisions. This was well before the current AI boom - back when neural networks were still considered somewhat niche and the term \"deep learning\" wasn\\'t yet a household phrase.\\n\\nI spent countless hours immersed in neural networks, image processing, and computer vision. My early career was defined by research projects and small-scale AI implementations - including Urdu OCR systems and data extraction from paper-based forms in 2003-2004. I still have vivid memories of recruiting fellow students to handwrite text samples, then meticulously scanning, labeling, and training neural networks with this data. While modest by today\\'s standards, these projects represented glimpses into a future where machines could meaningfully augment human capabilities in ways that seemed almost magical at the time.',\n",
              " '## The Early AI Days\\n\\nMy professional journey began with a deep fascination for artificial intelligence. As a student, I was captivated by the potential of machines that could learn and make decisions. This was well before the current AI boom - back when neural networks were still considered somewhat niche and the term \"deep learning\" wasn\\'t yet a household phrase.\\n\\nI spent countless hours immersed in neural networks, image processing, and computer vision. My early career was defined by research projects and small-scale AI implementations - including Urdu OCR systems and data extraction from paper-based forms in 2003-2004. I still have vivid memories of recruiting fellow students to handwrite text samples, then meticulously scanning, labeling, and training neural networks with this data. While modest by today\\'s standards, these projects represented glimpses into a future where machines could meaningfully augment human capabilities in ways that seemed almost magical at the time.',\n",
              " '## The Pivot to Web and Enterprise Development\\n\\nAs often happens in technology careers, opportunities led me in a different direction. The explosive growth of web technologies and enterprise systems created a high demand for developers with these skills, and I found myself gradually pivoting away from AI.\\n\\nFor several years, I immersed myself in the world of web and enterprise software development. I worked with various frameworks and technologies, built scalable systems, and helped businesses solve complex problems through software. This journey taught me invaluable lessons about software architecture, user experience, and delivering production-quality code that serves real business needs.',\n",
              " '## The Pivot to Web and Enterprise Development\\n\\nAs often happens in technology careers, opportunities led me in a different direction. The explosive growth of web technologies and enterprise systems created a high demand for developers with these skills, and I found myself gradually pivoting away from AI.\\n\\nFor several years, I immersed myself in the world of web and enterprise software development. I worked with various frameworks and technologies, built scalable systems, and helped businesses solve complex problems through software. This journey taught me invaluable lessons about software architecture, user experience, and delivering production-quality code that serves real business needs.',\n",
              " \"Working in enterprise software development exposed me to the challenges of building systems that not only function correctly but can also scale, evolve, and adapt to changing requirements. I learned the importance of clean code, thoughtful architecture, and considering the entire lifecycle of software products.\\n\\n## Why I'm Returning to AI\\n\\nWhile my time in web and enterprise development was rewarding, I've always felt a pull back toward artificial intelligence. The recent AI renaissance - with breakthroughs in large language models, generative AI, and machine learning at scale - has reignited my original passion.\\n\\nWe're living in what may be the most exciting time in AI history. Models like GPT-4, Claude, and open-source alternatives are demonstrating capabilities that seemed like science fiction just a few years ago. The tools and frameworks available today make AI more accessible than ever before, and the potential applications span virtually every domain of human endeavor.\",\n",
              " \"Working in enterprise software development exposed me to the challenges of building systems that not only function correctly but can also scale, evolve, and adapt to changing requirements. I learned the importance of clean code, thoughtful architecture, and considering the entire lifecycle of software products.\\n\\n## Why I'm Returning to AI\\n\\nWhile my time in web and enterprise development was rewarding, I've always felt a pull back toward artificial intelligence. The recent AI renaissance - with breakthroughs in large language models, generative AI, and machine learning at scale - has reignited my original passion.\\n\\nWe're living in what may be the most exciting time in AI history. Models like GPT-4, Claude, and open-source alternatives are demonstrating capabilities that seemed like science fiction just a few years ago. The tools and frameworks available today make AI more accessible than ever before, and the potential applications span virtually every domain of human endeavor.\",\n",
              " \"What excites me most is that my experience in enterprise software development gives me a unique perspective on AI implementation. I understand not just the algorithms and models, but also how to integrate them into robust, production-ready systems that deliver real value.\\n\\n## The Best of Both Worlds\\n\\nComing back to AI doesn't mean leaving behind everything I learned in web and enterprise development. Quite the opposite - I believe my background gives me a particular advantage in building AI systems that are:\",\n",
              " \"What excites me most is that my experience in enterprise software development gives me a unique perspective on AI implementation. I understand not just the algorithms and models, but also how to integrate them into robust, production-ready systems that deliver real value.\\n\\n## The Best of Both Worlds\\n\\nComing back to AI doesn't mean leaving behind everything I learned in web and enterprise development. Quite the opposite - I believe my background gives me a particular advantage in building AI systems that are:\",\n",
              " \"- **Production-ready**: Understanding software engineering best practices helps create AI systems that can operate reliably at scale.\\n- **User-focused**: Experience with UX principles ensures AI solutions are designed with actual human users in mind.\\n- **Integrated**: Knowledge of enterprise systems makes it easier to connect AI capabilities with existing business processes.\\n- **Simplified**: My experience in streamlining complex business processes helps me identify where AI can have the greatest impact through intelligent automation.\\n- **Business-oriented**: I understand that AI isn't just about the technology—it's about solving real business problems and creating measurable value.\\n- **Practical**: I focus on practical applications that deliver immediate benefits rather than getting caught up in theoretical possibilities.\\n\\n## What's Next\\n\\nAs I return to my AI roots, I'm excited to share this journey with you through this blog. In the coming months, I plan to write about:\",\n",
              " \"- **Production-ready**: Understanding software engineering best practices helps create AI systems that can operate reliably at scale.\\n- **User-focused**: Experience with UX principles ensures AI solutions are designed with actual human users in mind.\\n- **Integrated**: Knowledge of enterprise systems makes it easier to connect AI capabilities with existing business processes.\\n- **Simplified**: My experience in streamlining complex business processes helps me identify where AI can have the greatest impact through intelligent automation.\\n- **Business-oriented**: I understand that AI isn't just about the technology—it's about solving real business problems and creating measurable value.\\n- **Practical**: I focus on practical applications that deliver immediate benefits rather than getting caught up in theoretical possibilities.\\n\\n## What's Next\\n\\nAs I return to my AI roots, I'm excited to share this journey with you through this blog. In the coming months, I plan to write about:\",\n",
              " \"## What's Next\\n\\nAs I return to my AI roots, I'm excited to share this journey with you through this blog. In the coming months, I plan to write about:\\n\\n- Practical applications of modern AI technologies\\n- How to bridge the gap between AI research and production systems\\n- The intersection of web technologies and AI\\n- Ethical considerations in AI implementation\\n- Tutorials and guides for developers looking to incorporate AI into their projects\\n\\nIf you're interested in AI, software development, or the intersection of these fields, I hope you'll join me on this journey. Whether you're a seasoned AI practitioner, a web developer curious about machine learning, or simply interested in how technology is evolving, I believe there's something here for you.\\n\\nHere's to coming full circle, building on past experiences, and embracing the exciting future of AI!\\n\\n---\",\n",
              " \"## What's Next\\n\\nAs I return to my AI roots, I'm excited to share this journey with you through this blog. In the coming months, I plan to write about:\\n\\n- Practical applications of modern AI technologies\\n- How to bridge the gap between AI research and production systems\\n- The intersection of web technologies and AI\\n- Ethical considerations in AI implementation\\n- Tutorials and guides for developers looking to incorporate AI into their projects\\n\\nIf you're interested in AI, software development, or the intersection of these fields, I hope you'll join me on this journey. Whether you're a seasoned AI practitioner, a web developer curious about machine learning, or simply interested in how technology is evolving, I believe there's something here for you.\\n\\nHere's to coming full circle, building on past experiences, and embracing the exciting future of AI!\\n\\n---\",\n",
              " \"Here's to coming full circle, building on past experiences, and embracing the exciting future of AI!\\n\\n---\\n\\n*Have questions or topics you'd like me to cover? Feel free to [reach out](https://www.linkedin.com/in/muhammadafzaal/) — we’d love to help!*\",\n",
              " \"Here's to coming full circle, building on past experiences, and embracing the exciting future of AI!\\n\\n---\\n\\n*Have questions or topics you'd like me to cover? Feel free to [reach out](https://www.linkedin.com/in/muhammadafzaal/) — we’d love to help!*\",\n",
              " '---\\nlayout: blog\\ntitle: \"Data is King: Why Your Data Strategy IS Your Business Strategy\"\\ndate: 2025-04-15T00:00:00-06:00\\ncategories: [\"AI\", \"Strategy\",\"Data\"]\\ndescription: \"Discover why controlling unique, high-quality data is your organization\\'s most valuable competitive advantage in the AI era, and how a strategic approach to data ownership is becoming essential to business success.\"\\ncoverImage: \"https://images.unsplash.com/photo-1705484229341-4f7f7519b718?q=80&w=1740&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 3\\npublished: true\\n---\\n\\nIn the rapidly evolving world of artificial intelligence and machine learning, there\\'s a phrase that has become something of a mantra among practitioners: \"Data is king.\" This concept, often attributed to Peter Norvig, the Research Director at Google, challenges the conventional wisdom that sophisticated algorithms are the primary drivers of AI advancement.\\n\\n## The Origin of \"Data is King\"',\n",
              " '---\\nlayout: blog\\ntitle: \"Data is King: Why Your Data Strategy IS Your Business Strategy\"\\ndate: 2025-04-15T00:00:00-06:00\\ncategories: [\"AI\", \"Strategy\",\"Data\"]\\ndescription: \"Discover why controlling unique, high-quality data is your organization\\'s most valuable competitive advantage in the AI era, and how a strategic approach to data ownership is becoming essential to business success.\"\\ncoverImage: \"https://images.unsplash.com/photo-1705484229341-4f7f7519b718?q=80&w=1740&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 3\\npublished: true\\n---\\n\\nIn the rapidly evolving world of artificial intelligence and machine learning, there\\'s a phrase that has become something of a mantra among practitioners: \"Data is king.\" This concept, often attributed to Peter Norvig, the Research Director at Google, challenges the conventional wisdom that sophisticated algorithms are the primary drivers of AI advancement.\\n\\n## The Origin of \"Data is King\"',\n",
              " '## The Origin of \"Data is King\"\\n\\nPeter Norvig famously stated, \"We don\\'t have better algorithms. We just have more data.\" This statement emerged during a time when Google\\'s approach to machine translation was yielding surprisingly effective results not through algorithmic innovations, but through the sheer volume of multilingual data they had amassed. \\n\\nThis perspective represented a paradigm shift. Prior to this, the field had largely focused on crafting ever more sophisticated algorithms, with the assumption that smarter code would yield better results. Norvig\\'s insight suggested something different: even relatively simple algorithms could outperform more sophisticated ones when trained on sufficiently large datasets.\\n\\n## The Business Imperative of Data Ownership',\n",
              " '## The Origin of \"Data is King\"\\n\\nPeter Norvig famously stated, \"We don\\'t have better algorithms. We just have more data.\" This statement emerged during a time when Google\\'s approach to machine translation was yielding surprisingly effective results not through algorithmic innovations, but through the sheer volume of multilingual data they had amassed. \\n\\nThis perspective represented a paradigm shift. Prior to this, the field had largely focused on crafting ever more sophisticated algorithms, with the assumption that smarter code would yield better results. Norvig\\'s insight suggested something different: even relatively simple algorithms could outperform more sophisticated ones when trained on sufficiently large datasets.\\n\\n## The Business Imperative of Data Ownership',\n",
              " \"## The Business Imperative of Data Ownership\\n\\nIn today's AI-driven economy, Norvig's insight has profound implications for businesses. Companies that control unique, high-quality datasets possess an increasingly valuable competitive advantage that can't be easily replicated—even by competitors with superior engineering talent.\\n\\n### Why Data Ownership Matters\\n\\n1. **Sustainable Competitive Advantage**: While algorithms can be replicated or even improved upon by competitors, proprietary data is uniquely yours. A company with exclusive access to valuable data can maintain market leadership even when algorithmic approaches become standardized.\\n\\n2. **Diminishing Returns on Algorithmic Innovation**: As machine learning techniques mature, algorithmic improvements often yield smaller incremental gains compared to expanding or improving your data assets.\",\n",
              " \"## The Business Imperative of Data Ownership\\n\\nIn today's AI-driven economy, Norvig's insight has profound implications for businesses. Companies that control unique, high-quality datasets possess an increasingly valuable competitive advantage that can't be easily replicated—even by competitors with superior engineering talent.\\n\\n### Why Data Ownership Matters\\n\\n1. **Sustainable Competitive Advantage**: While algorithms can be replicated or even improved upon by competitors, proprietary data is uniquely yours. A company with exclusive access to valuable data can maintain market leadership even when algorithmic approaches become standardized.\\n\\n2. **Diminishing Returns on Algorithmic Innovation**: As machine learning techniques mature, algorithmic improvements often yield smaller incremental gains compared to expanding or improving your data assets.\",\n",
              " '3. **Model Defensibility**: Proprietary data creates a moat around your AI systems that competitors cannot easily cross, regardless of their technical capabilities.\\n\\n4. **Value Appreciation**: Unlike physical assets that depreciate, data assets often appreciate in value over time as more patterns and insights can be extracted with evolving technology.\\n\\n### The Risks of Data Dependency\\n\\nOrganizations that rely on third-party data sources or lack clear data ownership strategies face significant risks:\\n\\n- **Vulnerability to supply disruptions** when data providers change terms or access\\n- **Limited ability to differentiate** their AI applications from competitors\\n- **Reduced capacity for innovation** as they lack the raw material for new insights\\n- **Potential lock-in** to specific vendors or platforms that control their data access',\n",
              " '3. **Model Defensibility**: Proprietary data creates a moat around your AI systems that competitors cannot easily cross, regardless of their technical capabilities.\\n\\n4. **Value Appreciation**: Unlike physical assets that depreciate, data assets often appreciate in value over time as more patterns and insights can be extracted with evolving technology.\\n\\n### The Risks of Data Dependency\\n\\nOrganizations that rely on third-party data sources or lack clear data ownership strategies face significant risks:\\n\\n- **Vulnerability to supply disruptions** when data providers change terms or access\\n- **Limited ability to differentiate** their AI applications from competitors\\n- **Reduced capacity for innovation** as they lack the raw material for new insights\\n- **Potential lock-in** to specific vendors or platforms that control their data access',\n",
              " 'For forward-thinking enterprises, data strategy should be elevated to the same level of importance as product, technology, and market strategies. This means investing in data acquisition, management, and governance with the same rigor applied to other mission-critical functions.\\n\\n## How \"TheDataGuy\" Can Transform Your Data Strategy\\n\\nAs \"TheDataGuy,\" I help businesses transform their approach to data assets through a comprehensive framework that turns raw information into strategic advantage:\\n\\n### My Data Value Chain Approach\\n\\n1. **Data Collection & Acquisition**: Designing efficient pipelines to gather relevant, high-quality data while ensuring compliance with regulatory requirements.\\n\\n2. **Storage Architecture**: Implementing scalable, secure storage solutions that balance accessibility with cost-effectiveness.\\n\\n3. **Organization & Governance**: Establishing metadata frameworks, quality control processes, and governance structures that make data discoverable and trustworthy.',\n",
              " 'For forward-thinking enterprises, data strategy should be elevated to the same level of importance as product, technology, and market strategies. This means investing in data acquisition, management, and governance with the same rigor applied to other mission-critical functions.\\n\\n## How \"TheDataGuy\" Can Transform Your Data Strategy\\n\\nAs \"TheDataGuy,\" I help businesses transform their approach to data assets through a comprehensive framework that turns raw information into strategic advantage:\\n\\n### My Data Value Chain Approach\\n\\n1. **Data Collection & Acquisition**: Designing efficient pipelines to gather relevant, high-quality data while ensuring compliance with regulatory requirements.\\n\\n2. **Storage Architecture**: Implementing scalable, secure storage solutions that balance accessibility with cost-effectiveness.\\n\\n3. **Organization & Governance**: Establishing metadata frameworks, quality control processes, and governance structures that make data discoverable and trustworthy.',\n",
              " '3. **Organization & Governance**: Establishing metadata frameworks, quality control processes, and governance structures that make data discoverable and trustworthy.\\n\\n4. **Insight Extraction**: Applying analytics techniques from basic reporting to advanced machine learning that convert data into actionable business intelligence.',\n",
              " '3. **Organization & Governance**: Establishing metadata frameworks, quality control processes, and governance structures that make data discoverable and trustworthy.\\n\\n4. **Insight Extraction**: Applying analytics techniques from basic reporting to advanced machine learning that convert data into actionable business intelligence.',\n",
              " \"5. **LLM Specialization**: Creating specialized AI capabilities tailored to your business context:\\n   \\n   a. **Retrieval-Augmented Generation (RAG)**: Implementing systems that combine your proprietary data with foundation models, enabling AI to access your business knowledge while reducing hallucinations and improving accuracy.\\n   \\n   b. **Domain-Specific Fine-Tuning**: Adapting pre-trained models to your industry's terminology, workflows, and requirements through targeted training on curated datasets.\\n   \\n   c. **Hybrid Approaches**: Developing systems that intelligently combine RAG and fine-tuning to maximize performance while minimizing computational costs and training time.\\n   \\n   d. **Knowledge Distillation**: Creating smaller, more efficient specialized models that capture the essential capabilities needed for your specific business applications.\",\n",
              " \"5. **LLM Specialization**: Creating specialized AI capabilities tailored to your business context:\\n   \\n   a. **Retrieval-Augmented Generation (RAG)**: Implementing systems that combine your proprietary data with foundation models, enabling AI to access your business knowledge while reducing hallucinations and improving accuracy.\\n   \\n   b. **Domain-Specific Fine-Tuning**: Adapting pre-trained models to your industry's terminology, workflows, and requirements through targeted training on curated datasets.\\n   \\n   c. **Hybrid Approaches**: Developing systems that intelligently combine RAG and fine-tuning to maximize performance while minimizing computational costs and training time.\\n   \\n   d. **Knowledge Distillation**: Creating smaller, more efficient specialized models that capture the essential capabilities needed for your specific business applications.\",\n",
              " \"By working across this entire spectrum, organizations can develop truly proprietary AI capabilities that competitors cannot easily replicate, regardless of their technical talent or computational resources.\\n\\nRemember: in the age of AI, your data strategy isn't just supporting your business strategy—increasingly, it *is* your business strategy.\\n## Ready to Make Data Your Competitive Advantage?\\n\\nDon't let valuable data opportunities slip away. Whether you're just beginning your data journey or looking to enhance your existing strategy, I can help transform your approach to this critical business asset.\\n\\n### Let's Connect\\nConnect with me on [LinkedIn](https://www.linkedin.com/in/muhammadafzaal/) to discuss how I can help your organization harness the power of data.\",\n",
              " \"By working across this entire spectrum, organizations can develop truly proprietary AI capabilities that competitors cannot easily replicate, regardless of their technical talent or computational resources.\\n\\nRemember: in the age of AI, your data strategy isn't just supporting your business strategy—increasingly, it *is* your business strategy.\\n## Ready to Make Data Your Competitive Advantage?\\n\\nDon't let valuable data opportunities slip away. Whether you're just beginning your data journey or looking to enhance your existing strategy, I can help transform your approach to this critical business asset.\\n\\n### Let's Connect\\nConnect with me on [LinkedIn](https://www.linkedin.com/in/muhammadafzaal/) to discuss how I can help your organization harness the power of data.\",\n",
              " '---\\ntitle: \"Part 3: Evaluating RAG Systems with Ragas\"\\ndate: 2025-04-26T20:00:00-06:00\\nlayout: blog\\ndescription: \"Learn specialized techniques for comprehensive evaluation of Retrieval-Augmented Generation systems using Ragas, including metrics for retrieval quality, generation quality, and end-to-end performance.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\"]\\ncoverImage: \"https://images.unsplash.com/photo-1743796055664-3473eedab36e?q=80&w=1974&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 14\\npublished: true\\n---\\n\\nIn our previous post, we covered the fundamentals of setting up evaluation workflows with Ragas. Now, let\\'s focus specifically on evaluating Retrieval-Augmented Generation (RAG) systems, which present unique evaluation challenges due to their multi-component nature.\\n\\n## Understanding RAG Systems: More Than the Sum of Their Parts',\n",
              " '---\\ntitle: \"Part 3: Evaluating RAG Systems with Ragas\"\\ndate: 2025-04-26T20:00:00-06:00\\nlayout: blog\\ndescription: \"Learn specialized techniques for comprehensive evaluation of Retrieval-Augmented Generation systems using Ragas, including metrics for retrieval quality, generation quality, and end-to-end performance.\"\\ncategories: [\"AI\", \"RAG\", \"Evaluation\", \"Ragas\"]\\ncoverImage: \"https://images.unsplash.com/photo-1743796055664-3473eedab36e?q=80&w=1974&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\\nreadingTime: 14\\npublished: true\\n---\\n\\nIn our previous post, we covered the fundamentals of setting up evaluation workflows with Ragas. Now, let\\'s focus specifically on evaluating Retrieval-Augmented Generation (RAG) systems, which present unique evaluation challenges due to their multi-component nature.\\n\\n## Understanding RAG Systems: More Than the Sum of Their Parts',\n",
              " \"## Understanding RAG Systems: More Than the Sum of Their Parts\\n\\nRAG systems combine two critical capabilities:\\n1. **Retrieval**: Finding relevant information from a knowledge base\\n2. **Generation**: Creating coherent, accurate responses based on retrieved information\\n\\nThis dual nature means evaluation must address both components while also assessing their interaction. A system might retrieve perfect information but generate poor responses, or generate excellent prose from irrelevant retrieved content.\\n\\n## The RAG Evaluation Triad\\n\\nEffective RAG evaluation requires examining three key dimensions:\\n\\n1. **Retrieval Quality**: How well does the system find relevant information?\\n2. **Generation Quality**: How well does the system produce responses from retrieved information?\\n3. **End-to-End Performance**: How well does the complete system satisfy user needs?\\n\\nLet's explore how Ragas helps evaluate each dimension of RAG systems.\\n\\n## Core RAG Metrics in Ragas\",\n",
              " \"## Understanding RAG Systems: More Than the Sum of Their Parts\\n\\nRAG systems combine two critical capabilities:\\n1. **Retrieval**: Finding relevant information from a knowledge base\\n2. **Generation**: Creating coherent, accurate responses based on retrieved information\\n\\nThis dual nature means evaluation must address both components while also assessing their interaction. A system might retrieve perfect information but generate poor responses, or generate excellent prose from irrelevant retrieved content.\\n\\n## The RAG Evaluation Triad\\n\\nEffective RAG evaluation requires examining three key dimensions:\\n\\n1. **Retrieval Quality**: How well does the system find relevant information?\\n2. **Generation Quality**: How well does the system produce responses from retrieved information?\\n3. **End-to-End Performance**: How well does the complete system satisfy user needs?\\n\\nLet's explore how Ragas helps evaluate each dimension of RAG systems.\\n\\n## Core RAG Metrics in Ragas\",\n",
              " \"Let's explore how Ragas helps evaluate each dimension of RAG systems.\\n\\n## Core RAG Metrics in Ragas\\n\\nRagas provides specialized metrics to assess RAG systems across retrieval, generation, and end-to-end performance.\\n\\n### Retrieval Quality Metrics\\n\\n#### 1. Context Relevancy\\n\\nMeasures how relevant the retrieved documents are to the user's question.\\n\\n- **How it works:**  \\n    - Takes the user's question (`user_input`) and the retrieved documents (`retrieved_contexts`).\\n    - Uses an LLM to score relevance with two different prompts, averaging the results for robustness.\\n    - Scores are normalized between 0.0 (irrelevant) and 1.0 (fully relevant).\\n\\n- **Why it matters:**  \\n    Low scores indicate your retriever is pulling in unrelated or noisy documents. Monitoring this helps you improve the retrieval step.\\n\\n#### 2. Context Precision\\n\\nAssesses how much of the retrieved context is actually useful for generating the answer.\",\n",
              " \"Let's explore how Ragas helps evaluate each dimension of RAG systems.\\n\\n## Core RAG Metrics in Ragas\\n\\nRagas provides specialized metrics to assess RAG systems across retrieval, generation, and end-to-end performance.\\n\\n### Retrieval Quality Metrics\\n\\n#### 1. Context Relevancy\\n\\nMeasures how relevant the retrieved documents are to the user's question.\\n\\n- **How it works:**  \\n    - Takes the user's question (`user_input`) and the retrieved documents (`retrieved_contexts`).\\n    - Uses an LLM to score relevance with two different prompts, averaging the results for robustness.\\n    - Scores are normalized between 0.0 (irrelevant) and 1.0 (fully relevant).\\n\\n- **Why it matters:**  \\n    Low scores indicate your retriever is pulling in unrelated or noisy documents. Monitoring this helps you improve the retrieval step.\\n\\n#### 2. Context Precision\\n\\nAssesses how much of the retrieved context is actually useful for generating the answer.\",\n",
              " '#### 2. Context Precision\\n\\nAssesses how much of the retrieved context is actually useful for generating the answer.\\n\\n- **How it works:**  \\n    - For each retrieved chunk, an LLM judges if it was necessary for the answer, using the ground truth (`reference`) or the generated response.\\n    - Calculates [Average Precision](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision), rewarding systems that rank useful chunks higher.\\n\\n- **Variants:**  \\n    - `ContextUtilization`: Uses the generated response instead of ground truth.\\n    - Non-LLM version: Compares retrieved chunks to ideal reference contexts using string similarity.\\n\\n- **Why it matters:**  \\n    High precision means your retriever is efficient; low precision means too much irrelevant information is included.\\n\\n#### 3. Context Recall\\n\\nEvaluates whether all necessary information from the ground truth answer is present in the retrieved context.',\n",
              " '#### 2. Context Precision\\n\\nAssesses how much of the retrieved context is actually useful for generating the answer.\\n\\n- **How it works:**  \\n    - For each retrieved chunk, an LLM judges if it was necessary for the answer, using the ground truth (`reference`) or the generated response.\\n    - Calculates [Average Precision](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision), rewarding systems that rank useful chunks higher.\\n\\n- **Variants:**  \\n    - `ContextUtilization`: Uses the generated response instead of ground truth.\\n    - Non-LLM version: Compares retrieved chunks to ideal reference contexts using string similarity.\\n\\n- **Why it matters:**  \\n    High precision means your retriever is efficient; low precision means too much irrelevant information is included.\\n\\n#### 3. Context Recall\\n\\nEvaluates whether all necessary information from the ground truth answer is present in the retrieved context.',\n",
              " '#### 3. Context Recall\\n\\nEvaluates whether all necessary information from the ground truth answer is present in the retrieved context.\\n\\n- **How it works:**  \\n    - Breaks down the reference answer into sentences.\\n    - For each sentence, an LLM checks if it can be supported by the retrieved context.\\n    - The score is the proportion of reference sentences attributed to the retrieved context.\\n\\n- **Variants:**  \\n    - Non-LLM version: Compares reference and retrieved contexts using similarity and thresholds.\\n\\n- **Why it matters:**  \\n    High recall means your retriever finds all needed information; low recall means critical information is missing.\\n\\n**Summary:**  \\n- **Low context relevancy:** Retriever needs better query understanding or semantic matching.\\n- **Low context precision:** Retriever includes unnecessary information.\\n- **Low context recall:** Retriever misses critical information.\\n\\n### Generation Quality Metrics\\n\\n#### 1. Faithfulness',\n",
              " '#### 3. Context Recall\\n\\nEvaluates whether all necessary information from the ground truth answer is present in the retrieved context.\\n\\n- **How it works:**  \\n    - Breaks down the reference answer into sentences.\\n    - For each sentence, an LLM checks if it can be supported by the retrieved context.\\n    - The score is the proportion of reference sentences attributed to the retrieved context.\\n\\n- **Variants:**  \\n    - Non-LLM version: Compares reference and retrieved contexts using similarity and thresholds.\\n\\n- **Why it matters:**  \\n    High recall means your retriever finds all needed information; low recall means critical information is missing.\\n\\n**Summary:**  \\n- **Low context relevancy:** Retriever needs better query understanding or semantic matching.\\n- **Low context precision:** Retriever includes unnecessary information.\\n- **Low context recall:** Retriever misses critical information.\\n\\n### Generation Quality Metrics\\n\\n#### 1. Faithfulness',\n",
              " \"### Generation Quality Metrics\\n\\n#### 1. Faithfulness\\n\\nChecks if the generated answer is factually consistent with the retrieved context, addressing hallucination.\\n\\n- **How it works:**  \\n    - Breaks the answer into simple statements.\\n    - For each, an LLM checks if it can be inferred from the retrieved context.\\n    - The score is the proportion of faithful statements.\\n\\n- **Alternative:**  \\n    - `FaithfulnesswithHHEM`: Uses a specialized NLI model for verification.\\n\\n- **Why it matters:**  \\n    High faithfulness means answers are grounded in context; low faithfulness signals hallucination.\\n\\n#### 2. Answer Relevancy\\n\\nMeasures if the generated answer directly addresses the user's question.\\n\\n- **How it works:**  \\n    - Asks an LLM to generate possible questions for the answer.\\n    - Compares these to the original question using embedding similarity.\\n    - Penalizes noncommittal answers.\",\n",
              " \"### Generation Quality Metrics\\n\\n#### 1. Faithfulness\\n\\nChecks if the generated answer is factually consistent with the retrieved context, addressing hallucination.\\n\\n- **How it works:**  \\n    - Breaks the answer into simple statements.\\n    - For each, an LLM checks if it can be inferred from the retrieved context.\\n    - The score is the proportion of faithful statements.\\n\\n- **Alternative:**  \\n    - `FaithfulnesswithHHEM`: Uses a specialized NLI model for verification.\\n\\n- **Why it matters:**  \\n    High faithfulness means answers are grounded in context; low faithfulness signals hallucination.\\n\\n#### 2. Answer Relevancy\\n\\nMeasures if the generated answer directly addresses the user's question.\\n\\n- **How it works:**  \\n    - Asks an LLM to generate possible questions for the answer.\\n    - Compares these to the original question using embedding similarity.\\n    - Penalizes noncommittal answers.\",\n",
              " \"- **How it works:**  \\n    - Asks an LLM to generate possible questions for the answer.\\n    - Compares these to the original question using embedding similarity.\\n    - Penalizes noncommittal answers.\\n\\n- **Why it matters:**  \\n    High relevancy means answers are on-topic; low relevancy means answers are off-topic or incomplete.\\n\\n**Summary:**  \\n- **Low faithfulness:** Generator adds facts not supported by context.\\n- **Low answer relevancy:** Generator doesn't focus on the specific question.\\n\\n### End-to-End Metrics\\n\\n#### 1. Correctness\\n\\nAssesses factual alignment between the generated answer and a ground truth reference.\\n\\n- **How it works:**  \\n    - Breaks both the answer and reference into claims.\\n    - Uses NLI to verify claims in both directions.\\n    - Calculates precision, recall, or F1-score.\\n\\n- **Why it matters:**  \\n    High correctness means answers match the ground truth; low correctness signals factual errors.\",\n",
              " \"- **How it works:**  \\n    - Asks an LLM to generate possible questions for the answer.\\n    - Compares these to the original question using embedding similarity.\\n    - Penalizes noncommittal answers.\\n\\n- **Why it matters:**  \\n    High relevancy means answers are on-topic; low relevancy means answers are off-topic or incomplete.\\n\\n**Summary:**  \\n- **Low faithfulness:** Generator adds facts not supported by context.\\n- **Low answer relevancy:** Generator doesn't focus on the specific question.\\n\\n### End-to-End Metrics\\n\\n#### 1. Correctness\\n\\nAssesses factual alignment between the generated answer and a ground truth reference.\\n\\n- **How it works:**  \\n    - Breaks both the answer and reference into claims.\\n    - Uses NLI to verify claims in both directions.\\n    - Calculates precision, recall, or F1-score.\\n\\n- **Why it matters:**  \\n    High correctness means answers match the ground truth; low correctness signals factual errors.\",\n",
              " '- **Why it matters:**  \\n    High correctness means answers match the ground truth; low correctness signals factual errors.\\n\\n**Key distinction:**  \\n- `Faithfulness`: Compares answer to retrieved context.\\n- `FactualCorrectness`: Compares answer to ground truth.\\n\\n---\\n\\n## Common RAG Evaluation Patterns\\n\\n### 1. High Retrieval, Low Generation Scores\\n\\n- **Diagnosis:** Good retrieval, poor use of information.\\n- **Fixes:** Improve prompts, use better generation models, or verify responses post-generation.\\n\\n### 2. Low Retrieval, High Generation Scores\\n\\n- **Diagnosis:** Good generation, inadequate information.\\n- **Fixes:** Enhance indexing, retrieval algorithms, or expand the knowledge base.\\n\\n### 3. Low Context Precision, High Faithfulness\\n\\n- **Diagnosis:** Retrieves too much, but generates reliably.\\n- **Fixes:** Filter passages, optimize chunk size, or use re-ranking.\\n\\n---\\n\\n## Best Practices for RAG Evaluation',\n",
              " '- **Why it matters:**  \\n    High correctness means answers match the ground truth; low correctness signals factual errors.\\n\\n**Key distinction:**  \\n- `Faithfulness`: Compares answer to retrieved context.\\n- `FactualCorrectness`: Compares answer to ground truth.\\n\\n---\\n\\n## Common RAG Evaluation Patterns\\n\\n### 1. High Retrieval, Low Generation Scores\\n\\n- **Diagnosis:** Good retrieval, poor use of information.\\n- **Fixes:** Improve prompts, use better generation models, or verify responses post-generation.\\n\\n### 2. Low Retrieval, High Generation Scores\\n\\n- **Diagnosis:** Good generation, inadequate information.\\n- **Fixes:** Enhance indexing, retrieval algorithms, or expand the knowledge base.\\n\\n### 3. Low Context Precision, High Faithfulness\\n\\n- **Diagnosis:** Retrieves too much, but generates reliably.\\n- **Fixes:** Filter passages, optimize chunk size, or use re-ranking.\\n\\n---\\n\\n## Best Practices for RAG Evaluation',\n",
              " '- **Diagnosis:** Retrieves too much, but generates reliably.\\n- **Fixes:** Filter passages, optimize chunk size, or use re-ranking.\\n\\n---\\n\\n## Best Practices for RAG Evaluation\\n\\n1. **Evaluate components independently:** Assess retrieval and generation separately.\\n2. **Use diverse queries:** Include factoid, explanatory, and complex questions.\\n3. **Compare against baselines:** Test against simpler systems.\\n4. **Perform ablation studies:** Try variations like different chunk sizes or retrieval models.\\n5. **Combine with human evaluation:** Use Ragas with human judgment for a complete view.\\n\\n---\\n\\n## Conclusion: The Iterative RAG Evaluation Cycle\\n\\nEffective RAG development is iterative:\\n\\n1. **Evaluate:** Measure performance.\\n2. **Analyze:** Identify weaknesses.\\n3. **Improve:** Apply targeted enhancements.\\n4. **Re-evaluate:** Measure the impact of changes.',\n",
              " '- **Diagnosis:** Retrieves too much, but generates reliably.\\n- **Fixes:** Filter passages, optimize chunk size, or use re-ranking.\\n\\n---\\n\\n## Best Practices for RAG Evaluation\\n\\n1. **Evaluate components independently:** Assess retrieval and generation separately.\\n2. **Use diverse queries:** Include factoid, explanatory, and complex questions.\\n3. **Compare against baselines:** Test against simpler systems.\\n4. **Perform ablation studies:** Try variations like different chunk sizes or retrieval models.\\n5. **Combine with human evaluation:** Use Ragas with human judgment for a complete view.\\n\\n---\\n\\n## Conclusion: The Iterative RAG Evaluation Cycle\\n\\nEffective RAG development is iterative:\\n\\n1. **Evaluate:** Measure performance.\\n2. **Analyze:** Identify weaknesses.\\n3. **Improve:** Apply targeted enhancements.\\n4. **Re-evaluate:** Measure the impact of changes.',\n",
              " '1. **Evaluate:** Measure performance.\\n2. **Analyze:** Identify weaknesses.\\n3. **Improve:** Apply targeted enhancements.\\n4. **Re-evaluate:** Measure the impact of changes.\\n\\n<p align=\"center\">\\n    <img src=\"/images/the-iterative-rag-evaluation-cycle.png\" alt=\"The Iterative RAG Evaluation Cycle\" width=\"50%\">\\n</p>\\n\\nBy using Ragas to implement this cycle, you can systematically improve your RAG system\\'s performance across all dimensions.\\n\\nIn our next post, we\\'ll explore how to generate high-quality test datasets for comprehensive RAG evaluation, addressing the common challenge of limited test data.\\n\\n---',\n",
              " '1. **Evaluate:** Measure performance.\\n2. **Analyze:** Identify weaknesses.\\n3. **Improve:** Apply targeted enhancements.\\n4. **Re-evaluate:** Measure the impact of changes.\\n\\n<p align=\"center\">\\n    <img src=\"/images/the-iterative-rag-evaluation-cycle.png\" alt=\"The Iterative RAG Evaluation Cycle\" width=\"50%\">\\n</p>\\n\\nBy using Ragas to implement this cycle, you can systematically improve your RAG system\\'s performance across all dimensions.\\n\\nIn our next post, we\\'ll explore how to generate high-quality test datasets for comprehensive RAG evaluation, addressing the common challenge of limited test data.\\n\\n---',\n",
              " \"In our next post, we'll explore how to generate high-quality test datasets for comprehensive RAG evaluation, addressing the common challenge of limited test data.\\n\\n---\\n\\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**Part 3: Evaluating RAG Systems with Ragas — _You are here_**   \\n*Next up in the series:*  \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Evaluation Techniques](/blog/advanced-metrics-and-customization-with-ragas)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " \"In our next post, we'll explore how to generate high-quality test datasets for comprehensive RAG evaluation, addressing the common challenge of limited test data.\\n\\n---\\n\\n**[Part 1: Introduction to Ragas: The Essential Evaluation Framework for LLM Applications](/blog/introduction-to-ragas/)**  \\n**[Part 2: Basic Evaluation Workflow](/blog/basic-evaluation-workflow-with-ragas/)**  \\n**Part 3: Evaluating RAG Systems with Ragas — _You are here_**   \\n*Next up in the series:*  \\n**[Part 4: Test Data Generation](/blog/generating-test-data-with-ragas/)**  \\n**[Part 5: Advanced Evaluation Techniques](/blog/advanced-metrics-and-customization-with-ragas)**  \\n**[Part 6: Evaluating AI Agents](/blog/evaluating-ai-agents-with-ragas/)**  \\n**[Part 7: Integrations and Observability](/blog/integrations-and-observability-with-ragas/)**  \\n**[Part 8: Building Feedback Loops](/blog/building-feedback-loops-with-ragas/)**\",\n",
              " '*How have you implemented feedback loops in your LLM applications? What improvement strategies have been most effective for your use cases? If you’re facing specific evaluation hurdles, don’t hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we’d love to help!*',\n",
              " '*How have you implemented feedback loops in your LLM applications? What improvement strategies have been most effective for your use cases? If you’re facing specific evaluation hurdles, don’t hesitate to [reach out](https://www.linkedin.com/in/muhammadafzaal/)—we’d love to help!*']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
        "\n",
        "matryoshka_dimensions = [768, 512, 256, 128, 64]\n",
        "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
        "train_loss = MatryoshkaLoss(\n",
        "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
        ")"
      ],
      "metadata": {
        "id": "vB-rODS7ji9i"
      },
      "id": "vB-rODS7ji9i",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
        "\n",
        "model.fit(\n",
        "    train_objectives=[(loader, train_loss)],\n",
        "    epochs=EPOCHS,\n",
        "    warmup_steps=warmup_steps,\n",
        "    output_path='thedataguy_arctic_ft',\n",
        "    show_progress_bar=True,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "NbvRv4pzjriO",
        "outputId": "34aa0726-8dc6-4e8d-86b7-c180d7b6b9ac"
      },
      "id": "NbvRv4pzjriO",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'texts'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3a2af3084dce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwarmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_objectives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/fit_mixin.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0mbatch_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m                 \u001b[0mtexts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/fit_mixin.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0mbatch_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m                 \u001b[0mtexts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'texts'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1287e1f5ee4747f4b7be32a18c0371ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98ed0a843a5540e6b319ea7a5797466d",
              "IPY_MODEL_8374bfaf4dfc4e5cba24cde4eddb6eb1",
              "IPY_MODEL_20a6b33a3c4d4b59bb193823cdfa31c3"
            ],
            "layout": "IPY_MODEL_4dcb732b601c4cb38962febec23463b9"
          }
        },
        "98ed0a843a5540e6b319ea7a5797466d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c46c2b7a1e24426aa64c2e9924301c1",
            "placeholder": "​",
            "style": "IPY_MODEL_3cbd589285ff4707a0f55b10db9b1c55",
            "value": "modules.json: 100%"
          }
        },
        "8374bfaf4dfc4e5cba24cde4eddb6eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c860bf8fa844f3eaa568ea61321b558",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04b48cb1a021463694f193e7a792500a",
            "value": 349
          }
        },
        "20a6b33a3c4d4b59bb193823cdfa31c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92ab7080f404ea8b8923842cbb84e24",
            "placeholder": "​",
            "style": "IPY_MODEL_ce46b786804a4f079ecd9fcf0cb8e244",
            "value": " 349/349 [00:00&lt;00:00, 17.8kB/s]"
          }
        },
        "4dcb732b601c4cb38962febec23463b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c46c2b7a1e24426aa64c2e9924301c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cbd589285ff4707a0f55b10db9b1c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c860bf8fa844f3eaa568ea61321b558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b48cb1a021463694f193e7a792500a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e92ab7080f404ea8b8923842cbb84e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce46b786804a4f079ecd9fcf0cb8e244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbc711b851ff4e55bf75e8cb84d78718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ddc346b60914ba693e88c78956ea028",
              "IPY_MODEL_eea62d5b0b3345559e7f43c41f601744",
              "IPY_MODEL_7e1670bced804a23b51d8ee93dcd004c"
            ],
            "layout": "IPY_MODEL_4f5a70eab3d24f5186a95b3301a322a1"
          }
        },
        "8ddc346b60914ba693e88c78956ea028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25eecd420c22440fa93a302c8d036edd",
            "placeholder": "​",
            "style": "IPY_MODEL_13dcdd6d642b4544873fbea5f044a4a7",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "eea62d5b0b3345559e7f43c41f601744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a9a6e8d67264f7e97449a0daa0c6187",
            "max": 252,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4910db42e120456ab304fba874dbcdb3",
            "value": 252
          }
        },
        "7e1670bced804a23b51d8ee93dcd004c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aff17ab318d460990e9f9306d6130e4",
            "placeholder": "​",
            "style": "IPY_MODEL_255e75d694ce44828f2dc37fdb63f2a9",
            "value": " 252/252 [00:00&lt;00:00, 20.2kB/s]"
          }
        },
        "4f5a70eab3d24f5186a95b3301a322a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25eecd420c22440fa93a302c8d036edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13dcdd6d642b4544873fbea5f044a4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a9a6e8d67264f7e97449a0daa0c6187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4910db42e120456ab304fba874dbcdb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0aff17ab318d460990e9f9306d6130e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "255e75d694ce44828f2dc37fdb63f2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "482292b6d39c4408b5e6c19ff24ac118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5961daf315be4ff5b5ef1863dc44baf2",
              "IPY_MODEL_b58cfe205bb442198f87d56807e93fe7",
              "IPY_MODEL_e35714c1849d4ae5938a6498b8ebe8cc"
            ],
            "layout": "IPY_MODEL_e515005c754e4667be490a3585053e5c"
          }
        },
        "5961daf315be4ff5b5ef1863dc44baf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c7e61b1ebd147f2812109c97cfa5779",
            "placeholder": "​",
            "style": "IPY_MODEL_e3b261b8f6c947339eeb64e75b2c1077",
            "value": "README.md: 100%"
          }
        },
        "b58cfe205bb442198f87d56807e93fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5368115a18364e33b77d8cb35e9d3107",
            "max": 85438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4fdc95c3e4e43e781e8f4c7b5f23ce0",
            "value": 85438
          }
        },
        "e35714c1849d4ae5938a6498b8ebe8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_774b95ed73bd41d790e85a57f0355737",
            "placeholder": "​",
            "style": "IPY_MODEL_afe61b7053d74e56b8ee54ea6d246da5",
            "value": " 85.4k/85.4k [00:00&lt;00:00, 398kB/s]"
          }
        },
        "e515005c754e4667be490a3585053e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c7e61b1ebd147f2812109c97cfa5779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b261b8f6c947339eeb64e75b2c1077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5368115a18364e33b77d8cb35e9d3107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4fdc95c3e4e43e781e8f4c7b5f23ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "774b95ed73bd41d790e85a57f0355737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe61b7053d74e56b8ee54ea6d246da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e5dd853588f49438b0712b117e3955f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb87f81b7c0843a4baa9a240f7e5ac16",
              "IPY_MODEL_60ef772cefec40bfbd7e9cfef0a64651",
              "IPY_MODEL_f822e5d463b143a5836befebfe74e5ce"
            ],
            "layout": "IPY_MODEL_919398796a1445bf9fe589ff551581c8"
          }
        },
        "eb87f81b7c0843a4baa9a240f7e5ac16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d69d12b8be74835b5579ea0b973c274",
            "placeholder": "​",
            "style": "IPY_MODEL_036ec32a6c444be1ae95d2a727d1944c",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "60ef772cefec40bfbd7e9cfef0a64651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e3da08256142288f200af9c98edc93",
            "max": 107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8795588b15114316b3940456acbc473f",
            "value": 107
          }
        },
        "f822e5d463b143a5836befebfe74e5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46ed3926c672450da3bc78bc15feff9e",
            "placeholder": "​",
            "style": "IPY_MODEL_b279d1d981fd4d4298631336fa4b26d2",
            "value": " 107/107 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "919398796a1445bf9fe589ff551581c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d69d12b8be74835b5579ea0b973c274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "036ec32a6c444be1ae95d2a727d1944c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79e3da08256142288f200af9c98edc93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8795588b15114316b3940456acbc473f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46ed3926c672450da3bc78bc15feff9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b279d1d981fd4d4298631336fa4b26d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17fdafb7d0344661bb3cc459f18c34a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5edfb8869b9443fcb574d283cfa28b95",
              "IPY_MODEL_1ed792cd88ef4e7998e7ff8f6a711ce8",
              "IPY_MODEL_564d70470f6e4fc1a90c15c779ebf4a3"
            ],
            "layout": "IPY_MODEL_7b2548da271a4bcba0fb29bdb55b7bc6"
          }
        },
        "5edfb8869b9443fcb574d283cfa28b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa69ecb958a4ee29e735801d229b951",
            "placeholder": "​",
            "style": "IPY_MODEL_85552ed6321c4c5b9c5e2137aeb8dae3",
            "value": "config.json: 100%"
          }
        },
        "1ed792cd88ef4e7998e7ff8f6a711ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d77f7f3503a42809db27f11d80658e4",
            "max": 704,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01ad257c677e4366877751c2d2cf59d6",
            "value": 704
          }
        },
        "564d70470f6e4fc1a90c15c779ebf4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c8b4f86e43405490fa09a863e8cd9d",
            "placeholder": "​",
            "style": "IPY_MODEL_40cf1ab7dd0c4ac8b2d2992e1e6362bd",
            "value": " 704/704 [00:00&lt;00:00, 47.8kB/s]"
          }
        },
        "7b2548da271a4bcba0fb29bdb55b7bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa69ecb958a4ee29e735801d229b951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85552ed6321c4c5b9c5e2137aeb8dae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d77f7f3503a42809db27f11d80658e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01ad257c677e4366877751c2d2cf59d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64c8b4f86e43405490fa09a863e8cd9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40cf1ab7dd0c4ac8b2d2992e1e6362bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd8ead189e0340ccb2a417316dcf9065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_821fd88bda4c42a1915120de94c7d6c5",
              "IPY_MODEL_3539c4ebd6eb49f9ad1774bd7d498ea5",
              "IPY_MODEL_70d004de272e42d58501a8db71ea43b8"
            ],
            "layout": "IPY_MODEL_3378b32e58ff480aac403bcdeece053f"
          }
        },
        "821fd88bda4c42a1915120de94c7d6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b03fe5c7aa364ae086e732d4288c9807",
            "placeholder": "​",
            "style": "IPY_MODEL_2e27aff92a9049188ced2886e98f32a1",
            "value": "model.safetensors: 100%"
          }
        },
        "3539c4ebd6eb49f9ad1774bd7d498ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7105c71570647a4aa71d5c0c705af48",
            "max": 1336413848,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56aeb44c6385440987199ce4ea1dfc67",
            "value": 1336413848
          }
        },
        "70d004de272e42d58501a8db71ea43b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be54e9f4837841f6a92e6022ebcc5511",
            "placeholder": "​",
            "style": "IPY_MODEL_0c0be9be44874794bc39c53dfd0a239a",
            "value": " 1.34G/1.34G [00:05&lt;00:00, 240MB/s]"
          }
        },
        "3378b32e58ff480aac403bcdeece053f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03fe5c7aa364ae086e732d4288c9807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e27aff92a9049188ced2886e98f32a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7105c71570647a4aa71d5c0c705af48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56aeb44c6385440987199ce4ea1dfc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be54e9f4837841f6a92e6022ebcc5511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0be9be44874794bc39c53dfd0a239a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41b9ecafb65c40c38e476f97b172b94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fb7cfef28ff4dd8b983d0b6f45d3917",
              "IPY_MODEL_215ef21bbadb48289966a799547c31f5",
              "IPY_MODEL_87b4db1450d24c8c98b6abb1bfa892f5"
            ],
            "layout": "IPY_MODEL_45b27c3bcc1f4399930de6467109b204"
          }
        },
        "1fb7cfef28ff4dd8b983d0b6f45d3917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1245ee931c9a416e8569b54f86e60dd8",
            "placeholder": "​",
            "style": "IPY_MODEL_bdf705788cc949d09097ec7345dbf9ff",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "215ef21bbadb48289966a799547c31f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbe8a275285f4a75a27fbbf386d6bed5",
            "max": 1381,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7e96088df4a4856a7ed43dc3f3042ae",
            "value": 1381
          }
        },
        "87b4db1450d24c8c98b6abb1bfa892f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e9e28411fa4972845cf8255ed77560",
            "placeholder": "​",
            "style": "IPY_MODEL_679d30f47b31400d900199daff0c38c0",
            "value": " 1.38k/1.38k [00:00&lt;00:00, 148kB/s]"
          }
        },
        "45b27c3bcc1f4399930de6467109b204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1245ee931c9a416e8569b54f86e60dd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf705788cc949d09097ec7345dbf9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbe8a275285f4a75a27fbbf386d6bed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e96088df4a4856a7ed43dc3f3042ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02e9e28411fa4972845cf8255ed77560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679d30f47b31400d900199daff0c38c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fb2f3272a3f4e1290396befc23d95b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88eaf417ab44436fafc4bf4840054021",
              "IPY_MODEL_e884e447f60d4c1bae624e8c8b99439d",
              "IPY_MODEL_6a827996d2a1402dba21cfc7fbd54552"
            ],
            "layout": "IPY_MODEL_123a290d8e7d4efdb6f1b6d07f0374f0"
          }
        },
        "88eaf417ab44436fafc4bf4840054021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69bd266916b54f2dad6c2b32c84dc952",
            "placeholder": "​",
            "style": "IPY_MODEL_d0ea3c36e78b4aeb90197f554bec2f3c",
            "value": "vocab.txt: 100%"
          }
        },
        "e884e447f60d4c1bae624e8c8b99439d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b3088c37e754fdc95eec7fd1ee5ed0f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd8c92fa4948492290e454eabcb723f1",
            "value": 231508
          }
        },
        "6a827996d2a1402dba21cfc7fbd54552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce25eefbab6542b8adf31bc8f0af0630",
            "placeholder": "​",
            "style": "IPY_MODEL_233b020501e04edabc86ab20252ea578",
            "value": " 232k/232k [00:00&lt;00:00, 534kB/s]"
          }
        },
        "123a290d8e7d4efdb6f1b6d07f0374f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69bd266916b54f2dad6c2b32c84dc952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ea3c36e78b4aeb90197f554bec2f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b3088c37e754fdc95eec7fd1ee5ed0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd8c92fa4948492290e454eabcb723f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce25eefbab6542b8adf31bc8f0af0630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "233b020501e04edabc86ab20252ea578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "159985bc4ca04afcb64dea728f182d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44d0b243000f413bbdd64f4e1e27f835",
              "IPY_MODEL_64f0667ce8384b5e8c6cc23c0cee4db5",
              "IPY_MODEL_528734aaa187412ca211bccc2dff0d4e"
            ],
            "layout": "IPY_MODEL_a22baad263de419babcfa1959c1068e6"
          }
        },
        "44d0b243000f413bbdd64f4e1e27f835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd07becd096406896752a399977e347",
            "placeholder": "​",
            "style": "IPY_MODEL_a2afcfcb083748a599be1de1a1a76f89",
            "value": "tokenizer.json: 100%"
          }
        },
        "64f0667ce8384b5e8c6cc23c0cee4db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f73e86ee3a364f80b21e70d275bafbcb",
            "max": 711649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90b5f5c4e95a4a8a8b7d990db68b5f85",
            "value": 711649
          }
        },
        "528734aaa187412ca211bccc2dff0d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_584cdd8fcf3a4f679aede050843dac75",
            "placeholder": "​",
            "style": "IPY_MODEL_00616310981f4d78886826ca673d4a46",
            "value": " 712k/712k [00:00&lt;00:00, 1.58MB/s]"
          }
        },
        "a22baad263de419babcfa1959c1068e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bd07becd096406896752a399977e347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2afcfcb083748a599be1de1a1a76f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f73e86ee3a364f80b21e70d275bafbcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b5f5c4e95a4a8a8b7d990db68b5f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "584cdd8fcf3a4f679aede050843dac75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00616310981f4d78886826ca673d4a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2db5518a228941efa0d5bd0fa38b099d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c52514ef45f438b8ef105cb92b0e55f",
              "IPY_MODEL_b7bec93856ab468dbe58999b8fd4b9ef",
              "IPY_MODEL_e7ced0f233194397a7c4c894ec052b01"
            ],
            "layout": "IPY_MODEL_ae54928a39cf405abd824d3d32766eed"
          }
        },
        "7c52514ef45f438b8ef105cb92b0e55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e8ca9438dc2404eb61efabd837e455d",
            "placeholder": "​",
            "style": "IPY_MODEL_c49537bcf2dc47688d65c8e0eab07d26",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b7bec93856ab468dbe58999b8fd4b9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c498fffcc1604174bcd42a38148b89d9",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c392818942aa4461bd4b59c9cafd216b",
            "value": 695
          }
        },
        "e7ced0f233194397a7c4c894ec052b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3a2eba9926d48e7b0535cc6e09c849f",
            "placeholder": "​",
            "style": "IPY_MODEL_ad250319a6374c75b4de7d7ae80f55d2",
            "value": " 695/695 [00:00&lt;00:00, 70.8kB/s]"
          }
        },
        "ae54928a39cf405abd824d3d32766eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8ca9438dc2404eb61efabd837e455d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c49537bcf2dc47688d65c8e0eab07d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c498fffcc1604174bcd42a38148b89d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c392818942aa4461bd4b59c9cafd216b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3a2eba9926d48e7b0535cc6e09c849f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad250319a6374c75b4de7d7ae80f55d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "981bcf8fec6d496b86692ea9e7b68f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea2860fcd4be47c3869e22d342d90453",
              "IPY_MODEL_5d580c0e881d44529391bfe013837346",
              "IPY_MODEL_65644575f25245119fea1fb9c0ce5d8c"
            ],
            "layout": "IPY_MODEL_22b1cfbeb9d44a33bb9fb7b914980105"
          }
        },
        "ea2860fcd4be47c3869e22d342d90453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4001363fd98e413993415b6210fe1a16",
            "placeholder": "​",
            "style": "IPY_MODEL_1c00648957814d0899cac456cfddc1cf",
            "value": "config.json: 100%"
          }
        },
        "5d580c0e881d44529391bfe013837346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03867c26432045c78f8d6f366eae9652",
            "max": 297,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca65f51dafc0480ab0e9956ec0b479de",
            "value": 297
          }
        },
        "65644575f25245119fea1fb9c0ce5d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c4d8165964f4faba73684e730a1d9c7",
            "placeholder": "​",
            "style": "IPY_MODEL_a510b44cd0a145d298330c7fa0f019f6",
            "value": " 297/297 [00:00&lt;00:00, 31.0kB/s]"
          }
        },
        "22b1cfbeb9d44a33bb9fb7b914980105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4001363fd98e413993415b6210fe1a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c00648957814d0899cac456cfddc1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03867c26432045c78f8d6f366eae9652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca65f51dafc0480ab0e9956ec0b479de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c4d8165964f4faba73684e730a1d9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a510b44cd0a145d298330c7fa0f019f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}