{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to the Python path\n",
    "package_root = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "print(f\"Adding package root to sys.path: {package_root}\")\n",
    "if package_root not in sys.path:\n",
    "\tsys.path.append(package_root)\n",
    "\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "print(f\"Current notebook directory: {notebook_dir}\")\n",
    "# change to the directory to the root of the project\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "print(f\"Project root: {project_root}\")\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69867d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0aa6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ[\"LANGCHAIN_TRACING_V2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ecd1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lets_talk.chains as chains\n",
    "import lets_talk.prompts as prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589db451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lets_talk.config import Configuration\n",
    "\n",
    "congiruation = Configuration()\n",
    "\n",
    "print(Configuration.react_agent_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "prompt =  ChatPromptTemplate.from_messages( [SystemMessagePromptTemplate.from_template(prompts.REACT_AGENT_PROMPT),MessagesPlaceholder(variable_name=\"history\"), HumanMessagePromptTemplate.from_template(\"{input}\")])\n",
    "\n",
    "time = datetime.datetime.now(tz=datetime.timezone.utc).isoformat()\n",
    "\n",
    "a = prompt.invoke({\"system_time\": time,\"history\": [\"A\",\"B\"], \"input\": \"hello\"})\n",
    "print(a)\n",
    "\n",
    "# from lets_talk.config import LLM_MODEL\n",
    "# from langchain.chat_models import init_chat_model\n",
    "# b = (prompt |  init_chat_model(LLM_MODEL)).invoke({\"system_time\": time,\"history\": [], \"input\": \"What is current time in CST?\"})\n",
    "# print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6bbe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot reload the module\n",
    "\n",
    "importlib.reload(chains)\n",
    "importlib.reload(prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display marked down\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#printmd(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lets_talk.agent as agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uncompiled_graph = agent.build_graph()\n",
    "graph =  uncompiled_graph.compile()\n",
    "\n",
    "#show the graph\n",
    "\n",
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95246cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "config = RunnableConfig(\n",
    "        configurable={\"user_id\": \"abc\", }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "# display(Image(graph.get_graph().draw_png()))\n",
    "# from lets_talk.config import Configuration\n",
    "# config = Configuration()\n",
    "# a= await agent.check_question_tone({\"question\": \"Give me latest?\"},config=config)\n",
    "\n",
    "# print(a)\n",
    "\n",
    "\n",
    "a = await graph.ainvoke({\"question\": \"Go to hell?\"},config=config)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5580034",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"messages\"][-2].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf47811",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"is_rude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = await graph.ainvoke({\"question\": \"What is current time in CDT?\"},config=config)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb417132",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9028067",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df855eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "b['queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db6587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = await graph.ainvoke({\"question\": \"What is data value chain?\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(d[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3aaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lets_talk.utils import format_docs\n",
    "# write format_docs_v2 function\n",
    "def format_docs_v2(docs):\n",
    "    \"\"\"\n",
    "    Format the documents for display.\n",
    "    \"\"\"\n",
    "    # Render all items from metadata in K:V format\n",
    "    # and the page content in a single line\n",
    "    # with a line break between each document\n",
    "    # and a line break between each metadata item\n",
    "    # and the page content in a single line\n",
    "    \n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        # Format all metadata as key-value pairs\n",
    "        metadata_parts = []\n",
    "        for key, value in doc.metadata.items():\n",
    "            metadata_parts.append(f\"**{key}:** {value}\")\n",
    "        \n",
    "        # Join metadata items with line breaks\n",
    "        metadata_str = \"\\n\".join(metadata_parts)\n",
    "        \n",
    "        # Add page content with a line break after metadata\n",
    "        formatted_doc = f\"{metadata_str}\\n\\n**content:** {doc.page_content}\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "\n",
    "    # Join all documents with double line breaks for separation\n",
    "    return \"\\n\\n---\\n\\n\".join(formatted_docs)\n",
    "\n",
    "# Use the corrected format_docs_v2 function\n",
    "printmd(format_docs_v2(d[\"documents\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef05f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06541ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for chunk,_ in graph.astream({\"question\": \"Give me latest?\"}, stream_mode=\"messages\", config=config):\n",
    "    print(chunk.content,end=\"\")\n",
    "    #print(\"\\n\")\n",
    "\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for chunk,metadata in graph.astream({\"question\": \"What is data value chain?\"}, stream_mode=\"messages\"):\n",
    "    if (\n",
    "            chunk.content\n",
    "            and not isinstance(chunk, HumanMessage)\n",
    "            and metadata[\"langgraph_node\"] == \"agent\"\n",
    "        ):\n",
    "        print(chunk.content,end=\"\")\n",
    "    #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b3ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e74ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uncompiled_graph = agent.build_graph()\n",
    "graph =  uncompiled_graph.compile()\n",
    "response = await graph.ainvoke({\"question\": \"Greet the user and provide latest blog posts\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lets_talk.utils import get_message_text\n",
    "printmd(get_message_text(response[\"messages\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response =  await graph.ainvoke({\"question\": \"Who are you?\"},config=config)\n",
    "printmd(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259b5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b34229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the config dictionary to include recursion_limit\n",
    "config_with_recursion = {**config, \"recursion_limit\": 2}\n",
    "\n",
    "response = await graph.ainvoke({\"question\": \"I'm Isa and my email is isa@thedataguy.pro, send a message to thedataguy that I like your blog.\"}, config=config_with_recursion)\n",
    "printmd(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
